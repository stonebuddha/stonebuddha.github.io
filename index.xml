<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Di Wang</title>
    <link>https://stonebuddha.github.io/</link>
      <atom:link href="https://stonebuddha.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Di Wang</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 15 Jan 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://stonebuddha.github.io/media/icon_hub0ca2310ff82550007847b11be674ab8_14787_512x512_fill_lanczos_center_3.png</url>
      <title>Di Wang</title>
      <link>https://stonebuddha.github.io/</link>
    </image>
    
    <item>
      <title>Probabilistic Resource-Aware Session Types</title>
      <link>https://stonebuddha.github.io/publication/daswh23/</link>
      <pubDate>Sun, 15 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://stonebuddha.github.io/publication/daswh23/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Bayesian Synthesis in OCaml</title>
      <link>https://stonebuddha.github.io/post/bayesian-synthesis-in-ocaml/</link>
      <pubDate>Wed, 30 Nov 2022 09:38:59 +0800</pubDate>
      <guid>https://stonebuddha.github.io/post/bayesian-synthesis-in-ocaml/</guid>
      <description>&lt;p&gt;This post aims at reproducing some results from Saad et al.&amp;rsquo;s paper on Bayesian synthesis&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; in &lt;a href=&#34;https://dev.realworldocaml.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OCaml&lt;/a&gt;, an industrial strength functional programming language.
A complete notebook for the code in this post can be found &lt;a href=&#34;notebook.html&#34;&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt;.
The data used for a Bayesian-style time-series analysis can be found &lt;a href=&#34;airline.csv&#34;&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;environment-setup&#34;&gt;Environment Setup&lt;/h2&gt;
&lt;p&gt;The code in this post is tested under OCaml 4.14.0 on macOS 12.6.1 with an M2 chip.
The environment is supposed to contain a Python distribution with &lt;a href=&#34;https://jupyter.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;jupyter&lt;/a&gt; and &lt;a href=&#34;https://matplotlib.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;matplotlib&lt;/a&gt; installed.
The code should also work on macOS (or Linux) with Intel/AMD chips.&lt;/p&gt;
&lt;p&gt;I am maintaining a &lt;code&gt;ppl&lt;/code&gt; repo that contains some extensions of existing OCaml packages.
We will use &lt;code&gt;libtorch&lt;/code&gt; in this post and we need to pin the &lt;code&gt;ocaml-torch&lt;/code&gt; package to version &lt;code&gt;0.14&lt;/code&gt;, because currently the only M1/M2-compatible &lt;code&gt;libtorch&lt;/code&gt; library provided by my &lt;code&gt;ppl&lt;/code&gt; repo is only compatible with this version of &lt;code&gt;ocaml-torch&lt;/code&gt;.
The &lt;code&gt;torch_ext.0.14&lt;/code&gt; and &lt;code&gt;matplotlib.20221112&lt;/code&gt; packages are provided by my &lt;code&gt;ppl&lt;/code&gt; repo:
the former adds some functionality about probability distributions on tensors
and the latter supports more plotting controls and functions.
We will use &lt;code&gt;owl&lt;/code&gt; for parsing CSV files.
For M1/M2 users, you may need to refer to this &lt;a href=&#34;https://github.com/owlbarn/owl/issues/569#issuecomment-1119470541&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;comment&lt;/a&gt; to install &lt;code&gt;owl&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;opam remote add ppl https://github.com/stonebuddha/ppl-opam.git
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;opam pin https://github.com/LaurentMazare/ocaml-torch.git#0.14 --with-version=0.14
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;opam install core jupyter
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;opam install torch_ext.0.14 matplotlib.20221112
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;opam install owl
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The following command registers OCaml as a jupyter kernel (you might take a look at the installation log of the OCaml &lt;code&gt;jupyter&lt;/code&gt; package to find out the exact command):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;jupyter kernelspec install --name ocaml-jupyter /PATH/TO/YOUR/OCAML/SWITCH/share/jupyter
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For Anaconda-based Python distributions, or for Python distributions that are not linked to standard paths for looking for runtime libraries, you might need to update the &lt;code&gt;kernels/ocaml-jupyter/kernel.json&lt;/code&gt; file located in your jupyter installation.
For example, I need to add the following environment variable before invoking &lt;code&gt;ocaml-jupyter-kernel&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;DYLD_LIBRARY_PATH=/opt/homebrew/anaconda3/lib:$DYLD_LIBRARY_PATH
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Finally, we need to add the following code to the &lt;code&gt;.ocamlinit&lt;/code&gt; file (which should be located in your home folder):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-ocaml&#34; data-lang=&#34;ocaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;use&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;topfind&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nn&#34;&gt;Topfind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;log&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ignore&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now you should be able to create and run an OCaml notebook in jupyter.&lt;/p&gt;
&lt;h2 id=&#34;ocaml-torch-basics&#34;&gt;OCaml Torch Basics&lt;/h2&gt;
&lt;p&gt;Here is the &lt;a href=&#34;https://github.com/LaurentMazare/ocaml-torch/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt; to the official introduction of the &lt;code&gt;ocaml-torch&lt;/code&gt; package.
Most APIs are directly generated from &lt;code&gt;libtorch&lt;/code&gt;, and thus similar to the APIs of PyTorch, but in a more functional way.
Tensors are of type &lt;code&gt;Tensor.t&lt;/code&gt; and scalars are of type &lt;code&gt;Scalar.t&lt;/code&gt;.
Because OCaml is statically and strongly typed, we cannot directly multiply a tensor with a floating-point number; instead, we need to first embed a floating-point number as a scalar via &lt;code&gt;Scalar.f : float -&amp;gt; Scalar.t&lt;/code&gt; and then perform the tensor-scalar multiplication via &lt;code&gt;Tensor.mul_scalar : Tensor.t -&amp;gt; Scalar.t -&amp;gt; Tensor.t&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;One benefit of this programming style is that it removes many runtime checks because we know the type information at compile time.
However, this style is not very succinct compared to Python.
Even worse, lack of ad-hoc polymorphism (e.g., operator overloading) makes programming in OCaml more inconvenient than Haskell in this setting.
One workaround is that OCaml supports &lt;em&gt;scoped function calls&lt;/em&gt; (operators are also functions).
For example, if &lt;code&gt;t1 : Tensor.t&lt;/code&gt; and &lt;code&gt;t2 : Tensor.t&lt;/code&gt; are two tensors of the same shape,
we can write &lt;code&gt;Tensor.(t1 + t2)&lt;/code&gt; for pointwise addition of the two tensors.&lt;/p&gt;
&lt;h2 id=&#34;gaussian-process-regression&#34;&gt;Gaussian Process Regression&lt;/h2&gt;
&lt;p&gt;Readers can refer to the textbook &lt;a href=&#34;https://direct.mit.edu/books/book/2320/Gaussian-Processes-for-Machine-Learning&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gaussian Processes for Machine Learning&lt;/a&gt; for more details on Gaussian Processes.
In this post, we focus on a Bayesian-style time-series analysis based on Gaussian Process Regression.
Let $\mathbb{T}$ be an index set and $X \triangleq \{ X(t) \mid t \in \mathbb{T} \}$ be a collection of real-valued random variables.
We say $X$ is a &lt;em&gt;Gaussian Process&lt;/em&gt; if for any $\mathbf{t} = [t_1, t_2, \cdots, t_n]$ of distinct indexes, the random vector $X(\mathbf{t}) \triangleq [X(t_1), X(t_2), \cdots, X(t_n)]$ has a joint Gaussian distribution.&lt;/p&gt;
&lt;p&gt;We can represent a Gaussian Process by its &lt;em&gt;mean function&lt;/em&gt; $m : \mathbb{T} \to \mathbb{R}$ and &lt;em&gt;covariance function&lt;/em&gt; $k : \mathbb{T} \times \mathbb{T} \to \mathbb{R}$ that satisfy for all $t,t&amp;rsquo; \in \mathbb{T}$, it holds that $m(t) = \mathbb{E}[X(t)]$ and $k(t,t&amp;rsquo;) = \mathbb{E}[ (X(t) - m(t)) (X(t&amp;rsquo;) - m(t&amp;rsquo;))]$.
Let $m(\mathbf{t})$ denote the mean vector $[m(t_1), m(t_2), \cdots, m(t_n)]$.
Let $k(\mathbf{t}, \mathbf{t})$ denote the covariance matrix whose $i j$ entry is $k(t_i, t_j)$.
We denote by $X \sim \mathrm{GP}(m,k)$ a Gaussian Process $X$ with mean $m$ and covariance $k$.
For one-dimensional continuous time series (which we consider in this post), we can assume that $\mathbb{T} = \mathbb{R}$.&lt;/p&gt;
&lt;p&gt;The joint probability density of $X(\mathbf{t})$ at a real vector $x(\mathbf{t}) \triangleq [x(t_1), x(t_2), \cdots, x(t_n)]$ is
$$
\begin{align}
\log p(x(\mathbf{t})) &amp;amp; = -\frac{1}{2} \biggl[ (x(\mathbf{t}) - m(\mathbf{t}))^\mathsf{T} k(\mathbf{t}, \mathbf{t})^{-1} ( x(\mathbf{t}) - m(\mathbf{t}) ) \\
&amp;amp; \qquad\qquad {} - \log (\det k(\mathbf{t}, \mathbf{t})) \\
&amp;amp; \qquad\qquad {} - n \log (2\pi) \biggr] .
\end{align}
$$
Multivariate Gaussian distributions are closed under conditioning, thus the posterior distribution of $X(\mathbf{t}&amp;rsquo;)$ at new time indexes $\mathbf{t}&amp;rsquo;$ is also a multivariate Gaussian:
$$
\begin{align}
X(\mathbf{t}&amp;rsquo;) \mid X(\mathbf{t}) = x(\mathbf{t}) &amp;amp; \sim \mathrm{MultivariateGaussian}(m_{post}(\mathbf{t}&amp;rsquo;), k_{post}(\mathbf{t}&amp;rsquo;, \mathbf{t}&amp;rsquo;)), \\
m_{post}(\mathbf{t&amp;rsquo;}) &amp;amp; \triangleq k(\mathbf{t}&amp;rsquo;, \mathbf{t}) k(\mathbf{t}, \mathbf{t})^{-1} x(\mathbf{t}), \\
k_{post}(\mathbf{t&amp;rsquo;}, \mathbf{t}&amp;rsquo;) &amp;amp; \triangleq k(\mathbf{t}&amp;rsquo;, \mathbf{t}&amp;rsquo;) - k(\mathbf{t}&amp;rsquo;, \mathbf{t}) k(\mathbf{t}, \mathbf{t})^{-1} k(\mathbf{t}, \mathbf{t}&amp;rsquo;).
\end{align}
$$&lt;/p&gt;
&lt;p&gt;One can easily add i.i.d. noises to a Gaussian Process.
Consider $Z \sim \mathrm{GP}(m, k)$ and $X(t) \triangleq Z(t) + \gamma(t)$ where $\gamma(t) \sim \mathrm{Gaussian}(0, \varepsilon)$ for any $t \in \mathbb{T}$.
We then say $X$ is a Gaussian Process &lt;em&gt;with output noise $\varepsilon$&lt;/em&gt;, written $X \sim \mathrm{NoisyGP}(m,k,\varepsilon)$.
One can show that $X$ itself is indeed a Gaussian Process $X \sim \mathrm{GP}(m,k&amp;rsquo;)$ where $k&amp;rsquo;$ is defined as $k&amp;rsquo;(t,t&amp;rsquo;) \triangleq k(t,t&amp;rsquo;) + [t=t&amp;rsquo;] \cdot \varepsilon$ for all $t,t&amp;rsquo; \in \mathbb{T}$.&lt;/p&gt;
&lt;p&gt;See the &lt;code&gt;compute_log_likelihood&lt;/code&gt; function and the &lt;code&gt;get_conditional_mu_cov&lt;/code&gt; function in the notebook for computing likelihoods and posterior parameters.&lt;/p&gt;
&lt;h2 id=&#34;gp-synthesis-via-mcmc&#34;&gt;GP Synthesis via MCMC&lt;/h2&gt;
&lt;p&gt;There have been many methods for defining the covariance function of a Gaussian Process.
The grammar below shows one method using a &lt;em&gt;domain-specific language&lt;/em&gt; (DSL), thus enabling an expressive set of (possibly very complex) covariance functions:
$$
\begin{align}
E &amp;amp; ::= \texttt{NoisyGP}(0, K, \varepsilon) \\
K &amp;amp; ::= \texttt{Constant}(\varphi) \mid \texttt{Linear}(\theta) \mid \texttt{Squared_exponential}(\varphi) \\
&amp;amp; \mid \texttt{Periodic}(\varphi_1, \varphi_2) \mid K_1 + K_2 \mid K_1 * K_2 \\
&amp;amp; \varepsilon \in \mathbb{R}_{&amp;gt; 0} \qquad \theta \in \mathbb{R} \qquad \varphi \in \mathbb{R}_{&amp;gt; 0}
\end{align}
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\texttt{Constant}(\varphi)$: the parameter $\varphi$ means the variance of a constant process around $0$.&lt;/li&gt;
&lt;li&gt;$\texttt{Linear}(\theta)$: the parameter $\theta$ means the time intercept of a linear process, i.e., $X(\theta) = 0$ with probability one.&lt;/li&gt;
&lt;li&gt;$\texttt{Squared_exponential}(\varphi)$: the parameter $\varphi$ means the length scale of a stationary smooth process.&lt;/li&gt;
&lt;li&gt;$\texttt{Periodic}(\varphi_1, \varphi_2)$: the parameter $\varphi_1$ means the length scale of a periodic process, and the parameter $\varphi_2$ represents the frequency of the process.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In a Bayesian-style time-series analysis, we model unknown quantities as random variables and known data as generated observations.
For any $n &amp;gt; 0$ and distinct time indexes $\mathbf{t} = [t_1, t_2, \cdots, t_n]$, the generative model is&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Sample a noise level $\varepsilon \sim P(\varepsilon)$ (e.g., a Gamma prior).&lt;/li&gt;
&lt;li&gt;Sample a covariance expression $K \sim P(K)$ (e.g., the &lt;code&gt;covariance_prior&lt;/code&gt; function in the notebook, which implements a probabilistic context-free grammar).&lt;/li&gt;
&lt;li&gt;Sample time-series data $X(\mathbf{t}) \sim \mathrm{NoisyGP}(0, K, \varepsilon)$. (See the &lt;code&gt;eval_cov_mat&lt;/code&gt; function in the notebook for how to translate an expression in the DSL to a covariance function.)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Running Bayesian inference on the generative model above with the real vector $x(\mathbf{t}) = [x(t_1), x(t_2), \cdots, x(t_n)]$ essentially performs a &lt;em&gt;Bayesian synthesis&lt;/em&gt; of the covariance expression $K$.
Markov-chain Monte Carlo (MCMC) is a popular sampling-based method for Bayesian inference; it allows us to sample from the posterior distribution $P(\varepsilon, K \mid X(\mathbf{t}) = x(\mathbf{t}))$.
MCMC works by constructing a Markov chain over latent random variables ($\varepsilon$ and $K$ in this case),
and the chain is usually generated from a &lt;em&gt;proposal&lt;/em&gt; kernel that generates new candidates for latent variables from their current values.
The proposed new values are accepted with respect to the &lt;a href=&#34;https://en.wikipedia.org/wiki/Metropolis%e2%80%93Hastings_algorithm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Metropolis-Hastings&lt;/em&gt; criterion&lt;/a&gt;.
The &lt;code&gt;mh_resample_noise&lt;/code&gt; function in the notebook simply generates a fresh noise level from a Gamma distribution.
The &lt;code&gt;mh_resample_subtree_unbiased&lt;/code&gt; function implements a more involved mechanism that unbiasedly selects a node in the AST of the covariance expression $K$
and replaces the subtree rooted at that node with a freshly generated sub-expression.
The &lt;code&gt;run_mcmc&lt;/code&gt; function then runs an epoch of the MCMC method by resampling repeatedly for a few times.
The last cell of the notebook demonstrates the effectiveness of the Bayesian-synthesis approach on a time-series analysis of revenue passenger miles for US air carrier domestic flights.&lt;/p&gt;
&lt;h2 id=&#34;next-steps&#34;&gt;Next Steps&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;How to write tensor-manipulation code more easily in a statically and strongly typed language like OCaml?&lt;/li&gt;
&lt;li&gt;How to develop a lightweight mechanism that checks tensor shape compatibility at compile time?&lt;/li&gt;
&lt;li&gt;The plotting functionality provided in this post largely depends on the Python ecosystem. How to design a plotting library with APIs that are more suitable for typed functional programming?&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;Feras A. Saad, Marco F. Cusumano-Towner, Ulrich Schaechtle, Martin C. Rinard, and Vikash K. Mansinghka. 2019. Bayesian Synthesis of Probabilistic Programs for Automatic Data. &lt;em&gt;POPL&#39;19&lt;/em&gt;.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Easy Syntax Highlighting for LaTeX</title>
      <link>https://stonebuddha.github.io/post/easy-syntax-highlighting-for-latex/</link>
      <pubDate>Tue, 12 Jul 2022 04:56:22 +0800</pubDate>
      <guid>https://stonebuddha.github.io/post/easy-syntax-highlighting-for-latex/</guid>
      <description>&lt;p&gt;Tool link: &lt;a href=&#34;https://github.com/cpitclaudel/esh&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Emacs Syntax Highlighting for LaTeX (ESH)&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The tool does not really require understanding Emacs: one just needs a working
installation!
The tool seems well tested on GNU/Linux; however, I am mainly using macOS, so I
find out an easy workflow that works for me.
First, we need to install &lt;a href=&#34;https://github.com/cask/cask&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cask&lt;/a&gt;, a project
management tool for Emacs; such process should be easy and straightforward.
Then we clone the &lt;code&gt;esh&lt;/code&gt; repo and run &lt;code&gt;cask build&lt;/code&gt; at the root of the repo.
If nothing goes wrong, we are now able to use ESH!&lt;/p&gt;
&lt;p&gt;Let us go to a LaTeX project where we want to highlight OCaml code.
First, we create a file &lt;code&gt;Cask&lt;/code&gt; with the following content:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-lisp&#34; data-lang=&#34;lisp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;source&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;gnu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;source&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;melpa&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;depends-on&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;tuareg&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;;; for OCaml mode&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Then we run &lt;code&gt;cask install&lt;/code&gt; to install the required packages.
Now we start to configure how we would like our code to be highlighted.
We achieve this by creating a file &lt;code&gt;esh-init.el&lt;/code&gt;, and below gives an example:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-lisp&#34; data-lang=&#34;lisp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;load-theme&lt;/span&gt; &lt;span class=&#34;ss&#34;&gt;&amp;#39;tango&lt;/span&gt; &lt;span class=&#34;no&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;;; a color theme&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;add-to-list&lt;/span&gt; &lt;span class=&#34;ss&#34;&gt;&amp;#39;auto-mode-alist&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;\\.ml\\&amp;#39;&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;tuareg-mode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;;; .ml file extension&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;;; some custom prettification&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;when&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;require&lt;/span&gt; &lt;span class=&#34;ss&#34;&gt;&amp;#39;tuareg&lt;/span&gt; &lt;span class=&#34;no&#34;&gt;nil&lt;/span&gt; &lt;span class=&#34;no&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;defun&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;my-tuareg-setup&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;setq-local&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;prettify-symbols-alist&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;fun&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;?&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;λ&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;-&amp;gt;&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;?&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;→&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;prettify-symbols-mode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;add-hook&lt;/span&gt; &lt;span class=&#34;ss&#34;&gt;&amp;#39;tuareg-mode-hook&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;#&amp;#39;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;my-tuareg-setup&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Next, we run &lt;code&gt;./path/to/esh/bin/esh2tex --write-preamble&lt;/code&gt; to create a file &lt;code&gt;esh-preamble.tex&lt;/code&gt;.
The generated TeX file implements functions to highlight code in TeX.
Below presents an example LaTeX file:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-latex&#34; data-lang=&#34;latex&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;\documentclass&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{&lt;/span&gt;article&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;\usepackage&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;[varqu]&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{&lt;/span&gt;zi4&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;c&#34;&gt;% for inconsolata font
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;\input&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{&lt;/span&gt;esh-preamble&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;\begin&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{&lt;/span&gt;document&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;\ESHInputBlock&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{&lt;/span&gt;test.ml&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;\end&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;{&lt;/span&gt;document&lt;span class=&#34;nb&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;And an example OCaml code file &lt;code&gt;test.ml&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-ocaml&#34; data-lang=&#34;ocaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;let&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;rec&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;append&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;l1&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;l2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;match&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;l1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;[]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;l2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;::&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;xs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;::&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;xs&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;l2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;let&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;rec&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;partition&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;l&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;match&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;l&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;[]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;::&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;xs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;let&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;partition&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;xs&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;in&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;then&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;::&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;::&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;bs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;let&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;rec&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;quicksort&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;le&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;function&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;[]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;[]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;::&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;xs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;let&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ys&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;zs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;partition&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;le&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;xs&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;in&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;append&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;quicksort&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;le&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ys&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;::&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;quicksort&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;le&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;zs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;ESH needs to invoke Emacs to highlight the code and we have to perform this
external operation manually.
Fortunately, we just need to run &lt;code&gt;./path/to/esh/bin/esh2tex --standalone test.ml&lt;/code&gt;,
which should generate a file &lt;code&gt;test.ml.esh.tex&lt;/code&gt;.
Finally, we can typeset our LaTeX project (e.g, &lt;code&gt;pdflatex main&lt;/code&gt;) and should
get something similar to the following screenshot:
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/easy-syntax-highlighting-for-latex/example_hua9e26af124910f58e1d063b36d38f13c_133564_0c5bd0df2fcdfdd89c596ad0e0e753c5.webp 400w,
               /post/easy-syntax-highlighting-for-latex/example_hua9e26af124910f58e1d063b36d38f13c_133564_650d9435e24ada875e8a4ff9b448941d.webp 760w,
               /post/easy-syntax-highlighting-for-latex/example_hua9e26af124910f58e1d063b36d38f13c_133564_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://stonebuddha.github.io/post/easy-syntax-highlighting-for-latex/example_hua9e26af124910f58e1d063b36d38f13c_133564_0c5bd0df2fcdfdd89c596ad0e0e753c5.webp&#34;
               width=&#34;760&#34;
               height=&#34;665&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Amazing!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Central Moment Analysis for Cost Accumulators in Probabilistic Programs</title>
      <link>https://stonebuddha.github.io/publication/wanghr21a/</link>
      <pubDate>Sun, 20 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://stonebuddha.github.io/publication/wanghr21a/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Sound Probabilistic Inference via Guide Types</title>
      <link>https://stonebuddha.github.io/publication/wanghr21b/</link>
      <pubDate>Sun, 20 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://stonebuddha.github.io/publication/wanghr21b/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Type-Guided Worst-Case Input Generation</title>
      <link>https://stonebuddha.github.io/talk/type-guided-worst-case-input-generation/</link>
      <pubDate>Thu, 03 Jun 2021 10:00:00 -0400</pubDate>
      <guid>https://stonebuddha.github.io/talk/type-guided-worst-case-input-generation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Expected-Cost Analysis for Probabilistic Programs and Semantics-Level Adaption of Optional Stopping Theorems</title>
      <link>https://stonebuddha.github.io/publication/wanghr21c/</link>
      <pubDate>Tue, 30 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://stonebuddha.github.io/publication/wanghr21c/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Termination Analysis of Random Walks</title>
      <link>https://stonebuddha.github.io/post/termination-analysis-of-random-walks/</link>
      <pubDate>Mon, 15 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://stonebuddha.github.io/post/termination-analysis-of-random-walks/</guid>
      <description>&lt;p&gt;In this post, we consider one-dimensional random walks:
assume that $S_n = \sum_{i=1}^n X_i$ is a random walk on the integers with
initial value $S_0 = 0$, where $X_i, i \in \mathbb{N}$ are independent and
identically distributed random variables.
For termination analysis, we introduce a &lt;i&gt;stopping time&lt;/i&gt;: a nonnegative
integer-valued random variable $T$ such that for every integer $n \ge 0$, the
indicator function of the event $\lbrace T = n \rbrace$ is a function of
$S_1,S_2,\cdots,S_n$.&lt;/p&gt;
&lt;h2 id=&#34;symmetric-random-walk&#34;&gt;Symmetric Random Walk&lt;/h2&gt;
&lt;p&gt;For each $i \in \mathbb{N}$, we consider
$X_i = \left\lbrace \begin{array}{ll}  1 &amp;amp; \text{with prob.}~0.5 \\ -1 &amp;amp; \text{with prob.}~0.5 \end{array} \right.$.
Symmetric random walks are known to be &lt;em&gt;recurrent&lt;/em&gt;, i.e., with probability
one, any state is visited infinitely often.
Let us consider the case where the random walk terminates when it reaches the
level $1$, i.e., $T := \min\lbrace n \ge 0 : S_n = 1 \rbrace$, and $T$ is
clearly a stopping time.
How do we establish the recurrence property for $T$, i.e., $\mathbb{P}[T &amp;lt; \infty] = 1$?
Moreover, what can we say about $\mathbb{E}[T]$?&lt;/p&gt;
&lt;p&gt;One method is to derive $T$&amp;rsquo;s &lt;em&gt;probability generating function&lt;/em&gt;
$G(z) := \mathbb{E}[z^T] = \sum_{n=0}^{\infty} z^n \mathbb{P}[T=n]$,
which is defined for all real values of $z$ less than $1$ in absolute value.
The strategy for the derivation is to condition on the first step of the random
walk to obtain a functional equation for $G$; there are two possibilities:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if $X_1 = 1$, then $S_1 = 1$ and $T = 1$; or&lt;/li&gt;
&lt;li&gt;if $X_1 = -1$, then $S_1 = -1$, and the random walk must first return to the
origin, and the amount of time it takes to reach $0$ starting from $-1$ has the
same distribution as&amp;mdash;and is conditionally independent of&amp;mdash;$T$ itself (i.e.,
the amount of time to reach $1$ from $0$).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thus, $G(z) = 0.5z + 0.5z \cdot G(z) \cdot G(z) = (z + zG(z)^2) / 2$.
This is a functional equation, whose solution is $G(z) = (1 \pm \sqrt{1 - z^2})/z$.
Moreover, observing that $G(z)$ takes values between 0 and 1 when $z \in (0,1)$,
we obtain the unique solution $G(z) = (1 - \sqrt{1- z ^2})/z$.&lt;/p&gt;
&lt;p&gt;Then, by the monotone convergence theorem, we have
$$
\mathbb{P}[T &amp;lt; \infty] = \sum_{n=0}^\infty \mathbb{P}[T = n] = \lim_{z \to 1^-} G(z) = 1.
$$
Similarly, noting that $G&amp;rsquo;(z) = \sum_{n=1}^{\infty} n z^{n-1} \mathbb{P}[T=n]$,
we can express $\mathbb{E}[T]$ as $G&amp;rsquo;(1^-)$.
Because $G&amp;rsquo;(z) = (-1 + 1/\sqrt{1 - z^2})/z^2$,
we have $\mathbb{E}[T] = G&amp;rsquo;(1^-) = \infty$, i.e., the expected termination time is infinity.&lt;/p&gt;
&lt;h2 id=&#34;gamblers-ruin&#34;&gt;Gambler&amp;rsquo;s Ruin&lt;/h2&gt;
&lt;p&gt;Let us consider another termination criterion for symmetric random walks:
it is set up so that Alice and Bob bet one dollar against each other on the
results of a fair coin flip until one play runs out of money. Suppose that Alice
starts with $A$ dollars and Bob starts with $B$ dollars.
We define a termination time to model the gamble:
$T := \min\lbrace n \ge 0: S_n = -A \vee S_n = B\rbrace$, which is clearly a stopping time.
By a similar argument, we can show both $\mathbb{P}[T_A &amp;lt; \infty] = 1$
where $T_A := \min\lbrace n \ge 0: S_n = -A \rbrace$,
and $\mathbb{P}[T_B &amp;lt; \infty] = 1$ where $T_B := \min\lbrace n \ge 0: S_n = B\rbrace$.
Thus, we know that $\mathbb{P}[T &amp;lt; \infty] = 1$ as $T = \min(T_A,T_B)$.
But what about $\mathbb{E}[T]$ in this case?&lt;/p&gt;
&lt;p&gt;We use another technique called &lt;em&gt;Wald identities&lt;/em&gt;, two of which have the form below
in a random-walk setting:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;If the step distribution has a finite first moment and the stopping
time has a finite expectation, then $\mathbb{E}[S_T] = \mathbb{E}[X_1]\mathbb{E}[T]$.&lt;/li&gt;
&lt;li&gt;If the step distribution has a finite second moment and the stopping
time has a finite expectation, then $\mathbb{E}[(S_T-\mathbb{E}[X_1]T)^2]=\mathbb{E}[(X_1-\mathbb{E}[X_1])^2]\mathbb{E}[T]$.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let us assume $\mathbb{E}[T] &amp;lt; \infty$ first.
By the definition of $X_1$, we know that $\mathbb{E}[X_1] = 0$ and $\mathbb{E}[X_1^2]=1$.
By the first Wald identity, we have $\mathbb{E}[S_T]=0$.
The random variable $S_T$ takes only two values, $-A$ and $B$, with probabilities
$u$ and $1-u$ such that $u \cdot (-A) + (1-u) \cdot B = 0 \implies u = B/(A+B)$.
By the second Wald identity, we know that $\mathbb{E}[S_T^2]=\mathbb{E}[T]$.
Thus, we can compute $\mathbb{E}[T]$ from $S_T$&amp;rsquo;s distribution:
$ \frac{B}{A+B} \cdot (-A)^2 + \frac{A}{A+B} \cdot B^2 = A \cdot B$.&lt;/p&gt;
&lt;p&gt;To show $\mathbb{E}[T] &amp;lt; \infty$ at the first place, we observe that if at any
time during the gamble Alice wins consecutive $A+B$ rounds, then Bob must run out
of money and the gamble must terminate. Thus,
$$
\mathbb{P}[T &amp;gt; k(A+B)] \le (1 - \frac{1}{2^{A+B}})^k,
$$
and $\mathbb{E}[T] \le \sum_{k=0}^\infty (A+B)(1-\frac{1}{2^{A+B}})^k &amp;lt; \infty$.&lt;/p&gt;
&lt;h2 id=&#34;asymmetric-random-walk-uneven-steps&#34;&gt;Asymmetric Random Walk (Uneven Steps)&lt;/h2&gt;
&lt;p&gt;For each $i \in \mathbb{N}$, we consider
$X_i = \left\lbrace \begin{array}{ll}  2 &amp;amp; \text{with prob.}~0.5 \\ -1 &amp;amp; \text{with prob.}~0.5 \end{array} \right.$.
For the termination criterion, we define $T(m) := \min\lbrace n \ge 0 : S_n \ge m\rbrace$ for any positive integer $m$.
Let us fixed an $m$ and write $T = T(m)$.
This time, we do not argue that $\mathbb{P}[T &amp;lt; \infty] = 1$, but reason about $\mathbb{E}[T]$ directly.&lt;/p&gt;
&lt;p&gt;We want to construct a &lt;em&gt;martingale&lt;/em&gt; $\lbrace Y_n \rbrace_{n \in \mathbb{N}_0}$,
which is adapted to $\lbrace S_n \rbrace_{n \in \mathbb{N}_0}$, as follows:
$$ Y_n := n + 2(m+1 - S_n), n \in \mathbb{N}_0. $$
We can verify the martingale property by
$$
\begin{align}
&amp;amp; \mathbb{E}[Y_{n+1} \mid S_0,S_1,\cdots,S_n] \\
={} &amp;amp; n+1 + 2(m+1-S_n) - 2\mathbb{E}[X_{n+1} \mid S_0,S_1,\cdots,S_n] \\
={} &amp;amp; n+1 + 2(m+1-S_n) - 1 \\
={} &amp;amp; Y_n.
\end{align}
$$
Then the stopped process $\lbrace Y_{T \wedge n} \rbrace_{n \in \mathbb{N}_0}$ is a nonnegative
martingale, because $\mathbb{P}[S_n \le m + 1 \mid n \le T] = 1$.
Therefore, by Doob&amp;rsquo;s martingale convergence theorem, $Y_T := \lim_{n \to \infty} Y_{T \wedge n}$
is almost-surely well-defined and $\mathbb{E}[Y_T] \le \mathbb{E}[Y_0] = 2(m+1)$.
On the other hand, the random variable $S_T$ takes only two values, $m$ and $(m+1)$, so
we have $Y_T = T + 2(m+1-S_T) \ge T$, thus $\mathbb{E}[T] \le 2(m+1)$.&lt;/p&gt;
&lt;p&gt;To obtain an exact result for $\mathbb{E}[T]$, we can reason about the distribution
of $S_T$ (via recurrence solving) and apply the first Wald identity.
The result is $\mathbb{E}[T] = 2(m+1 - \frac{2}{1+\sqrt{5}}( 1 - (\frac{1-\sqrt{5}}{2})^{m+1} ) )$.&lt;/p&gt;
&lt;h2 id=&#34;asymmetric-random-walk-uneven-probabilities&#34;&gt;Asymmetric Random Walk (Uneven Probabilities)&lt;/h2&gt;
&lt;p&gt;For each $i \in \mathbb{N}$, we consider
$X_i = \left\lbrace \begin{array}{ll}  1 &amp;amp; \text{with prob.}~0.75 \\ -1 &amp;amp; \text{with prob.}~0.25 \end{array} \right.$.
For the termination criterion, we define $T(m) := \min\lbrace n \ge 0 : S_n = m\rbrace$ for any positive integer $m$.
This time, we want to reason about both $\mathbb{E}[T(m)]$ and $\mathbb{E}[T(m)^2]$.&lt;/p&gt;
&lt;p&gt;We can use the techniques in previous sections to derive that $\mathbb{P}[T(m) &amp;lt; \infty] = 1$
and $\mathbb{E}[T(m)] = 2m$.
For second (or even higher) moments, we can again use probability generating functions
$G_m(z) := \mathbb{E}[z^{T(m)}]$.
Observing that a random walk with the target level $m$ can be decomposed into $m$
independent random walks that reach $1$ starting from $0$,
we have $G_m(z) = G_1(z)^m$.
We follow the strategy that conditions on the first step of the random walk to obtain
a functional equation for $G_1(z)$; there are two possibilities:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if $X_1=1$, then $S_1=1$ and $T=1$; or&lt;/li&gt;
&lt;li&gt;if $X_1=-1$, then $S_1=-1$ and the problem can be reduced to reaching $2$ starting from $0$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thus, $G_1(z) = 0.75z + 0.25z \cdot G_2(z) = 0.75z + 0.25zG_1(z)^2$.
The solution is $G_1(z) = (2 \pm \sqrt{4 - 3z^2})/z$.
Again, because $G_1(z)$ takes values between 0 and 1 when $z \in (0,1)$, we obtain the unique solution
$G_1(z) = (2-\sqrt{4-3z^2})/z$.&lt;/p&gt;
&lt;p&gt;Let us write $T = T(m)$.
By the property of probability generating functions, we have $\mathbb{E}[T(T-1)] = G_m&amp;rsquo;&amp;rsquo;(1^-) = 4m^2+4m$.
Therefore, $\mathbb{E}[T^2] = \mathbb{E}[T(T-1)] + \mathbb{E}[T] = 4m^2+6m$.&lt;/p&gt;
&lt;h2 id=&#34;whats-more&#34;&gt;What&amp;rsquo;s More&lt;/h2&gt;
&lt;p&gt;In &lt;a href=&#34;../../publication/wanghr21a&#34;&gt;our paper&lt;/a&gt;, we present a systematic and automated
framework for upper- and lower-bounding higher moments of cost accumulators (e.g., termination time)
in probabilistic programs (e.g., random walks).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Type-Based Resource-Guided Search</title>
      <link>https://stonebuddha.github.io/talk/type-based-resource-guided-search/</link>
      <pubDate>Fri, 16 Oct 2020 12:00:00 -0400</pubDate>
      <guid>https://stonebuddha.github.io/talk/type-based-resource-guided-search/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Liquid Resource Types</title>
      <link>https://stonebuddha.github.io/publication/knothwr20/</link>
      <pubDate>Sun, 23 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://stonebuddha.github.io/publication/knothwr20/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Raising Expectations: Automating Expected Cost Analysis with Types</title>
      <link>https://stonebuddha.github.io/publication/wangkh20/</link>
      <pubDate>Sun, 23 Aug 2020 00:00:00 +0000</pubDate>
      <guid>https://stonebuddha.github.io/publication/wangkh20/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Resource-Guided Program Synthesis</title>
      <link>https://stonebuddha.github.io/talk/resource-guided-program-synthesis/</link>
      <pubDate>Fri, 22 Nov 2019 12:00:00 -0500</pubDate>
      <guid>https://stonebuddha.github.io/talk/resource-guided-program-synthesis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Resource-Guided Program Synthesis</title>
      <link>https://stonebuddha.github.io/publication/knothwp19/</link>
      <pubDate>Sat, 22 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://stonebuddha.github.io/publication/knothwp19/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Denotational Semantics for Low-Level Probabilistic Programs with Nondeterminism</title>
      <link>https://stonebuddha.github.io/publication/wanghr19/</link>
      <pubDate>Mon, 03 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://stonebuddha.github.io/publication/wanghr19/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Type-Guided Worst-Case Input Generation</title>
      <link>https://stonebuddha.github.io/publication/wangh19/</link>
      <pubDate>Sun, 13 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://stonebuddha.github.io/publication/wangh19/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Using FFT to Speed Up DP</title>
      <link>https://stonebuddha.github.io/post/using-fft-to-speed-up-dp/</link>
      <pubDate>Sat, 03 Nov 2018 00:00:00 +0000</pubDate>
      <guid>https://stonebuddha.github.io/post/using-fft-to-speed-up-dp/</guid>
      <description>&lt;p&gt;Problem link: &lt;a href=&#34;https://www.hackerrank.com/challenges/counting-road-networks&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Counting Road Networks | HackerRank&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You are supposed to count the number of connected undirected labeled graphs with $n$ vertices.
Algorithms with $O(n \log^2 n)$ time complexity are preferable.&lt;/p&gt;
&lt;h2 id=&#34;a-dynamic-programming-algorithm&#34;&gt;A Dynamic-Programming Algorithm&lt;/h2&gt;
&lt;p&gt;Let $f(n)$ be the answer for $n$.
The first idea to compute $f(n)$ is subtracting the number of disconnected graphs from the total number.
The total number of size-$n$ graphs is $g(n) := 2^{\binom{n}{2}}$.
How to count the disconnected graphs?
Let&amp;rsquo;s consider the size $m$ of the connected component containing the vertex labeled with 1.
Since the graph is disconnected, $m$ cannot be $n$.
Then the number of disconnected graphs where the connected component containing vertex 1 is a certain one with size $m$ is exactly $f(m) \cdot g(n-m)$.
Now we have an $O(n^2)$-time dynamic-programming algorithm as follows.
$$
f(n) = g(n) - \sum_{m=1}^{n-1} \binom{n-1}{m-1} \cdot f(m) \cdot g(n - m)
$$&lt;/p&gt;
&lt;h2 id=&#34;expression-rearrangement&#34;&gt;Expression Rearrangement&lt;/h2&gt;
&lt;p&gt;If we unfold the binomial coefficients, we will have
$$
\frac{f(n)}{(n-1)!} = n \cdot \frac{g(n)}{n!} - \sum_{m=1}^{n-1} \frac{f(m)}{(m-1)!} \cdot \frac{g(n-m)}{(n-m)!}
$$
Let $F(n) := \frac{f(n)}{(n-1)!}$ and $G(n) := \frac{g(n)}{n!}$.
Moreover, let&amp;rsquo;s set $F(0)$ to $0$ and then we have
$$
F(n) = n \cdot G(n) - \sum_{m=0}^{n-1} F(m) \cdot G(n-m)
$$
Note that we already have a convolution-like term in the formula.&lt;/p&gt;
&lt;h2 id=&#34;an-optimization-based-on-fft&#34;&gt;An Optimization Based on FFT&lt;/h2&gt;
&lt;p&gt;We will use &lt;a href=&#34;https://en.wikipedia.org/wiki/Fast_Fourier_transform&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Fast Fourier transform&lt;/a&gt; (FFT) as an $O(n \log n)$-time algorithm to compute convolution of length $n$.&lt;/p&gt;
&lt;p&gt;First of all, $G(n)$ are easy to compute so we can pre-process them.
Now we are going to use a divide-and-conquer scheme.
Let $solve(l,r)$ be a procedure that computes $F(n)$ for all $n \in [l,r)$.
In addition, we add the following invariant to this procedure:&lt;/p&gt;
&lt;p&gt;When invoking $solve(l,r)$, we already compute for each $n \in [l,r)$, the partial convolution $\sum_{m=0}^{l-1} F(m) \cdot G(n-m)$, and store them in $H(n)$.&lt;/p&gt;
&lt;p&gt;Then our algorithm proceeds as follows.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If $l+1=r$, we set $F(l)$ to $l \cdot G(l) - H(l)$.&lt;/li&gt;
&lt;li&gt;Otherwise, let&amp;rsquo;s invoke $solve(l,k)$ first where $k = \frac{l+r}{2}$, i.e., the middle point.
Now we already solve the first half of the problem.
To become able to invoke $solve(k,r)$ to complete the second half, we need to do something to maintain the invariant above.
In essence, we need to update
$$
H(n) \gets H(n) + \sum_{m=l}^{k-1} F(m) \cdot G(n-m)
$$
for each $n \in [k,r)$.
Here comes the chance for optimization.
What we really want to compute is the convolution of $F[l,k)$ and $G[0,r-l)$!
Let the convolution result be $C$ and indeed we have
$$
C(n) = \sum_{m=l}^{k-1}  F(m) \cdot G(n-m)
$$
for each $n \in [k,r)$.
After performing $H(n) \gets H(n) + C(n)$ for each $n \in [k,r)$, we reestablish the invariant and we can recurse to $solve(k,r)$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Finally, let&amp;rsquo;s estimate the time complexity of the algorithm above.
Let $T(n)$ be the running time of $solve(l,r)$ with $n=r-l$.
By using FFT to compute the convolution, we can establish the following
$$
T(n) = 2T(\frac{n}{2}) + O(n \log n)
$$
Then by the Master Theorem we derive that $T(n) = O(n \log^2 n)$.&lt;/p&gt;
&lt;h2 id=&#34;whats-more&#34;&gt;What&amp;rsquo;s More&lt;/h2&gt;
&lt;p&gt;For those who could read Chinese, &lt;a href=&#34;https://www.cs.princeton.edu/~danqic/misc/divide-and-conquer.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CDQ&amp;rsquo;s divide-and-conquer&lt;/a&gt; is a good reference about applications of the divide-and-conquer scheme in this post.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PMAF: An Algebraic Framework for Static Analysis of Probabilistic Programs</title>
      <link>https://stonebuddha.github.io/publication/wanghr18/</link>
      <pubDate>Wed, 20 Jun 2018 00:00:00 +0000</pubDate>
      <guid>https://stonebuddha.github.io/publication/wanghr18/</guid>
      <description></description>
    </item>
    
    <item>
      <title>PMAF: An Algebraic Framework for Static Analysis of Probabilistic Programs</title>
      <link>https://stonebuddha.github.io/talk/pmaf-an-algebraic-framework-for-static-analysis-of-probabilistic-programs/</link>
      <pubDate>Fri, 20 Apr 2018 12:00:00 -0400</pubDate>
      <guid>https://stonebuddha.github.io/talk/pmaf-an-algebraic-framework-for-static-analysis-of-probabilistic-programs/</guid>
      <description></description>
    </item>
    
    <item>
      <title>TiML: A Functional Language for Practical Complexity Analysis with Invariants</title>
      <link>https://stonebuddha.github.io/talk/timl-a-functional-language-for-practical-complexity-analysis-with-invariants/</link>
      <pubDate>Fri, 09 Feb 2018 12:00:00 -0500</pubDate>
      <guid>https://stonebuddha.github.io/talk/timl-a-functional-language-for-practical-complexity-analysis-with-invariants/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Nondeterministic Interpretation</title>
      <link>https://stonebuddha.github.io/post/nondeterministic-interpretation/</link>
      <pubDate>Thu, 08 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://stonebuddha.github.io/post/nondeterministic-interpretation/</guid>
      <description>&lt;p&gt;Suppose you have a toy specification with built-in nondeterminism, and you want to generate answers with respect to the specification:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-ocaml&#34; data-lang=&#34;ocaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;exp&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;EInt&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;EPair&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;exp&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;exp&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;ENdet&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;exp&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;exp&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ans&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;VInt&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;VPair&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ans&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ans&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;For example, from the following specification&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-ocaml&#34; data-lang=&#34;ocaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nc&#34;&gt;EPair&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;ENdet&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;EInt&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;EInt&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;ENdet&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;EInt&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;7&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;EInt&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;you might want to generate a bunch of possible answers:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-ocaml&#34; data-lang=&#34;ocaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nc&#34;&gt;VPair&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;VInt&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;VInt&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;7&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nc&#34;&gt;VPair&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;VInt&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;VInt&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nc&#34;&gt;VPair&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;VInt&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;VInt&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;7&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nc&#34;&gt;VPair&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;VInt&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;VInt&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The scene might be where you want to specify something with multiple sites of nondeterminism, ask the generator to come up with an answer, and successively give you other answers until you are satisfied.&lt;/p&gt;
&lt;p&gt;The basic methodology is search.
We want to construct a recursive procedure on the structure of a specification.
For a sub-specification, it should know two sorts of computation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the computation that completes a whole answer and constructs a procedure for next whole answers, given the current sub-answer for the sub-specification and a procedure for next whole answers if the current sub-answer would leads to a subsequent unsatisfactoriness; and&lt;/li&gt;
&lt;li&gt;the computation to find next whole answers.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this sense, the first computation has type $\mathsf{ans} \to \mathsf{next} \to \mathsf{ans} \times \mathsf{next}$, and the second one should be typed $\mathsf{next}$.
A computation of type $\mathsf{next}$ is supposed to (i) either fail, or (ii) take no arguments, and when invoked it should return the next whole answer as well as a new $\mathsf{next}$ computation.
Thus we have $\mathsf{next} \equiv \mathbf{1} + \mathbf{1} \to (\mathsf{ans} \times \mathsf{next})$.
Therefore we use recursive types to model this mechanism.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-ocaml&#34; data-lang=&#34;ocaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;next&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;NFail&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;NCont&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;unit&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ans&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;next&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Then it is straightforward to implement an interpreter:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-ocaml&#34; data-lang=&#34;ocaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;let&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;rec&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;interp&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;exp&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cont&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fail&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;match&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;exp&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;EInt&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cont&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;VInt&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fail&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;EPair&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;e&amp;#39;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;interp&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;e&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fun&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fail&amp;#39;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;interp&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;e&amp;#39;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fun&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&amp;#39;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fail&amp;#39;&amp;#39;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cont&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;VPair&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&amp;#39;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fail&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fail&amp;#39;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fail&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;o&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;ENdet&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;e1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;e2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;interp&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;e1&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cont&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;NCont&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fun&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;interp&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;e2&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cont&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fail&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The execution should be the following:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-ocaml&#34; data-lang=&#34;ocaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;let&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ans1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;next1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;interp&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;EPair&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;ENdet&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;EInt&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;EInt&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;ENdet&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;EInt&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;7&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;EInt&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fun&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fail&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;fail&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;NFail&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c&#34;&gt;(* val ans1 : ans = VPair (VInt 5, VInt 7) *)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c&#34;&gt;(* val next1 : next = NCont &amp;lt;fun&amp;gt; *)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;let&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ans2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;next2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;match&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;next1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;NCont&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c&#34;&gt;(* val ans2 : ans = VPair (VInt 5, VInt 8) *)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c&#34;&gt;(* val next2 : next = NCont &amp;lt;fun&amp;gt; *)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;let&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ans3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;next3&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;match&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;next2&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;NCont&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c&#34;&gt;(* val ans3 : ans = VPair (VInt 6, VInt 7) *)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c&#34;&gt;(* val next3 : next = NCont &amp;lt;fun&amp;gt; *)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;let&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ans4&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;next4&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;match&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;next3&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;NCont&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c&#34;&gt;(* val ans4 : ans = VPair (VInt 6, VInt 8) *)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c&#34;&gt;(* val next4 : next = NFail *)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>TiML: A Functional Language for Practical Complexity Analysis with Invariants</title>
      <link>https://stonebuddha.github.io/publication/wangwc17/</link>
      <pubDate>Wed, 25 Oct 2017 00:00:00 +0000</pubDate>
      <guid>https://stonebuddha.github.io/publication/wangwc17/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Conditional Dyck-CFL Reachability Analysis for Complete and Efficient Library Summarization</title>
      <link>https://stonebuddha.github.io/publication/tangwx17/</link>
      <pubDate>Sat, 22 Apr 2017 00:00:00 +0000</pubDate>
      <guid>https://stonebuddha.github.io/publication/tangwx17/</guid>
      <description></description>
    </item>
    
    <item>
      <title>News Archive</title>
      <link>https://stonebuddha.github.io/news_archive/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://stonebuddha.github.io/news_archive/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;[Nov 2020]&lt;/strong&gt; Our technical report about &lt;a href=&#34;https://arxiv.org/pdf/2011.09037.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Probabilistic Resource-Aware Session Types&lt;/a&gt; is available on arXiv.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[Jun 2020]&lt;/strong&gt; Our articles &lt;a href=&#34;../publication/knothwr20&#34;&gt;Liquid Resource Types&lt;/a&gt; and &lt;a href=&#34;../publication/wangkh20&#34;&gt;Raising Expectations: Automating Expected Cost Analysis with Types&lt;/a&gt; have been accepted to ICFP 2020.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[May 2019]&lt;/strong&gt; Check out our recent MFPS paper on &lt;a href=&#34;../publication/wanghr19&#34;&gt;A Denotational Semantics for Low-Level Probabilistic Programs with Nondeterminism&lt;/a&gt; with Jan and Tom.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[Feb 2019]&lt;/strong&gt; Great news: Our paper on &lt;a href=&#34;../publication/knothwp19&#34;&gt;Resource-Guided Program Synthesis&lt;/a&gt; has been conditionally accepted to PLDI 2019.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[Nov 2018]&lt;/strong&gt; I am excited that our paper &lt;a href=&#34;../publication/wangh19&#34;&gt;Type-Guided Worst-Case Input Generation&lt;/a&gt; with Jan Hoffmann has been accepted to POPL 2019.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[Mar 2018]&lt;/strong&gt; Check out my talent show &lt;a href=&#34;https://www.youtube.com/watch?v=zNxltZhPIG0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Chengdu&lt;/a&gt; on SCS Day 2018!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[Feb 2018]&lt;/strong&gt; I am excited that our paper &lt;a href=&#34;../publication/wanghr18&#34;&gt;PMAF: An Algebraic Framework for Static Analysis of Probabilistic Programs&lt;/a&gt; (with Jan Hoffmann and Tom Reps) has been conditionally accepted to PLDI 2018.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[Jun 2017]&lt;/strong&gt; I graduated from Peking University! My diploma thesis is about &lt;a href=&#34;../files/wang17thesis.pdf&#34;&gt;Accelerating Program Analyses by Conditional Summarization with Datalog&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Resources for Prospective Students</title>
      <link>https://stonebuddha.github.io/prospective-students/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://stonebuddha.github.io/prospective-students/</guid>
      <description>&lt;p&gt;I am broadly interested in topics related to programming languages, especially
formal verification, program analysis, and probabilistic programming.
I am currently working on resource-safe system programming, programmable
Bayesian inference, quantitative program analysis, and proof-oriented
programming languages.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If you want to learn about possible projects and research directions that I
would like to advise or collaborate on at the moment, check out the &lt;a href=&#34;#current-research-directions&#34;&gt;list&lt;/a&gt; below.&lt;/li&gt;
&lt;li&gt;If you want to know more about my long-term perspectives of &lt;strong&gt;incorporating
randomness in software&lt;/strong&gt;, check out my
&lt;a href=&#34;https://stonebuddha.github.io/files/research.pdf&#34; target=&#34;_blank&#34;&gt;research statement&lt;/a&gt;
that I wrote for my faculty applications.&lt;/li&gt;
&lt;li&gt;If you care about teaching and mentoring, check out my
&lt;a href=&#34;https://stonebuddha.github.io/files/teaching.pdf&#34; target=&#34;_blank&#34;&gt;teaching statement&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;If you have concrete questions about me or Peking University, check out the
&lt;a href=&#34;#qa&#34;&gt;Q&amp;amp;A&lt;/a&gt; below, and send me an email if your question is not covered there.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;qa&#34;&gt;Q&amp;amp;A&lt;/h1&gt;
&lt;details open class=&#34;spoiler&#34;&gt;
  &lt;summary&gt;Are you recruiting students?&lt;/summary&gt;
  &lt;div style=&#34;display:inline-block;margin-left:1.5em;&#34;&gt;
  &lt;b&gt;Yes&lt;/b&gt;!
  I am just getting started and planning to ramp up slowly (one to two PhD student a year).
  I am also looking for self-motivated master and undergraduate students.
  &lt;/div&gt;
&lt;/details&gt;
&lt;details open class=&#34;spoiler&#34;&gt;
  &lt;summary&gt;
  Do I need to have a &lt;em&gt;specific&lt;/em&gt; research background?
  Do I need to know a &lt;em&gt;specific&lt;/em&gt; problem to work on?
  &lt;/summary&gt;
  &lt;div style=&#34;display:inline-block;margin-left:1.5em;&#34;&gt;
  The short answer is &#34;&lt;b&gt;no&lt;/b&gt;.&#34;
  Programming-languages or software-engineering research experience would be a plus but &lt;b&gt;not a requisite&lt;/b&gt;.
  It is more important to know what you are interested in and be passionate enough about
  a broad area of problems to spend about four to five years to work on.
  &lt;/div&gt;
&lt;/details&gt;
&lt;details open class=&#34;spoiler&#34;&gt;
  &lt;summary&gt;Can I do machine learning / operating systems / database / ...?&lt;/summary&gt;
  &lt;div style=&#34;display:inline-block;margin-left:1.5em;&#34;&gt;
  &lt;b&gt;Yes&lt;/b&gt;, if you are interested in the intersection of programming languages and the other field.
  Check out these interdisciplinary workshops:
  &lt;a href=&#34;https://pldi22.sigplan.org/home/maps-2022&#34;&gt;Symposium on Machine Programming&lt;/a&gt;,
  &lt;a href=&#34;https://popl22.sigplan.org/home/lafi-2022&#34;&gt;Workshop on Languages for Inference&lt;/a&gt;,
  &lt;a href=&#34;https://plos-workshop.org/2021/&#34;&gt;Workshop on Programming Languages and Operating Systems&lt;/a&gt;,
  and
  &lt;a href=&#34;https://sites.google.com/view/dbpl2021&#34;&gt;Symposium on Database Programming Languages&lt;/a&gt;.
  &lt;/div&gt;
&lt;/details&gt;
&lt;details open class=&#34;spoiler&#34;&gt;
  &lt;summary&gt;Why should I consider Peking University? Who else could I work with at Peking University?&lt;/summary&gt;
  &lt;div style=&#34;display:inline-block;margin-left:1.5em;&#34;&gt;
  Peking University has a world-class Computer Science Department (#13 according to
  &lt;a href=&#34;https://csrankings.org/#/index?all&amp;world&#34;&gt;CSRankings&lt;/a&gt;
  and #24 according to
  &lt;a href=&#34;https://www.topuniversities.com/university-rankings/university-subject-rankings/2022/computer-science-information-systems&#34;&gt;QS Rankings&lt;/a&gt;).
  We have a large department with many amazing faculty and students working on software
  engineering, programming languages, systems, and other areas.
  Check out the following professors and their students, in last-name alphabetical order:
  &lt;a href=&#34;http://sei.pku.edu.cn/~haod&#34;&gt;Hao, Dan&lt;/a&gt;;
  &lt;a href=&#34;https://zhenjiang888.github.io/&#34;&gt;Hu, Zhenjiang&lt;/a&gt;;
  &lt;a href=&#34;https://taoxiease.github.io/&#34;&gt;Xie, Tao&lt;/a&gt;;
  &lt;a href=&#34;https://xiongyingfei.github.io/&#34;&gt;Xiong, Yingfei&lt;/a&gt;;
  &lt;a href=&#34;http://sei.pku.edu.cn/~zhanglu&#34;&gt;Zhang, Lu&lt;/a&gt;; and
  &lt;a href=&#34;https://xinpl.github.io/&#34;&gt;Zhang, Xin&lt;/a&gt;.
  &lt;/div&gt;
&lt;/details&gt;
&lt;details open class=&#34;spoiler&#34;&gt;
  &lt;summary&gt;You did not reply to my email!&lt;/summary&gt;
  &lt;div style=&#34;display:inline-block;margin-left:1.5em;&#34;&gt;
  &lt;b&gt;Please wait for one week, then resend it.&lt;/b&gt;
  &lt;/div&gt;
&lt;/details&gt;
&lt;h1 id=&#34;current-research-directions&#34;&gt;Current Research Directions&lt;/h1&gt;
&lt;p&gt;I always welcome new collaborators on the following (incomprehensive) list of research topics.
Please contact me if you are interested in working on one of those directions.&lt;/p&gt;
&lt;h3 id=&#34;resource-safe-system-programming&#34;&gt;Resource-Safe System Programming&lt;/h3&gt;
&lt;p&gt;Resource usage (e.g., time, memory, and energy) of a program is one of the central
subjects of computer science. However, resource usage usually does not play a central
role in programming language theory such as formal semantics, static analysis,
type systems, and program logics. I am generally interested in most resource-analysis
projects, including both verification (e.g., of software implemented in an existing
programming language) and language design (e.g., for easier and more precise resource analysis).&lt;/p&gt;
&lt;p&gt;Analysis of resource usage becomes increasingly critical for system programming.
The recent success of Rust indicates that modern system programming languages should
focus on static safety guarantees, such as memory safety and thread safety.
There are a lot of programming languages that do provide such guarantees, but
mostly via runtime mechanisms (such as garbage collection), and those mechanisms
result in unsatisfactory performance, especially in system software.
Rust, by proposing a memory-safety type system, reduces runtime resource consumption
and thus achieves high performance.
&lt;strong&gt;The performance of system software does not only involve memory management, thought.&lt;/strong&gt;
I am interested in proposing a paradigm of &lt;strong&gt;resource-safe programming&lt;/strong&gt;, where
resource consumption of programs are statically verified to meet developers&amp;rsquo; expectation,
and the programs do not exhibit multiple kinds of resource-related vulnerabilities,
such as algorithmic complexity attacks and side-channel attacks.
Below is a sample of medium- to long-term projects of resource-safe system programming:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Resource analysis of Rust&lt;/em&gt;: Can the fine-grained memory model improve the precision
and efficiency of resource analysis?&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Resource analysis of concurrent programs&lt;/em&gt;: Rust has limited support for static thread-safety
guarantees, e.g., Rust does not statically rule out deadlocks. Can we incorporate fine-grained
concurrency model in system programming and extend resource analysis to support it?&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Target-level resource analysis&lt;/em&gt;: How can we analyze compiled programs with respect to
low-level resource metrics, e.g., the number of clock cycles? The analysis needs to be hardware-specific
because we need to take cache, pipeline, branch prediction, etc. into consideration.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Discovery of resource-related security vulnerabilities&lt;/em&gt;: Can we detect algorithmic-complexity-attack
bugs and/or side-channel-attack bugs? In addition, if such bugs exist, can we automatically
synthesize an attacker to trigger the bugs?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At the moment, my favored approach is Automatic Amortized Resource Analysis (AARA&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;)
but I am open to other approaches such as recurrence solving, sized types, ranking functions,
symbolic resource analysis, etc.&lt;/p&gt;
&lt;h3 id=&#34;programmable-bayesian-inference&#34;&gt;Programmable Bayesian Inference&lt;/h3&gt;
&lt;p&gt;In contrast to frequentist methods like deep learning, Bayesian learning accounts
for the probability distribution of hypotheses that produce the observed data and thus
naturally quantifies the uncertainty that is present in the learned models.
In addition, Bayesian learning enables the straightforward incorporation of domain
knowledge and generalizes well to unseen data. These advantages of Bayesian learning
are realized by probabilistic programming languages (PPLs) like &lt;a href=&#34;https://mc-stan.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Stan&lt;/a&gt; and &lt;a href=&#34;http://pyro.ai/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Pyro&lt;/a&gt;,
which provide an interface that separates model development from various built-in
Bayesian inference algorithms.&lt;/p&gt;
&lt;p&gt;The main downside of Bayesian learning is that probabilistic inference is computationally hard
and not even the most advanced inference algorithms work well for all models.
To make probabilistic inference for Bayesian learning feasible for more models and larger data sets,
some PPLs have there forgone the strict separation of modeling and inference by enabling users to customize
specific Bayesian inference algorithms through so-called &lt;strong&gt;programmable inference&lt;/strong&gt;&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.
However, it is all too easy for users to incorrectly program inference in a way that
breaks convergence and leads to unsound learned models. Such a mistake can even go unnoticed.&lt;/p&gt;
&lt;p&gt;I am interested in dissipating the tension between soundness and flexibility of
probabilistic inference by applying programming language techniques such as type
systems and static analysis. The vision is that new programming abstractions and
type systems ensure the soundness of programmable inference while static analysis
and program synthesis assist users by automating the customization of inference
with to goal of improving efficiency. Our &lt;a href=&#34;https://stonebuddha.github.io/publication/wanghr21b&#34; target=&#34;_blank&#34;&gt;recent paper&lt;/a&gt;
is a concrete demonstration of this research direction.&lt;/p&gt;
&lt;h3 id=&#34;quantitative-program-analysis&#34;&gt;Quantitative Program Analysis&lt;/h3&gt;
&lt;p&gt;Randomness in programs can show up in two ways: external randomness (e.g.,
uncertainty from the environment) and internal randomness (e.g., randomized algorithms).
As Kleene algebras become an algebraic foundation for analysis of non-probabilistic programs&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;,
I am interested in developing an algebraic framework for analysis of probabilistic programs.
To this end, we need to formulate an algebraic semantic framework of probabilistic programs,
and develop a generic algorithm to solve program-analysis instances for probabilistic programs.&lt;/p&gt;
&lt;p&gt;One fundamental difference between non-probabilistic and probabilistic programs
is that an execution of a non-probabilistic program is a &lt;strong&gt;chain&lt;/strong&gt;, but an execution
of a probabilistic program is a &lt;strong&gt;tree&lt;/strong&gt;.
To see the point, consider that our program model allows nondeterminism.
A non-probabilistic program then corresponds to a collection of possible execution chains,
but a probabilistic program should be interpreted as a &lt;strong&gt;collection of distributions&lt;/strong&gt;,
each of which can be encoded as an execution tree, where each rooted path (annotated with
a probability) is a concrete run of the program.
See our &lt;a href=&#34;https://stonebuddha.github.io/publication/wanghr19&#34; target=&#34;_blank&#34;&gt;MFPS paper&lt;/a&gt; for
a more formal presentation based on &lt;em&gt;hyper graphs&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Abstract interpretation is a powerful framework for describing and solving program-analysis
instances.
Researchers have proposed generic solving strategies, such as chaotic iteration, widening, narrowing, etc.
&lt;strong&gt;However, the iterative solving algorithms do not fit into the quantitative nature
of probabilistic programs.&lt;/strong&gt;
Suppose we want to analyze a probabilistic loop &amp;ldquo;$\mathbf{while}~(\mathbf{prob}(3/4))~\{ x = x + 1; \}$.&amp;rdquo;
The expected delta of the variable $x$ is the least solution to the equation $r = f(r) \equiv (1/4) \cdot 0+(3/4) \cdot (r+1)$,
and we can analytically solve it directly: $r = 3$.
However, an iterative solving strategy would approach $r$ by a sequence of approximations: $\{ f^i(0) \}_{i \in \mathbb{N}}$,
which will not converge in any finite number of iterations.
I am interested in adapting &lt;em&gt;Newtonian Program Analysis&lt;/em&gt;&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; to the probabilistic setting, with the observation
that Newton&amp;rsquo;s method is more suitable for such a quantitative setting.&lt;/p&gt;
&lt;p&gt;Moreover, the proposed algebraic framework of reasoning about probabilistic programs
should, in principle, be also suitable for reasoning about other quantitative properties,
such as &lt;strong&gt;resource consumption&lt;/strong&gt;.
It would be interesting be see if this observation leads to a more general quantitative
program analysis framework.
A recent paper by Batz et al. proposed a notion of &lt;em&gt;weighted programming&lt;/em&gt;&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;, which
further generalizes the quantitative properties.
Applications of the proposed quantitative program analysis framework include
technology transfer between probabilistic analysis and resource analysis; for example,
Maximum-a-Posteriori (MAP) estimation has a very
similar problem statement to Worst-Case Analysis (WCA), so it would be interesting to
use the observation to build new statistical resource analysis techniques.&lt;/p&gt;
&lt;h3 id=&#34;proof-oriented-programming-languages&#34;&gt;Proof-Oriented Programming Languages&lt;/h3&gt;
&lt;h1 id=&#34;other-projects&#34;&gt;Other Projects&lt;/h1&gt;
&lt;p&gt;I am always open to new directions, including interdisciplinary ones.
Below is a sample of initial ideas that I am interested in exploring in the
short (or medium) term.
The list is not complete, and be aware that most of the thoughts are not
matured at all; in fact, I would expect some of them will quickly lead to
negative results.&lt;/p&gt;
&lt;h3 id=&#34;static-analysis&#34;&gt;Static Analysis&lt;/h3&gt;
&lt;details class=&#34;spoiler&#34;&gt;
  &lt;summary&gt;Library Summarization via Tensor Products&lt;/summary&gt;
  &lt;span style=&#34;display:inline-block;margin-left:1.5em;&#34;&gt;
&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: Library summarization is an effective way to accelerate the
analysis of client code. However, information about the client is unknown
at the library summarization, preventing complete summarization of the library.
A state-of-the-art approach is &lt;a href=&#34;https://stonebuddha.github.io/publication/tangwx17&#34; target=&#34;_blank&#34;&gt;Conditional Dyck-CFL Reachability Analysis (ConCRA)&lt;/a&gt;,
which targets graph-reachability-like static analyses and uses hypothetical summaries.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proposal&lt;/strong&gt;: Lal et al.&lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt; proposed a tensor-product principle: Tensor products
with an appropriate detensor operation allow computations to be rearranged in
certain ways; for example, they can be used to delay a multiplication in a chain
of multiplications. This principle may allow us to generalize, in the summarization framework,
Dyck-CFL-reachability-based analyses to algebraic semiring-based analysis.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Follow-up&lt;/strong&gt;: The library summarization problem can be generalized to partially solving
an equation system for a static analysis. Any thoughts on partial evaluation?&lt;/p&gt;
  &lt;/span&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler&#34;&gt;
  &lt;summary&gt;NPA-TP for Non-idempotent Semirings&lt;/summary&gt;
  &lt;span style=&#34;display:inline-block;margin-left:1.5em;&#34;&gt;
&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: Esparza et al.&lt;sup id=&#34;fnref1:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; generalized Newton&amp;rsquo;s method to a method for finding
fixed-points of systems of equations over semirings, leading to a new algorithm
to solve interprocedural dataflow analysis.
Reps et al.&lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt; developed NPA-TP, which extended Esparza&amp;rsquo;s framework with an improved
algorithm for solving linear-context-free-language (LCFL) sub-problems.
However, NPA-TP assumes the underlying abstract domain admits an idempotent semiring;
such an assumption rules out interesting analysis domains, especially for numerical
properties, e.g., the reaching probability.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proposal&lt;/strong&gt;: Esparza&amp;rsquo;s original framework does support non-idempotent semirings,
so it would be a good starting point. The NPA-TP framework features tensor products
to solve LCFL sub-problems, and from the perspective of algebras, the principle of
tensor products does not require idempotence.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Follow-up&lt;/strong&gt;: Some recent work shows that quantum computation also needs
non-idempotent semirings. Can the idea of NPA-TP be generalized to analyze
quantum programs?&lt;/p&gt;
  &lt;/span&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler&#34;&gt;
  &lt;summary&gt;Complicated Probability Manipulation&lt;/summary&gt;
  &lt;span style=&#34;display:inline-block;margin-left:1.5em;&#34;&gt;
&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: In many programs, the manipulation of probability is very complicated
and even manual analysis of their correctness is difficult. Consider the problem below:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;while&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;prob&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We want to verify that at the end of the loop, the probability of the event $x \ge \frac{1}{2}$
is exactly $p$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proposal&lt;/strong&gt;: &lt;a href=&#34;https://en.wikipedia.org/wiki/Probability-generating_function&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Probability-generating functions&lt;/a&gt; provide a succinct
way to describe probability distributions of discrete random variables.
We might try to derive the probability-generating function of a probabilistic program to
reason about the resulting distribution of the program.
A recent paper&lt;sup id=&#34;fnref:8&#34;&gt;&lt;a href=&#34;#fn:8&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;8&lt;/a&gt;&lt;/sup&gt; is on this direction.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Follow-up&lt;/strong&gt;: There is a connection between derivatives of the probability-generating function of
a random variable $X$ and the moments of $X$. Can we use the fact to perform moment analysis?&lt;/p&gt;
  &lt;/span&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler&#34;&gt;
  &lt;summary&gt;Fine-grained Heap Abstraction via Regular Patterns&lt;/summary&gt;
  &lt;span style=&#34;display:inline-block;margin-left:1.5em;&#34;&gt;
&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: Static analysis of heap-manipulation programs often involves
heap sensitivity. In the simplest case, all memory allocations with the same
program location are treated as a single allocation (thus in a context-insensitive way).
Advanced techniques include three-value-logic for shape analysis, $k$-CFA, $m$-CFA&lt;sup id=&#34;fnref:9&#34;&gt;&lt;a href=&#34;#fn:9&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;9&lt;/a&gt;&lt;/sup&gt;, etc.
However, they seem insufficient when we want to analyze recursive programs.
(Imagine that in functional programming, iterating over a list is usually implemented as a
recursive function.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proposal&lt;/strong&gt;: We can treat the set of all call-strings as a language, then
different strategies for handling sensitivity are essentially different ways of
defining equivalence classes on the language. A presumably good proposal is to use
regular patterns to classify equivalence classes.
For example, $(ff)^*$ indicates calling a function $f$ for an even number of times,
$f(ff)^*$ for an odd number.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Follow-up&lt;/strong&gt;: In fact, this approach should generalize to all sensitivities that
use call strings. Is it meaningful to develop a general framework with regular-pattern-sensitivity?&lt;/p&gt;
  &lt;/span&gt;
&lt;/details&gt;
&lt;h3 id=&#34;formal-semantics&#34;&gt;Formal Semantics&lt;/h3&gt;
&lt;details class=&#34;spoiler&#34;&gt;
  &lt;summary&gt;Combination of Continuous Distributions and Nondeterminism-first&lt;/summary&gt;
  &lt;span style=&#34;display:inline-block;margin-left:1.5em;&#34;&gt;
&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: &lt;a href=&#34;https://stonebuddha.github.io/publication/wanghr19&#34; target=&#34;_blank&#34;&gt;Nondeterminism-first&lt;/a&gt; means that we resolve nondeterminism prior to
program inputs when defining denotational semantics. For example, suppose that a
deterministic function has the signature $A \to B$, then a standard resolution of
nondeterminism gives us $A \to \wp(B)$, but nondeterminism-first suggests $\wp(A \to B)$.
Nondeterminism-first can be useful for e.g., compile-time nondeterminism.
A recent study proposed a denotational semantics for probabilistic programs
that combines discrete distributions (on a countable state space) and nondeterminism-first.
However, it remains open if the semantics can be extended to support continuous distributions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proposal&lt;/strong&gt;: In fact, I do not have any ideas yet.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Follow-up&lt;/strong&gt;: What about a computational theory for such a combination?&lt;/p&gt;
  &lt;/span&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler&#34;&gt;
  &lt;summary&gt;Combination of Probability and Message-passing Concurrency&lt;/summary&gt;
  &lt;span style=&#34;display:inline-block;margin-left:1.5em;&#34;&gt;
&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: The common treatment of a probabilistic flip in the semantics
is to &amp;ldquo;split&amp;rdquo; the current program configuration into two, one for the &amp;ldquo;world&amp;rdquo; where
the flip shows heads and the other for tails. When we need to deal with multiple
concurrent processes, such a treatment means a local flip in a process results in
duplicating all other processes. Such a non-local (thus non-compositional) behavior has been shown to be
problematic for proving soundness of formal methods (e.g., type systems, which are usually compositional).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proposal&lt;/strong&gt;: The result of a probabilistic flip should remain as local as possible.
We have recently developed &lt;a href=&#34;https://stonebuddha.github.io/publication/daswh20&#34; target=&#34;_blank&#34;&gt;an operational semantics with the desirable locality&lt;/a&gt;, but I feel that
a more algebraic representation is better. For example, we might want to rearrange
the operational semantics to reduction rules and congruence rules. Furthermore, we
should prove an equivalence result to the ordinary probabilistic semantics (e.g., Markov chains).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Follow-up&lt;/strong&gt;: I can always imagine that adding nondeterminism causes a lot of troubles.&lt;/p&gt;
  &lt;/span&gt;
&lt;/details&gt;
&lt;h3 id=&#34;type-systems&#34;&gt;Type Systems&lt;/h3&gt;
&lt;details class=&#34;spoiler&#34;&gt;
  &lt;summary&gt;Safe Interaction between Typed Domain Specific Languages&lt;/summary&gt;
  &lt;span style=&#34;display:inline-block;margin-left:1.5em;&#34;&gt;
&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: Consider we have a typed programming language that is suitable for developing
embedded Domain Specific Languages (eDSLs).
Every eDSL can directly use the base type system from the host language, but it can
also have its own advanced domain-specific type system.
Languages such as &lt;a href=&#34;https://okmij.org/ftp/ML/MetaOCaml.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MetaOCaml&lt;/a&gt; have already supported
such a mechanism, but the interaction between the host language and the eDSL,
or maybe even between different eDSLs, is not very convenient yet.
It would be nice to have a simple and safe interaction scheme among eDSLs on
a same host language.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proposal&lt;/strong&gt;: In fact, I do not have any ideas yet.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Follow-up&lt;/strong&gt;: What else should we have for such a flexible eDSL framework? For example,
we might want to consider multi-stage compilation, debugger, mixed paradigm, etc.&lt;/p&gt;
  &lt;/span&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler&#34;&gt;
  &lt;summary&gt;Lightweight Shape Check for Array Programming&lt;/summary&gt;
  &lt;span style=&#34;display:inline-block;margin-left:1.5em;&#34;&gt;
&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: Array programming (or tensor programming) is pervasive nowadays because of machine learning.
Many machine-learning frameworks lack the ability to statically check tensor shapes are always consistent
during program execution. Approaches based on dependent/refinement/indexed types all seem too heavy to
become practical.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proposal&lt;/strong&gt;: In many (really?) cases, when the input of an array program is fixed,
the shapes of all intermediate arrays are also fixed. So we can perform a static shape check
after the input is given, but before we execute the program, by propagating the concrete shape information
from the given input.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Follow-up&lt;/strong&gt;: Is it possible to automatically learn the shape-related effects of library functions (e.g., &lt;code&gt;broadcast_tensor&lt;/code&gt;)?&lt;/p&gt;
  &lt;/span&gt;
&lt;/details&gt;
&lt;h3 id=&#34;resource-analysis&#34;&gt;Resource Analysis&lt;/h3&gt;
&lt;details class=&#34;spoiler&#34;&gt;
  &lt;summary&gt;Fraction Bounds for Expected Cost Analysis&lt;/summary&gt;
  &lt;span style=&#34;display:inline-block;margin-left:1.5em;&#34;&gt;
&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: Most of current resource-analysis techniques derive linear, polynomial,
or exponential bounds. However, when analyzing probabilistic programs, we often
encounter bounds that involve fractions. For example, the simple loop &lt;code&gt;while (prob(p)) tick(1);&lt;/code&gt;
has an expected cost of $\frac{p}{1-p}$, where $p$ is a program variable that denotes
a non-trivial probability.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proposal&lt;/strong&gt;: In many cases, a fraction bound can be expressed as a polynomial
over another polynomial. So it should be possible to extend current template-based
resource-analysis techniques (e.g., AARA) that derive polynomial bounds, by using
a template for the denominator to reduce fraction-bound inference to polynomial-bound
inference.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Follow-up&lt;/strong&gt;: A random thought: how can we apply such resource-analysis technique
to Bayesian inference (like a recent paper by Beutner et al.&lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;)?&lt;/p&gt;
  &lt;/span&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler&#34;&gt;
  &lt;summary&gt;AARA for Probabilistic Functional Programs with Non-monotone Resources&lt;/summary&gt;
  &lt;span style=&#34;display:inline-block;margin-left:1.5em;&#34;&gt;
&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: Our &lt;a href=&#34;https://stonebuddha.github.io/publication/wangkh20&#34; target=&#34;_blank&#34;&gt;ICFP paper&lt;/a&gt; presents
an extension of AARA that infers upper bounds on the expected cost of probabilistic functional
programs with monotone resources (such as time). In general, combining probability
and non-monotone resources (such as memory) is unreasonably complex&lt;sup id=&#34;fnref:11&#34;&gt;&lt;a href=&#34;#fn:11&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;11&lt;/a&gt;&lt;/sup&gt;. Applying optional stopping
theorems, people have successfully developed techniques for analyzing arithmetic programs.
It would be interesting to see if the whole methodology applies to functional programming,
where we have inductive data structures (that can hold potential) instead of numbers.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proposal&lt;/strong&gt;: One version of optional stopping theorems states that the expected change
in one evaluation step should be &amp;ldquo;bounded.&amp;rdquo; This should intuitively hold for
functional programming (I mean, in most cases) because one step should change the
size of a data structure by at most one (consider the case of &lt;code&gt;cons&lt;/code&gt;).
By constructing a suitable Markov chain, we might be able to reason about
probabilistic functional programs with non-monotone resources.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Follow-up&lt;/strong&gt;: Optional stopping theorems always talk about &amp;ldquo;expected change&amp;rdquo;
and &amp;ldquo;expected termination time.&amp;rdquo; Why them?!&lt;/p&gt;
  &lt;/span&gt;
&lt;/details&gt;
&lt;h3 id=&#34;probabilistic-programming&#34;&gt;Probabilistic Programming&lt;/h3&gt;
&lt;details class=&#34;spoiler&#34;&gt;
  &lt;summary&gt;Domain-specific Procedural Design&lt;/summary&gt;
  &lt;span style=&#34;display:inline-block;margin-left:1.5em;&#34;&gt;
&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: &lt;a href=&#34;https://dritchie.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Daniel Ritchie&lt;/a&gt; suggested generative
probabilistic programming for procedural modeling and design (the use of random programs
to generate visual content with respect to aesthetic or functional constraints).
Such an approach has been rediscovered in several individual developments, such as
Scenic&lt;sup id=&#34;fnref:12&#34;&gt;&lt;a href=&#34;#fn:12&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;12&lt;/a&gt;&lt;/sup&gt; and Picture&lt;sup id=&#34;fnref:13&#34;&gt;&lt;a href=&#34;#fn:13&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;13&lt;/a&gt;&lt;/sup&gt;. So instead of separate developments,
we want to develop a framework to ease such domain-specific procedural design.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proposal&lt;/strong&gt;: This has something to do with the eDSL framework.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Follow-up&lt;/strong&gt;: It might be interesting to see how such &lt;strong&gt;static&lt;/strong&gt; procedural design
evolves to &lt;strong&gt;dynamic&lt;/strong&gt; procedural design (e.g., synthesis of an environment).
Another direction is interactive refinement (e.g., incorporating feedbacks from users)
of the generated designs.&lt;/p&gt;
  &lt;/span&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler&#34;&gt;
  &lt;summary&gt;Language Design for Sound Involutive MCMC&lt;/summary&gt;
  &lt;span style=&#34;display:inline-block;margin-left:1.5em;&#34;&gt;
&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: A recent paper by Cusumano-Towner et al.&lt;sup id=&#34;fnref:14&#34;&gt;&lt;a href=&#34;#fn:14&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;14&lt;/a&gt;&lt;/sup&gt; studies
how to ease the burden of implementing involutive MCMC by combining probabilistic
programming and differentiable programming. It still remains a challenge (emm, you have to double check)
to statically verify the correctness of a concrete implementation in their framework.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proposal&lt;/strong&gt;: I would try to combine type systems for sound programmable inference
and sound differentiable programming.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Follow-up&lt;/strong&gt;: I am thinking of &lt;em&gt;The Next XXX MCMC Algorithms&lt;/em&gt;.&lt;/p&gt;
  &lt;/span&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler&#34;&gt;
  &lt;summary&gt;Quantum Probability and Bayesian Inference&lt;/summary&gt;
  &lt;span style=&#34;display:inline-block;margin-left:1.5em;&#34;&gt;
&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: Quantum physics uses a form of complex probability. People have been
thinking of it as a serious probability theory (see &lt;a href=&#34;https://arxiv.org/abs/hep-th/9307019&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt; and &lt;a href=&#34;https://en.wikipedia.org/wiki/Quantum_Bayesianism&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt;).
There are even quantum analogs of Bayesian inference (&lt;a href=&#34;https://link.springer.com/chapter/10.1007/978-3-642-00834-4_5&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;one&lt;/a&gt; and &lt;a href=&#34;https://arxiv.org/abs/2006.02256&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;the other&lt;/a&gt;). Does it make sense to incorporate some of those ideas in current probabilistic programming systems?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proposal&lt;/strong&gt;: I still have to learn quantum physics (emm, not really).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Follow-up&lt;/strong&gt;: Some people are trying to add quantum features
to standard Bayesian models (check out &lt;a href=&#34;https://www.informatyka.agh.edu.pl/media/uploads/qis_presentation12.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this&lt;/a&gt;).&lt;/p&gt;
  &lt;/span&gt;
&lt;/details&gt;
&lt;h3 id=&#34;program-synthesis&#34;&gt;Program Synthesis&lt;/h3&gt;
&lt;details class=&#34;spoiler&#34;&gt;
  &lt;summary&gt;Interface Synthesis for Database Tables&lt;/summary&gt;
  &lt;span style=&#34;display:inline-block;margin-left:1.5em;&#34;&gt;
&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: One central function of low-code programming platforms is to
automatically generate usable interface for manipulating database tables.
In an application, the developers might want to customize a specific way to
organize the interface, and they want to reuse the customization across the
application.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proposal&lt;/strong&gt;: The customization can be thought as a functor that takes a
database-table module as its input and outputs an inference module for that table.
For low-code programming, it would be useful to have a mechanism where
the developers customize a table interactively and the platform automatically
synthesize the code of the customization functor.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Follow-up&lt;/strong&gt;: Low-code programming involves many UI-related customization.
Is there a more general principle? For example, it might be interesting to
investigate &lt;a href=&#34;https://www.cs.cmu.edu/~NatProg/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Natural Programming&lt;/a&gt;.&lt;/p&gt;
  &lt;/span&gt;
&lt;/details&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;Jan Hoffmann and Steffen Jost. Two Decades of Automatic Amortized Resource Analysis. &lt;em&gt;Math. Struct. Comput. Sci.&lt;/em&gt; (2022). &lt;a href=&#34;https://doi.org/10.1017/S0960129521000487&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DOI&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;Vikash K. Mansinghka, Ulrich Schaechtle, Shivam Handa, Alexey Radul, Yutian Chen, and Martin Rinard.
Probabilistic Programming with Programmable Inference. &lt;em&gt;Prog. Lang. Design and Impl.&lt;/em&gt; (2018). &lt;a href=&#34;https://doi.org/10.1145/3192366.3192409&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DOI&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;Zachary Kincaid, Thomas Reps, and John Cyphert. Algebraic Program Analysis. &lt;a href=&#34;https://doi.org/10.1007/978-3-030-81685-8_3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1007/978-3-030-81685-8_3&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;
&lt;p&gt;Javier Esparza, Stefan Kiefer, and Michael Luttenberger. Newtonian Program Analysis. &lt;em&gt;J. ACM&lt;/em&gt; (2010). &lt;a href=&#34;https://doi.org/10.1145/1857914.1857917&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DOI&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref1:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34;&gt;
&lt;p&gt;Kevin Batz, Adrian Gallus, Benjamin Lucien Kaminski, Joost-Pieter Katoen, and Tobias Winkler. Weighted Programming: A Programming Paradigm for Specifying Mathematical Models. &lt;em&gt;Object-Oriented Prog., Syst., Lang., and Applications&lt;/em&gt; (2022). &lt;a href=&#34;https://doi.org/10.1145/3527310&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DOI&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34;&gt;
&lt;p&gt;Akash Lal, Tayssir Touili, Nicholas Kidd, and Thomas Reps. Interprocedural Analysis of Concurrent Programs Under a Context Bound. &lt;em&gt;Tools and Algor. for the Constr. and Anal. of Syst.&lt;/em&gt; (2008). &lt;a href=&#34;https://doi.org/10.1007/978-3-540-78800-3_20&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DOI&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:7&#34;&gt;
&lt;p&gt;Thomas Reps, Emma Turetsky, and  Prathmesh Prabhu. Newtonian Program Analysis via Tensor Product. &lt;em&gt;Princ. of Prog. Lang.&lt;/em&gt; (2016). &lt;a href=&#34;https://doi.org/10.1145/2837614.2837659&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DOI&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:7&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:8&#34;&gt;
&lt;p&gt;Mingshuai Chen, Joost-Pieter Katoen, Lutz Klinkenberg, and Tobias Winkler. Does a Program Yield the Right Distribution?. &lt;em&gt;Computer Aided Verif.&lt;/em&gt; (2022). &lt;a href=&#34;https://doi.org/10.1007/978-3-031-13185-1_5&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DOI&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:8&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:9&#34;&gt;
&lt;p&gt;Matthew Might, Yannis Smaragdakis, and David Van Horn. Resolving and Exploiting the $k$-CFA Paradox: Illuminating Functional vs. Object-Oriented Program Analysis. &lt;em&gt;Prog. Lang. Design and Impl.&lt;/em&gt; (2010). &lt;a href=&#34;https://doi.org/10.1145/1806596.1806631&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DOI&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:9&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:10&#34;&gt;
&lt;p&gt;Raven Beutner, Luke Ong, and Fabian Zaiser. Guaranteed Bounds for Posterior Inference in Universal Probabilistic Programming. &lt;em&gt;Prog. Lang. Design and Impl.&lt;/em&gt; (2022). &lt;a href=&#34;https://doi.org/10.1145/3519939.3523721&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DOI&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:10&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:11&#34;&gt;
&lt;p&gt;Marcel Hark, Benjamin Lucien Kaminski, Jürgen Giesl, and Joost-Pieter Katoen. Aiming Low Is Harder: Induction for Lower Bounds in Probabilistic Program Verification. &lt;em&gt;Princ. of Prog. Lang.&lt;/em&gt; (2020). &lt;a href=&#34;https://doi.org/10.1145/3371105&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DOI&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:11&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:12&#34;&gt;
&lt;p&gt;Daniel J. Fremont, Tommaso Dreossi, Shromona Ghosh, Xiangyu Yue, Alberto L. Sangiovanni-Vincentelli, and Sanjit A. Seshia. Scenic: A Language for Scenario Specification and Scene Generation. &lt;em&gt;Prog. Lang. Design and Impl.&lt;/em&gt; (2019). &lt;a href=&#34;https://doi.org/10.1145/3314221.3314633&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DOI&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:12&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:13&#34;&gt;
&lt;p&gt;Tejas D. Kulkarni, Pushmeet Kohli, Joshua B. Tenenbaum, and Vikash Mansinghka. Picture: A Probabilistic Programming Language for Scene Perception. &lt;em&gt;Comp. Vision and Pattern Recognition&lt;/em&gt; (2015). &lt;a href=&#34;https://doi.org/10.1109/CVPR.2015.7299068&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DOI&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:13&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:14&#34;&gt;
&lt;p&gt;Marco Cusumano-Towner, Alexander K. Lew, and Vikash K. Mansinghka. Automating Involutive MCMC using Probabilistic and
Differentiable Programming. &lt;a href=&#34;https://arxiv.org/abs/2007.09871&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:14&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
