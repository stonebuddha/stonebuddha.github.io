[{"authors":null,"categories":null,"content":"I am a final-year doctoral student in computer science at Carnegie Mellon University. I am advised by Prof. Jan Hoffmann. My research focuses are programming languages, quantitative verification, and probabilistic programming; my broader interests include type theory, program synthesis, concurrency, and Bayesian inference.\nI completed my undergraduate at Peking University, China where I worked with Prof. Yingfei Xiong on summarization techniques to analyze programs sharing big libraries.\n  Here is my Curriculum Vitae.\nNews  I am on the academic job market for 2022 positions. Please reach out to me if you think I would be a good fit for your department. I’m excited that our papers Sound Probabilistic Inference via Guide Types and Central Moment Analysis for Cost Accumulators in Probabilistic Programs with Jan and Tom have been conditionally accepted to PLDI 2021. Our technical report about Probabilistic Resource-Aware Session Types is available on arXiv. Our articles Liquid Resource Types and Raising Expectations: Automating Expected Cost Analysis with Types have been accepted to ICFP 2020. Check out our recent MFPS paper on A Denotational Semantics for Low-Level Probabilistic Programs with Nondeterminism with Jan and Tom. Great news: Our paper on Resource-Guided Program Synthesis has been conditionally accepted to PLDI 2019. I’m excited that our paper Type-Guided Worst-Case Input Generation with Jan Hoffmann has benn accepted to POPL 2019. Check out my talent show Chengdu on SCS Day 2018! I’m excited that our paper PMAF: An Algebraic Framework for Static Analysis of Probabilistic Programs (with Jan Hoffmann and Tom Reps) has been conditionally accepted to PLDI 2018.  ","date":1624147200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1631577600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a final-year doctoral student in computer science at Carnegie Mellon University. I am advised by Prof. Jan Hoffmann. My research focuses are programming languages, quantitative verification, and probabilistic programming; my broader interests include type theory, program synthesis, concurrency, and Bayesian inference.","tags":null,"title":"Di Wang","type":"authors"},{"authors":["Di Wang","Jan Hoffmann","Thomas Reps"],"categories":[],"content":"","date":1624147200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624147200,"objectID":"45117ebf3164126815c2285cafe7bc4a","permalink":"https://stonebuddha.github.io/publication/wanghr21a/","publishdate":"2021-09-15T11:30:37+08:00","relpermalink":"/publication/wanghr21a/","section":"publication","summary":"For probabilistic programs, it is usually not possible to automatically derive exact information about their properties, such as the distribution of states at a given program point. Instead, one can attempt to derive approximations, such as upper bounds on *tail probabilities*. Such bounds can be obtained via concentration inequalities, which rely on the *moments* of a distribution, such as the expectation (the first *raw* moment) or the variance (the second *central* moment). Tail bounds obtained using central moments are often tighter than the ones obtained using raw moments, but automatically analyzing central moments is more challenging.\n\nThis paper presents an analysis for probabilistic programs that automatically derives symbolic upper and lower bounds on variances, as well as higher central moments, of *cost accumulators*. To overcome the challenges of higher-moment analysis, it generalizes analyses for expectations with an algebraic abstraction that simultaneously analyzes different moments, utilizing relations between them. A key innovation is the notion of *moment-polymorphic recursion*, and a practical derivation system that handles recursive functions.\n\nThe analysis has been implemented using a template-based technique that reduces the inference of polynomial bounds to linear programming. Experiments with our prototype central-moment analyzer show that, despite the analyzer's upper/lower bounds on various quantities, it obtains tighter tail bounds than an existing system that uses only raw moments, such as expectations.","tags":[],"title":"Central Moment Analysis for Cost Accumulators in Probabilistic Programs","type":"publication"},{"authors":["Di Wang","Jan Hoffmann","Thomas Reps"],"categories":[],"content":"","date":1624147200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624147200,"objectID":"1c9c209b3c8ad03bd0f0d48a6fa71e7c","permalink":"https://stonebuddha.github.io/publication/wanghr21b/","publishdate":"2021-09-15T11:52:24+08:00","relpermalink":"/publication/wanghr21b/","section":"publication","summary":"Probabilistic programming languages aim to describe and automate Bayesian modeling and inference. Modern languages support programmable inference, which allows users to customize inference algorithms by incorporating guide programs to improve inference performance. For Bayesian inference to be sound, guide programs must be compatible with model programs. One pervasive but challenging condition for model-guide compatibility is absolute continuity, which requires that the model and guide programs define probability distributions with the same support.\n\nThis paper presents a new probabilistic programming language that guarantees absolute continuity, and features general programming constructs, such as branching and recursion. Model and guide programs are implemented as coroutines that communicate with each other to synchronize the set of random variables they sample during their execution. Novel guide types describe and enforce communication protocols between coroutines. If the model and guide are well-typed using the same protocol, then they are guaranteed to enjoy absolute continuity. An efficient algorithm infers guide types from code so that users do not have to specify the types. The new programming language is evaluated with an implementation that includes the type-inference algorithm and a prototype compiler that targets Pyro. Experiments show that our language is capable of expressing a variety of probabilistic models with nontrivial control flow and recursion, and that the coroutine-based computation does not introduce significant overhead in actual Bayesian inference.","tags":[],"title":"Sound Probabilistic Inference via Guide Types","type":"publication"},{"authors":[],"categories":null,"content":"","date":1622728800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622728800,"objectID":"489a1a204bcc141119494b1b9fb94799","permalink":"https://stonebuddha.github.io/talk/type-guided-worst-case-input-generation/","publishdate":"2021-09-15T13:03:52+08:00","relpermalink":"/talk/type-guided-worst-case-input-generation/","section":"event","summary":"","tags":[],"title":"Type-Guided Worst-Case Input Generation","type":"event"},{"authors":["Di Wang","Jan Hoffmann","Thomas Reps"],"categories":[],"content":"","date":1617062400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617062400,"objectID":"d76ecb80d763b2564b46315aae241e97","permalink":"https://stonebuddha.github.io/publication/wanghr21c/","publishdate":"2021-09-15T11:57:39+08:00","relpermalink":"/publication/wanghr21c/","section":"publication","summary":"In this article, we present a semantics-level adaption of the Optional Stopping Theorem, sketch an expected-cost analysis as its application, and survey different variants of the Optional Stopping Theorem that have been used in static analysis of probabilistic programs.","tags":[],"title":"Expected-Cost Analysis for Probabilistic Programs and Semantics-Level Adaption of Optional Stopping Theorems","type":"publication"},{"authors":["Di Wang"],"categories":["Math"],"content":"In this post, we consider one-dimensional random walks: assume that $S_n = \\sum_{i=1}^n X_i$ is a random walk on the integers with initial value $S_0 = 0$, where $X_i, i \\in \\mathbb{N}$ are independent and identically distributed random variables. For termination analysis, we introduce a stopping time: a nonnegative integer-valued random variable $T$ such that for every integer $n \\ge 0$, the indicator function of the event $\\lbrace T = n \\rbrace$ is a function of $S_1,S_2,\\cdots,S_n$.\nSymmetric Random Walk For each $i \\in \\mathbb{N}$, we consider $X_i = \\left\\lbrace \\begin{array}{ll} 1 \u0026amp; \\text{with prob.}~0.5 \\\\ -1 \u0026amp; \\text{with prob.}~0.5 \\end{array} \\right.$. Symmetric random walks are known to be recurrent, i.e., with probability one, any state is visited infinitely often. Let us consider the case where the random walk terminates when it reaches the level $1$, i.e., $T := \\min\\lbrace n \\ge 0 : S_n = 1 \\rbrace$, and $T$ is clearly a stopping time. How do we establish the recurrence property for $T$, i.e., $\\mathbb{P}[T \u0026lt; \\infty] = 1$? Moreover, what can we say about $\\mathbb{E}[T]$?\nOne method is to derive $T$’s probability generating function $G(z) := \\mathbb{E}[z^T] = \\sum_{n=0}^{\\infty} z^n \\mathbb{P}[T=n]$, which is defined for all real values of $z$ less than $1$ in absolute value. The strategy for the derivation is to condition on the first step of the random walk to obtain a functional equation for $G$; there are two possibilities:\n if $X_1 = 1$, then $S_1 = 1$ and $T = 1$; or if $X_1 = -1$, then $S_1 = -1$, and the random walk must first return to the origin, and the amount of time it takes to reach $0$ starting from $-1$ has the same distribution as—and is conditionally independent of—$T$ itself (i.e., the amount of time to reach $1$ from $0$).  Thus, $G(z) = 0.5z + 0.5z \\cdot G(z) \\cdot G(z) = (z + zG(z)^2) / 2$. This is a functional equation, whose solution is $G(z) = (1 \\pm \\sqrt{1 - z^2})/z$. Moreover, observing that $G(z)$ takes values between 0 and 1 when $z \\in (0,1)$, we obtain the unique solution $G(z) = (1 - \\sqrt{1- z ^2})/z$.\nThen, by the monotone convergence theorem, we have $$ \\mathbb{P}[T \u0026lt; \\infty] = \\sum_{n=0}^\\infty \\mathbb{P}[T = n] = \\lim_{z \\to 1^-} G(z) = 1. $$ Similarly, noting that $G’(z) = \\sum_{n=1}^{\\infty} n z^{n-1} \\mathbb{P}[T=n]$, we can express $\\mathbb{E}[T]$ as $G’(1^-)$. Because $G’(z) = (-1 + 1/\\sqrt{1 - z^2})/z^2$, we have $\\mathbb{E}[T] = G’(1^-) = \\infty$, i.e., the expected termination time is infinity.\nGambler’s Ruin Let us consider another termination criterion for symmetric random walks: it is set up so that Alice and Bob bet one dollar against each other on the results of a fair coin flip until one play runs out of money. Suppose that Alice starts with $A$ dollars and Bob starts with $B$ dollars. We define a termination time to model the gamble: $T := \\min\\lbrace n \\ge 0: S_n = -A \\vee S_n = B\\rbrace$, which is clearly a stopping time. By a similar argument, we can show both $\\mathbb{P}[T_A \u0026lt; \\infty] = 1$ where $T_A := \\min\\lbrace n \\ge 0: S_n = -A \\rbrace$, and $\\mathbb{P}[T_B \u0026lt; \\infty] = 1$ where $T_B := \\min\\lbrace n \\ge 0: S_n = B\\rbrace$. Thus, we know that $\\mathbb{P}[T \u0026lt; \\infty] = 1$ as $T = \\min(T_A,T_B)$. But what about $\\mathbb{E}[T]$ in this case?\nWe use another technique called Wald identities, two of which have the form below in a random-walk setting:\n If the step distribution has a finite first moment and the stopping time has a finite expectation, then $\\mathbb{E}[S_T] = \\mathbb{E}[X_1]\\mathbb{E}[T]$. If the step distribution has a finite second moment and the stopping time has a finite expectation, then $\\mathbb{E}[(S_T-\\mathbb{E}[X_1]T)^2]=\\mathbb{E}[(X_1-\\mathbb{E}[X_1])^2]\\mathbb{E}[T]$.  Let us assume $\\mathbb{E}[T] \u0026lt; \\infty$ first. By the definition of $X_1$, we know that $\\mathbb{E}[X_1] = 0$ and $\\mathbb{E}[X_1^2]=1$. By the first Wald identity, we have $\\mathbb{E}[S_T]=0$. The random variable $S_T$ takes only two values, $-A$ and $B$, with probabilities $u$ and $1-u$ such that $u \\cdot (-A) + (1-u) \\cdot B = 0 \\implies u = B/(A+B)$. By the second Wald identity, we know that $\\mathbb{E}[S_T^2]=\\mathbb{E}[T]$. Thus, we can compute $\\mathbb{E}[T]$ from $S_T$’s distribution: $ \\frac{B}{A+B} \\cdot (-A)^2 + \\frac{A}{A+B} \\cdot B^2 = A \\cdot B$.\nTo show $\\mathbb{E}[T] \u0026lt; \\infty$ at the first place, we observe that if at any time during the gamble Alice wins consecutive $A+B$ rounds, then Bob must run out of money and the gamble must terminate. Thus, $$ \\mathbb{P}[T \u0026gt; k(A+B)] \\le (1 - \\frac{1}{2^{A+B}})^k, $$ and $\\mathbb{E}[T] \\le \\sum_{k=0}^\\infty (A+B)(1-\\frac{1}{2^{A+B}})^k \u0026lt; \\infty$.\nAsymmetric Random Walk (Uneven Steps) For each $i \\in \\mathbb{N}$, we consider $X_i = \\left\\lbrace \\begin{array}{ll} 2 \u0026amp; \\text{with prob.}~0.5 \\\\ -1 \u0026amp; \\text{with prob.}~0.5 \\end{array} \\right.$. For the termination criterion, we define $T(m) := \\min\\lbrace n \\ge 0 : S_n \\ge m\\rbrace$ for any positive integer $m$. Let us fixed an $m$ and write $T = T(m)$. …","date":1613347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1631577600,"objectID":"56ec80e9a94396e230a2275c9f568763","permalink":"https://stonebuddha.github.io/post/termination-analysis-of-random-walks/","publishdate":"2021-02-15T00:00:00Z","relpermalink":"/post/termination-analysis-of-random-walks/","section":"post","summary":"In this post, we consider one-dimensional random walks: assume that $S_n = \\sum_{i=1}^n X_i$ is a random walk on the integers with initial value $S_0 = 0$, where $X_i, i \\in \\mathbb{N}$ are independent and identically distributed random variables.","tags":[],"title":"Termination Analysis of Random Walks","type":"post"},{"authors":["Ankush Das","Di Wang","Jan Hoffmann"],"categories":[],"content":"","date":1605657600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605657600,"objectID":"8deb610d0733a99572c20e9e29f16a89","permalink":"https://stonebuddha.github.io/publication/daswh20/","publishdate":"2021-09-15T12:10:30+08:00","relpermalink":"/publication/daswh20/","section":"publication","summary":"Session types guarantee that message-passing processes adhere to predefined communication protocols. Prior work on session types has focused on deterministic languages but many message-passing systems, such as Markov chains and randomized distributed algorithms, are probabilistic. To model and analyze such systems, this article introduces probabilistic session types and explores their application in automatic expected resource analysis. Probabilistic session types describe probability distributions over messages and are a conservative extension of intuitionistic (binary) session types. To send on a probabilistic channel, processes have to utilize internal randomness from a probabilistic branching expression or external randomness from receiving on a probabilistic channel. The analysis for expected resource bounds is integrated with the type system and is a variant of automatic amortized resource analysis. It can automatically derive symbolic bounds for different cost metrics by reducing type inference to linear constraint solving. The technical contributions include the meta theory that is based on a novel nested multiverse semantics and a type-reconstruction algorithm that allows flexible mixing of different sources of randomness without burdening the programmer with type annotations. The type system has been implemented in the language PRast. Experiments demonstrate that PRast is applicable in different domains such as resource analysis of randomized distributed algorithms, verification of limiting distributions in Markov chains, and analysis of probabilistic digital contracts.","tags":[],"title":"Probabilistic Resource-Aware Session Types","type":"publication"},{"authors":[],"categories":null,"content":"","date":1602864000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602864000,"objectID":"f2f943e9b90569b648b57b0e28659d20","permalink":"https://stonebuddha.github.io/talk/type-based-resource-guided-search/","publishdate":"2021-09-15T13:03:49+08:00","relpermalink":"/talk/type-based-resource-guided-search/","section":"event","summary":"","tags":[],"title":"Type-Based Resource-Guided Search","type":"event"},{"authors":["Tristan Knoth","Di Wang","Adam Reynolds","Jan Hoffmann","Nadia Polikarpova"],"categories":[],"content":"","date":1598140800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598140800,"objectID":"891908906372a09b354db8d1cdbd4ad8","permalink":"https://stonebuddha.github.io/publication/knothwr20/","publishdate":"2021-09-15T12:13:40+08:00","relpermalink":"/publication/knothwr20/","section":"publication","summary":"This article presents *liquid resource types*, a technique for automatically verifying the resource consumption of functional programs. Existing resource analysis techniques trade automation for flexibility -- automated techniques are restricted to relatively constrained families of resource bounds, while more expressive proof techniques admitting value-dependent bounds rely on handwritten proofs. Liquid resource types combine the best of these approaches, using logical refinements to automatically prove precise bounds on a program's resource consumption. The type system augments refinement types with potential annotations to conduct an amortized resource analysis. Importantly, users can annotate data structure declarations to indicate how potential is allocated within the type, allowing the system to express bounds with polynomials and exponentials, as well as more precise expressions depending on program values. We prove the soundness of the type system, provide a library of flexible and reusable data structures for conducting resource analysis, and use our prototype implementation to automatically verify resource bounds that previously required a manual proof.","tags":[],"title":"Liquid Resource Types","type":"publication"},{"authors":["Di Wang","David M. Kahn","Jan Hoffmann"],"categories":[],"content":"","date":1598140800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598140800,"objectID":"e9891938a37fd75956d111600c8d43d4","permalink":"https://stonebuddha.github.io/publication/wangkh20/","publishdate":"2021-09-15T12:17:33+08:00","relpermalink":"/publication/wangkh20/","section":"publication","summary":"This article presents a type-based analysis for deriving upper bounds on the expected execution cost of probabilistic programs. The analysis is naturally compositional, parametric in the cost model, and supports higher-order functions and inductive data types. The derived bounds are multivariate polynomials that are functions of data structures. Bound inference is enabled by local type rules that reduce type inference to linear constraint solving. The type system is based on the potential method of amortized analysis and extends automatic amortized resource analysis (AARA) for deterministic programs. A main innovation is that bounds can contain symbolic probabilities, which may appear in data structures and function arguments. Another contribution is a novel soundness proof that establishes the correctness of the derived bounds with respect to a distribution-based operational cost semantics that also includes nontrivial diverging behavior. For cost models like time, derived bounds imply termination with probability one. To highlight the novel ideas, the presentation focuses on linear potential and a core language. However, the analysis is implemented as an extension of Resource Aware ML and supports polynomial bounds and user defined data structures. The effectiveness of the technique is evaluated by analyzing the sample complexity of discrete distributions and with a novel average-case estimation for deterministic programs that combines expected cost analysis with statistical methods.","tags":[],"title":"Raising Expectations: Automating Expected Cost Analysis with Types","type":"publication"},{"authors":[],"categories":null,"content":"","date":1574442000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574442000,"objectID":"1f9966125b237ccbe96f2d654aaff7d6","permalink":"https://stonebuddha.github.io/talk/resource-guided-program-synthesis/","publishdate":"2021-09-15T13:03:42+08:00","relpermalink":"/talk/resource-guided-program-synthesis/","section":"event","summary":"","tags":[],"title":"Resource-Guided Program Synthesis","type":"event"},{"authors":["Tristan Knoth","Di Wang","Nadia Polikarpova","Jan Hoffmann"],"categories":[],"content":"","date":1561161600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561161600,"objectID":"8c9817600be722a6272fb40bfcf9933c","permalink":"https://stonebuddha.github.io/publication/knothwp19/","publishdate":"2021-09-15T12:22:06+08:00","relpermalink":"/publication/knothwp19/","section":"publication","summary":"This article presents resource-guided synthesis, a technique for synthesizing recursive programs that satisfy both a functional specification and a symbolic resource bound. The technique is type-directed and rests upon a novel type system that combines polymorphic refinement types with potential annotations of automatic amortized resource analysis. The type system enables efficient constraint-based type checking and can express precise refinement-based resource bounds. The proof of type soundness shows that synthesized programs are correct by construction. By tightly integrating program exploration and type checking, the synthesizer can leverage the user-provided resource bound to guide the search, eagerly rejecting incomplete programs that consume too many resources. An implementation in the resource-guided synthesizer ReSyn is used to evaluate the technique on a range of recursive data structure manipulations. The experiments show that ReSyn synthesizes programs that are asymptotically more efficient than those generated by a resource-agnostic synthesizer. Moreover, synthesis with ReSyn is faster than a naive combination of synthesis and resource analysis. ReSyn is also able to generate implementations that have a constant resource consumption for fixed input sizes, which can be used to mitigate side-channel attacks.","tags":[],"title":"Resource-Guided Program Synthesis","type":"publication"},{"authors":["Di Wang","Jan Hoffmann","Thomas Reps"],"categories":[],"content":"","date":1559520000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559520000,"objectID":"8c71245de524557a2fffb8e48e7fe3ca","permalink":"https://stonebuddha.github.io/publication/wanghr19/","publishdate":"2021-09-15T12:25:42+08:00","relpermalink":"/publication/wanghr19/","section":"publication","summary":"Probabilistic programming is an increasingly popular formalism for modeling randomness and uncertainty. Designing semantic models for probabilistic programs has been extensively studied, but is technically challenging. Particular complications arise when trying to account for (i) unstructured control-flow, a natural feature in low-level imperative programs; (ii) general recursion, an extensively used programming paradigm; and (iii) nondeterminism, which is often used to represent adversarial actions in probabilistic models, and to support refinement-based development. This paper presents a denotational-semantics framework that supports the three features mentioned above, while allowing nondeterminism to be handled in different ways. To support both probabilistic choice and nondeterministic choice, the semantics is given over control-flow *hyper*-graphs. The semantics follows an *algebraic* approach: it can be instantiated in different ways as long as certain algebraic properties hold. In particular, the semantics can be instantiated to support nondeterminism among either *program states* or *state transformers*. We develop a new formalization of nondeterminism based on *powerdomains* over *sub-probability kernels*. Semantic objects in the powerdomain enjoy a notion we call *generalized convexity*, which is a generalization of convexity. As an application, the paper studies the semantic foundations of an algebraic framework for static analysis of probabilistic programs.","tags":[],"title":"A Denotational Semantics for Low-Level Probabilistic Programs with Nondeterminism","type":"publication"},{"authors":["Di Wang","Jan Hoffmann"],"categories":[],"content":"","date":1547337600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1547337600,"objectID":"696798cbada90d27d9db5c1f6b017964","permalink":"https://stonebuddha.github.io/publication/wangh19/","publishdate":"2021-09-15T12:28:43+08:00","relpermalink":"/publication/wangh19/","section":"publication","summary":"This paper presents a novel technique for type-guided worst-case input generation for functional programs. The technique builds on automatic amortized resource analysis (AARA), a type-based technique for deriving symbolic bounds on the resource usage of functions. Worst-case input generation is performed by an algorithm that takes as input a function, its resource-annotated type derivation in AARA, and a skeleton that describes the shape and size of the input that is to be generated. If successful, the algorithm fills in integers, booleans, and data structures to produce a value of the shape given by the skeleton. The soundness theorem states that the generated value exhibits the highest cost among all arguments of the functions that have the shape of the skeleton. This cost corresponds exactly to the worst-case bound that is established by the type derivation. In this way, a successful completion of the algorithm proves that the bound is tight for inputs of the given shape. Correspondingly, a relative completeness theorem is proved to show that the algorithm succeeds if and only if the derived worst-case bound is tight. The theorem is relative because it depends on a decision procedure for constraint solving. The technical development is presented for a simple first-order language with linear resource bounds. However, the technique scales to and has been implemented for Resource Aware ML, an implementation of AARA for a fragment of OCaml with higher-order functions, user-defined data types, and types for polynomial bounds. Experiments demonstrate that the technique works effectively and can derive worst-case inputs with hundreds of integers for sorting algorithms, operations on search trees, and insertions into hash tables.","tags":[],"title":"Type-Guided Worst-Case Input Generation","type":"publication"},{"authors":["Di Wang"],"categories":["Problem Solving"],"content":"Problem link: Counting Road Networks | HackerRank.\nYou are supposed to count the number of connected undirected labeled graphs with $n$ vertices. Algorithms with $O(n \\log^2 n)$ time complexity are preferable.\nA Dynamic-Programming Algorithm Let $f(n)$ be the answer for $n$. The first idea to compute $f(n)$ is subtracting the number of disconnected graphs from the total number. The total number of size-$n$ graphs is $g(n) := 2^{\\binom{n}{2}}$. How to count the disconnected graphs? Let’s consider the size $m$ of the connected component containing the vertex labeled with 1. Since the graph is disconnected, $m$ cannot be $n$. Then the number of disconnected graphs where the connected component containing vertex 1 is a certain one with size $m$ is exactly $f(m) \\cdot g(n-m)$. Now we have an $O(n^2)$-time dynamic-programming algorithm as follows. $$ f(n) = g(n) - \\sum_{m=1}^{n-1} \\binom{n-1}{m-1} \\cdot f(m) \\cdot g(n - m) $$\nExpression Rearrangement If we unfold the binomial coefficients, we will have $$ \\frac{f(n)}{(n-1)!} = n \\cdot \\frac{g(n)}{n!} - \\sum_{m=1}^{n-1} \\frac{f(m)}{(m-1)!} \\cdot \\frac{g(n-m)}{(n-m)!} $$ Let $F(n) := \\frac{f(n)}{(n-1)!}$ and $G(n) := \\frac{g(n)}{n!}$. Moreover, let’s set $F(0)$ to $0$ and then we have $$ F(n) = n \\cdot G(n) - \\sum_{m=0}^{n-1} F(m) \\cdot G(n-m) $$ Note that we already have a convolution-like term in the formula.\nAn Optimization Based on FFT We will use Fast Fourier transform (FFT) as an $O(n \\log n)$-time algorithm to compute convolution of length $n$.\nFirst of all, $G(n)$ are easy to compute so we can pre-process them. Now we are going to use a divide-and-conquer scheme. Let $solve(l,r)$ be a procedure that computes $F(n)$ for all $n \\in [l,r)$. In addition, we add the following invariant to this procedure:\nWhen invoking $solve(l,r)$, we already compute for each $n \\in [l,r)$, the partial convolution $\\sum_{m=0}^{l-1} F(m) \\cdot G(n-m)$, and store them in $H(n)$.\nThen our algorithm proceeds as follows.\n If $l+1=r$, we set $F(l)$ to $l \\cdot G(l) - H(l)$. Otherwise, let’s invoke $solve(l,k)$ first where $k = \\frac{l+r}{2}$, i.e., the middle point. Now we already solve the first half of the problem. To become able to invoke $solve(k,r)$ to complete the second half, we need to do something to maintain the invariant above. In essence, we need to update $$ H(n) \\gets H(n) + \\sum_{m=l}^{k-1} F(m) \\cdot G(n-m) $$ for each $n \\in [k,r)$. Here comes the chance for optimization. What we really want to compute is the convolution of $F[l,k)$ and $G[0,r-l)$! Let the convolution result be $C$ and indeed we have $$ C(n) = \\sum_{m=l}^{k-1} F(m) \\cdot G(n-m) $$ for each $n \\in [k,r)$. After performing $H(n) \\gets H(n) + C(n)$ for each $n \\in [k,r)$, we reestablish the invariant and we can recurse to $solve(k,r)$.  Finally, let’s estimate the time complexity of the algorithm above. Let $T(n)$ be the running time of $solve(l,r)$ with $n=r-l$. By using FFT to compute the convolution, we can establish the following $$ T(n) = 2T(\\frac{n}{2}) + O(n \\log n) $$ Then by the Master Theorem we derive that $T(n) = O(n \\log^2 n)$.\nWhat’s More For those who could read Chinese, CDQ’s divide-and-conquer is a good reference about applications of the divide-and-conquer scheme in this post.\n","date":1541203200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1541203200,"objectID":"29ccbfdaca3dda2d3b131cf43406a657","permalink":"https://stonebuddha.github.io/post/using-fft-to-speed-up-dp/","publishdate":"2018-11-03T00:00:00Z","relpermalink":"/post/using-fft-to-speed-up-dp/","section":"post","summary":"Problem link: Counting Road Networks | HackerRank.\nYou are supposed to count the number of connected undirected labeled graphs with $n$ vertices. Algorithms with $O(n \\log^2 n)$ time complexity are preferable.","tags":[],"title":"Using FFT to Speed Up DP","type":"post"},{"authors":["Di Wang","Jan Hoffmann","Thomas Reps"],"categories":[],"content":"","date":1529452800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1529452800,"objectID":"101d9e3872d9bfa30a1da294e9e55e81","permalink":"https://stonebuddha.github.io/publication/wanghr18/","publishdate":"2021-09-15T12:31:55+08:00","relpermalink":"/publication/wanghr18/","section":"publication","summary":"Automatically establishing that a probabilistic program satisfies some property $\\varphi$ is a challenging problem. While a sampling-based approach---which involves running the program repeatedly---can *suggest* that $\\varphi$ holds, to establish that the program *satisfies* $\\varphi$, analysis techniques must be used. Despite recent successes, probabilistic static analyses are still more difficult to design and implement than their deterministic counterparts. This paper presents a framework, called *PMAF*, for designing, implementing, and proving the correctness of static analyses of probabilistic programs with challenging features such as recursion, unstructured control-flow, divergence, nondeterminism, and continuous distributions. PMAF introduces *pre-Markov algebras* to factor out common parts of different analyses. To perform *interprocedural analysis* and to create *procedure summaries*, PMAF extends ideas from non-probabilistic interprocedural dataflow analysis to the probabilistic setting. One novelty is that PMAF is based on a semantics formulated in terms of a control-flow *hyper-graph* for each procedure, rather than a standard control-flow graph. To evaluate its effectiveness, PMAF has been used to reformulate and implement existing *intraprocedural* analyses for Bayesian-inference and the Markov decision problem, by creating corresponding *interprocedural* analyses. Additionally, PMAF has been used to implement a new interprocedural *linear expectation-invariant analysis*. Experiments with benchmark programs for the three analyses demonstrate that the approach is practical.","tags":[],"title":"PMAF: An Algebraic Framework for Static Analysis of Probabilistic Programs","type":"publication"},{"authors":[],"categories":null,"content":"","date":1524240000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1524240000,"objectID":"daa36599b1552c0645901e5c699b9fd9","permalink":"https://stonebuddha.github.io/talk/pmaf-an-algebraic-framework-for-static-analysis-of-probabilistic-programs/","publishdate":"2021-09-15T12:58:44+08:00","relpermalink":"/talk/pmaf-an-algebraic-framework-for-static-analysis-of-probabilistic-programs/","section":"event","summary":"","tags":[],"title":"PMAF: An Algebraic Framework for Static Analysis of Probabilistic Programs","type":"event"},{"authors":[],"categories":null,"content":"","date":1518195600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1518195600,"objectID":"310a157f4f49e4d30f2538b522d5e363","permalink":"https://stonebuddha.github.io/talk/timl-a-functional-language-for-practical-complexity-analysis-with-invariants/","publishdate":"2021-09-15T13:03:56+08:00","relpermalink":"/talk/timl-a-functional-language-for-practical-complexity-analysis-with-invariants/","section":"event","summary":"","tags":[],"title":"TiML: A Functional Language for Practical Complexity Analysis with Invariants","type":"event"},{"authors":["Di Wang"],"categories":["Programming"],"content":"Suppose you have a toy specification with built-in nondeterminism, and you want to generate answers with respect to the specification:\ntype exp = EInt of int | EPair of exp * exp | ENdet of exp * exp type ans = VInt of int | VPair of ans * ans For example, from the following specification\nEPair (ENdet (EInt 5) (EInt 6)) (ENdet (EInt 7) (EInt 8)) you might want to generate a bunch of possible answers:\nVPair (VInt 5) (VInt 7) VPair (VInt 5) (VInt 8) VPair (VInt 6) (VInt 7) VPair (VInt 6) (VInt 8) The scene might be where you want to specify something with multiple sites of nondeterminism, ask the generator to come up with an answer, and successively give you other answers until you are satisfied.\nThe basic methodology is search. We want to construct a recursive procedure on the structure of a specification. For a sub-specification, it should know two sorts of computation:\n the computation that completes a whole answer and constructs a procedure for next whole answers, given the current sub-answer for the sub-specification and a procedure for next whole answers if the current sub-answer would leads to a subsequent unsatisfactoriness; and the computation to find next whole answers.  In this sense, the first computation has type $\\mathsf{ans} \\to \\mathsf{next} \\to \\mathsf{ans} \\times \\mathsf{next}$, and the second one should be typed $\\mathsf{next}$. A computation of type $\\mathsf{next}$ is supposed to (i) either fail, or (ii) take no arguments, and when invoked it should return the next whole answer as well as a new $\\mathsf{next}$ computation. Thus we have $\\mathsf{next} \\equiv \\mathbf{1} + \\mathbf{1} \\to (\\mathsf{ans} \\times \\mathsf{next})$. Therefore we use recursive types to model this mechanism.\ntype next = NFail | NCont of (unit -\u0026gt; ans * next) Then it is straightforward to implement an interpreter:\nlet rec interp exp cont fail = match exp with | EInt n -\u0026gt; cont (VInt n) fail | EPair (e, e\u0026#39;) -\u0026gt; interp e (fun v fail\u0026#39; -\u0026gt; interp e\u0026#39; (fun v\u0026#39; fail\u0026#39;\u0026#39; -\u0026gt; cont (VPair (v, v\u0026#39;)) fail\u0026#39;\u0026#39;) fail\u0026#39;) fail | ENdet (e1, e2) -\u0026gt; interp e1 cont (NCont (fun () -\u0026gt; interp e2 cont fail)) The execution should be the following:\nlet (ans1, next1) = interp (EPair (ENdet (EInt 5) (EInt 6)) (ENdet (EInt 7) (EInt 8))) (fun v fail -\u0026gt; (v, fail)) NFail;; (* val ans1 : ans = VPair (VInt 5, VInt 7) *) (* val next1 : next = NCont \u0026lt;fun\u0026gt; *) let (ans2, next2) = match next1 with NCont f -\u0026gt; f ();; (* val ans2 : ans = VPair (VInt 5, VInt 8) *) (* val next2 : next = NCont \u0026lt;fun\u0026gt; *) let (ans3, next3) = match next2 with NCont f -\u0026gt; f ();; (* val ans3 : ans = VPair (VInt 6, VInt 7) *) (* val next3 : next = NCont \u0026lt;fun\u0026gt; *) let (ans4, next4) = match next3 with NCont f -\u0026gt; f ();; (* val ans4 : ans = VPair (VInt 6, VInt 8) *) (* val next4 : next = NFail *) ","date":1518048000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1518048000,"objectID":"bdf032f7d4b3913f7157dc7ec6f50582","permalink":"https://stonebuddha.github.io/post/nondeterministic-interpretation/","publishdate":"2018-02-08T00:00:00Z","relpermalink":"/post/nondeterministic-interpretation/","section":"post","summary":"Suppose you have a toy specification with built-in nondeterminism, and you want to generate answers with respect to the specification:\ntype exp = EInt of int | EPair of exp * exp | ENdet of exp * exp type ans = VInt of int | VPair of ans * ans For example, from the following specification","tags":[],"title":"Nondeterministic Interpretation","type":"post"},{"authors":["Peng Wang","Di Wang","Adam Chlipala"],"categories":[],"content":"","date":1508889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508889600,"objectID":"c6416621277713f368cece0c36217422","permalink":"https://stonebuddha.github.io/publication/wangwc17/","publishdate":"2021-09-15T12:35:14+08:00","relpermalink":"/publication/wangwc17/","section":"publication","summary":"We present TiML (Timed ML), an ML-like functional language with time-complexity annotations in types. It uses indexed types to express sizes of data structures and upper bounds on running time of functions; and refinement kinds to constrain these indices, expressing data-structure invariants and pre/post-conditions. Indexed types are flexible enough that TiML avoids a built-in notion of \"size,\" and the programmer can choose to index user-defined datatypes in any way that helps her analysis. TiML's distinguishing characteristic is supporting highly automated time-bound verification applicable to data structures with nontrivial invariants. The programmer provides type annotations, and the typechecker generates verification conditions that are discharged by an SMT solver. Type and index inference are supported to lower annotation burden, and, furthermore, big-O complexity can be inferred from recurrences generated during typechecking by a recurrence solver based on heuristic pattern matching (e.g. using the Master Theorem to handle divide-and-conquerlike recurrences). We have evaluated TiML's usability by implementing a broad suite of case-study modules, demonstrating that TiML, though lacking full automation and theoretical completeness, is versatile enough to verify worst-case and/or amortized complexities for algorithms and data structures like classic list operations, merge sort, Dijkstra's shortest-path algorithm, red-black trees, Braun trees, functional queues, and dynamic tables with bounds like $mn \\log n$. The learning curve and annotation burden are reasonable, as we argue with empirical results on our case studies. We formalized TiML's type-soundness proof in Coq.","tags":[],"title":"TiML: A Functional Language for Practical Complexity Analysis with Invariants","type":"publication"},{"authors":["Hao Tang","Di Wang","Yingfei Xiong","Lingming Zhang","Xiaoyin Wang","Lu Zhang"],"categories":[],"content":"","date":1492819200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1492819200,"objectID":"f10bc7fc2a07bb729f6242653bbc6924","permalink":"https://stonebuddha.github.io/publication/tangwx17/","publishdate":"2021-09-15T12:35:20+08:00","relpermalink":"/publication/tangwx17/","section":"publication","summary":"Library summarization is an effective way to accelerate the analysis of client code. However, information about the client is unknown at the library summarization, preventing complete summarization of the library. An existing approach utilizes tree-adjoining languages (TALs) to provide conditional summaries, enabling the summarization of a library under certain premises. However, the use of TAL imposes several problems, preventing a complete summarization of a library and reducing the efficiency of the analysis. In this paper we propose a new conditional summarization technique based on the context-free language (CFL) reachability analysis. Our technique overcomes the above two limitations of TAL, and is more accessible since CFL reachability is much more efficient and widely-used than TAL reachability. Furthermore, to overcome the high cost from premise combination, we also provide a technique to confine the number of premises while maintaining full summarization of the library. We empirically compared our approach with the state-of-art TAL conditional summarization technique on 12 Java benchmark subjects from the SPECjvm2008 benchmark suite. The results demonstrate that our approach is able to significantly outperform TAL on both efficiency and precision.","tags":[],"title":"Conditional Dyck-CFL Reachability Analysis for Complete and Efficient Library Summarization","type":"publication"}]