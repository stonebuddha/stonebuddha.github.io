[{"authors":null,"categories":null,"content":"我是北京大学计算机学院的一名助理教授。 我现在是程序设计语言研究室的成员，也是图灵人才培养计划的科研导师。\n我对编程语言的多个研究话题都很有兴趣，尤其是形式化验证、程序分析以及概率编程。 我的目标是构建适用于编写安全、高效的软件的通用、易用的编程抽象和范式，以及能够自动分析、优化、合成程序的编程语言工具链。 我目前的研究项目主要涉及资源安全的系统编程、可编程贝叶斯推断、量化程序分析以及面向证明的编程语言。\n在加入北京大学前，我在卡内基梅隆大学获得博士学位，导师为 Jan Hoffmann 教授。\n这是我的简历。\n新闻 欢迎对编程语言领域感兴趣的学生联系我！我在这里概述了我的一些研究想法。 [Jun 2024] Programmable MCMC with Soundly Composed Guide Programs 和 Semantics Lifting for Syntactic Sugar 被 OOPSLA 2024 条件接收。 [Jun 2024] Formalizing, Mechanizing, and Verifying Class-based Refinement Types 被 ECOOP 2024 接收。 [Jan 2024] Decomposition-Based Synthesis for Applying D\u0026amp;C-Like Algorithmic Paradigms 被 TOPLAS 接收。 [Dec 2023] Newtonian Program Analysis of Probabilistic Programs 被 OOPSLA 2024 接收。 [Sep 2023] 我将担任 PLDI 2024 程序委员会成员。 [July 2023] 预印本 Newtonian Program Analysis of Probabilistic Programs 已上传至 arXiv。 [May 2023] 我将担任 OOPSLA 2024 审稿委员会成员。 [May 2023] 我将担任 ASE 2023 程序委员会成员。 [Sep 2022] Probabilistic Resource-Aware Session Types 被 POPL 2023 接收。 [May 2022] 我完成了博士学位答辩。我的博士论文为 Static Analysis of Probabilistic Programs: An Algebraic Approach。 老新闻归档至此处。\n课程 2024 春： 编译原理（与张路、刘先华老师合上） 编程语言的设计原理（与赵海燕老师合上） 2023 秋：编译原理（与张路、刘先华老师合上） 2023 春：编程语言的设计原理（与赵海燕老师合上） 服务 程序/审稿委员会： 2024: OOPSLA 2024. PLDI 2024. 2023: ASE 2023. ","date":1711497600,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":1711497600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"我是北京大学计算机学院的一名助理教授。 我现在是程序设计语言研","tags":null,"title":"王迪","type":"authors"},{"authors":["王迪","Thomas Reps"],"categories":[],"content":"","date":1711497600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1711497600,"objectID":"5ffc3742307b6922e401d2d2026c2019","permalink":"https://stonebuddha.github.io/zh/publication/wangr24/","publishdate":"2023-07-29T11:57:39+08:00","relpermalink":"/zh/publication/wangr24/","section":"publication","summary":"Due to their *quantitative* nature, probabilistic programs pose non-trivial challenges for designing compositional and efficient program analyses. Many analyses for probabilistic programs rely on *iterative* approximation. This article presents an interprocedural dataflow-analysis framework, called *NPA-PMA*, for designing and implementing (partially) *non-iterative* program analyses of probabilistic programs with unstructured control-flow, nondeterminism, and general recursion. NPA-PMA is based on Newtonian Program Analysis (NPA), a generalization of Newton's method to solve equation systems over semirings. The key challenge for developing NPA-PMA is to handle multiple kinds of *confluences* in both the algebraic structures that specify analyses and the equation systems that encode control flow: semirings support a single confluence operation, whereas NPA-PMA involves three confluence operations (conditional, probabilistic, and nondeterministic).\n\n Our work introduces *$\\omega$-continuous pre-Markov algebras* ( $\\omega$PMAs) to factor out common parts of different analyses; adopts *regular infinite-tree expressions* to encode program-execution paths in control-flow hyper-graphs; and presents a *linearization* method that makes Newton's method applicable to the setting of regular-infinite-tree equations over $\\omega$PMAs. NPA-PMA allows analyses to supply a non-iterative strategy to solve linearized equations. Our experimental evaluation demonstrates that (i) NPA-PMA holds considerable promise for outperforming Kleene iteration, and (ii) provides great generality for designing program analyses.","tags":[],"title":"Newtonian Program Analysis of Probabilistic Programs","type":"publication"},{"authors":["Ruyi Ji","Yuwei Zhao","Yingfei Xiong","王迪","Lu Zhang","Zhenjiang Hu"],"categories":[],"content":"","date":1707868800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1707868800,"objectID":"08d77cabf366c3afae89ffe2f4f168bd","permalink":"https://stonebuddha.github.io/zh/publication/jizx24/","publishdate":"2024-04-08T19:16:00+08:00","relpermalink":"/zh/publication/jizx24/","section":"publication","summary":"Algorithmic paradigms such as divide-and-conquer (D\u0026C) are proposed to guide developers in designing efficient algorithms, but it can still be difficult to apply algorithmic paradigms to practical tasks. To ease the usage of paradigms, many research efforts have been devoted to the automatic application of algorithmic paradigms. However, most existing approaches to this problem rely on syntax-based program transformations and thus put significant restrictions on the original program.\n\nIn this paper, we study the automatic application of D\u0026C and several similar paradigms, denoted as D\u0026C-like algorithmic paradigms, and aim to remove the restrictions from syntax-based transformations. To achieve this goal, we propose an efficient synthesizer, named *AutoLifter*, which does not depend on syntax-based transformations. Specifically, the main challenge of applying algorithmic paradigms is from the large scale of the synthesized programs, and *AutoLifter* addresses this challenge by applying two novel decomposition methods that do not depend on the syntax of the input program, *component elimination* and *variable elimination*, to soundly divide the whole problem into simpler subtasks, each synthesizing a sub-program of the final program and being tractable with existing synthesizers.\n\nWe evaluate *AutoLifter* on 96 programming tasks related to 6 different algorithmic paradigms. *AutoLifter* solves 82/96 tasks with an average time cost of 20.17 seconds, significantly outperforming existing approaches.","tags":[],"title":"Decomposition-Based Synthesis for Applying Divide-and-Conquer-Like Algorithmic Paradigms","type":"publication"},{"authors":[],"categories":null,"content":"","date":1702711800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1702711800,"objectID":"fa16a28790cdd017ae3d24b247b2f5b4","permalink":"https://stonebuddha.github.io/zh/talk/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E6%96%B0%E8%8C%83%E5%BC%8F%E5%88%9D%E6%8E%A2/","publishdate":"2021-09-15T13:03:52+08:00","relpermalink":"/zh/talk/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E6%96%B0%E8%8C%83%E5%BC%8F%E5%88%9D%E6%8E%A2/","section":"event","summary":"","tags":[],"title":"编程语言新范式初探","type":"event"},{"authors":[],"categories":null,"content":"","date":1701498900,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1701498900,"objectID":"765abdecc53cf8a2f994e17fbb3861ff","permalink":"https://stonebuddha.github.io/zh/talk/%E6%A6%82%E7%8E%87%E7%A8%8B%E5%BA%8F%E7%9A%84%E4%BB%A3%E6%95%B0%E7%A8%8B%E5%BA%8F%E5%88%86%E6%9E%90%E6%96%B0/","publishdate":"2021-09-15T13:03:52+08:00","relpermalink":"/zh/talk/%E6%A6%82%E7%8E%87%E7%A8%8B%E5%BA%8F%E7%9A%84%E4%BB%A3%E6%95%B0%E7%A8%8B%E5%BA%8F%E5%88%86%E6%9E%90%E6%96%B0/","section":"event","summary":"","tags":[],"title":"概率程序的代数程序分析（新）","type":"event"},{"authors":[],"categories":null,"content":"","date":1688109300,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1688109300,"objectID":"f68eea62dd4f14e81648ade062d1c403","permalink":"https://stonebuddha.github.io/zh/talk/%E6%A6%82%E7%8E%87%E7%A8%8B%E5%BA%8F%E7%9A%84%E4%BB%A3%E6%95%B0%E7%A8%8B%E5%BA%8F%E5%88%86%E6%9E%90/","publishdate":"2021-09-15T13:03:52+08:00","relpermalink":"/zh/talk/%E6%A6%82%E7%8E%87%E7%A8%8B%E5%BA%8F%E7%9A%84%E4%BB%A3%E6%95%B0%E7%A8%8B%E5%BA%8F%E5%88%86%E6%9E%90/","section":"event","summary":"","tags":[],"title":"概率程序的代数程序分析","type":"event"},{"authors":[],"categories":null,"content":"","date":1686963600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1686963600,"objectID":"452b33a14972661ab07d589c079ff25b","permalink":"https://stonebuddha.github.io/zh/talk/%E7%B1%BB%E5%9E%8B%E4%B8%BB%E5%AF%BC%E7%9A%84%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E8%AE%BE%E8%AE%A1/","publishdate":"2021-09-15T13:03:52+08:00","relpermalink":"/zh/talk/%E7%B1%BB%E5%9E%8B%E4%B8%BB%E5%AF%BC%E7%9A%84%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E8%AE%BE%E8%AE%A1/","section":"event","summary":"","tags":[],"title":"类型主导的编程语言设计","type":"event"},{"authors":[],"categories":null,"content":"","date":1684481400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1684481400,"objectID":"99076ec5292e5471d71cad1100ab8d92","permalink":"https://stonebuddha.github.io/zh/talk/%E8%B5%84%E6%BA%90%E5%AE%89%E5%85%A8%E7%9A%84%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/","publishdate":"2021-09-15T13:03:52+08:00","relpermalink":"/zh/talk/%E8%B5%84%E6%BA%90%E5%AE%89%E5%85%A8%E7%9A%84%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/","section":"event","summary":"","tags":[],"title":"资源安全的系统编程语言","type":"event"},{"authors":[],"categories":null,"content":"","date":1679986800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1679986800,"objectID":"8b4d716bf4541084c873ec54b1e6ee5b","permalink":"https://stonebuddha.github.io/zh/talk/%E7%9B%B4%E8%A7%89%E4%B8%BB%E4%B9%89%E9%80%BB%E8%BE%91%E4%B8%8E%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E8%AF%AD%E8%A8%80/","publishdate":"2021-09-15T13:03:52+08:00","relpermalink":"/zh/talk/%E7%9B%B4%E8%A7%89%E4%B8%BB%E4%B9%89%E9%80%BB%E8%BE%91%E4%B8%8E%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E8%AF%AD%E8%A8%80/","section":"event","summary":"","tags":[],"title":"直觉主义逻辑与程序设计语言","type":"event"},{"authors":["Ankush Das","王迪","Jan Hoffmann"],"categories":[],"content":"","date":1673740800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1673740800,"objectID":"b1aa4218de8cb8395efec1779b1239e1","permalink":"https://stonebuddha.github.io/zh/publication/daswh23/","publishdate":"2021-09-15T12:10:30+08:00","relpermalink":"/zh/publication/daswh23/","section":"publication","summary":"Session types guarantee that message-passing processes adhere to predefined communication protocols. Prior work on session types has focused on deterministic languages but many message-passing systems, such as Markov chains and randomized distributed algorithms, are probabilistic. To implement and analyze such systems, this article develops the meta theory of probabilistic session types with an application focus on automatic expected resource analysis. Probabilistic session types describe probability distributions over messages and are a conservative extension of intuitionistic (binary) session types. To send on a probabilistic channel, processes have to utilize internal randomness from a probabilistic branching or external randomness from receiving on a probabilistic channel. The analysis for expected resource bounds is smoothly integrated with the type system and is a variant of automatic amortized resource analysis. Type inference relies on linear constraint solving to automatically derive symbolic bounds for various cost metrics. The technical contributions include the meta theory that is based on a novel nested multiverse semantics and a type-reconstruction algorithm that allows flexible mixing of different sources of randomness without burdening the programmer with complex type annotations. The type system has been implemented in the language NomosPro with linear-time type checking. Experiments demonstrate that NomosPro is applicable in different domains such as cost analysis of randomized distributed algorithms, analysis of Markov chains, probabilistic analysis of amortized data structures and digital contracts. NomosPro is also shown to be scalable by *(i)* implementing two broadcast and a bounded retransmission protocol where messages are dropped with a fixed probability, and *(ii)* verifying the limiting distribution of a Markov chain with 64 states and 420 transitions.","tags":[],"title":"Probabilistic Resource-Aware Session Types","type":"publication"},{"authors":[],"categories":null,"content":"","date":1671688800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1671688800,"objectID":"8960ab0a46959ce19e2766c0f7db22ba","permalink":"https://stonebuddha.github.io/zh/talk/%E9%87%8F%E5%8C%96%E7%A8%8B%E5%BA%8F%E5%88%86%E6%9E%90%E4%B8%8E%E9%AA%8C%E8%AF%81/","publishdate":"2021-09-15T13:03:52+08:00","relpermalink":"/zh/talk/%E9%87%8F%E5%8C%96%E7%A8%8B%E5%BA%8F%E5%88%86%E6%9E%90%E4%B8%8E%E9%AA%8C%E8%AF%81/","section":"event","summary":"","tags":[],"title":"量化程序分析与验证","type":"event"},{"authors":["王迪"],"categories":[],"content":"This post aims at reproducing some results from Saad et al.’s paper on Bayesian synthesis1 in OCaml, an industrial strength functional programming language. A complete notebook for the code in this post can be found here. The data used for a Bayesian-style time-series analysis can be found here.\nEnvironment Setup The code in this post is tested under OCaml 4.14.0 on macOS 12.6.1 with an M2 chip. The environment is supposed to contain a Python distribution with jupyter and matplotlib installed. The code should also work on macOS (or Linux) with Intel/AMD chips.\nI am maintaining a ppl repo that contains some extensions of existing OCaml packages. We will use libtorch in this post and we need to pin the ocaml-torch package to version 0.14, because currently the only M1/M2-compatible libtorch library provided by my ppl repo is only compatible with this version of ocaml-torch. The torch_ext.0.14 and matplotlib.20221112 packages are provided by my ppl repo: the former adds some functionality about probability distributions on tensors and the latter supports more plotting controls and functions. We will use owl for parsing CSV files. For M1/M2 users, you may need to refer to this comment to install owl.\nopam remote add ppl https://github.com/stonebuddha/ppl-opam.git opam pin https://github.com/LaurentMazare/ocaml-torch.git#0.14 --with-version=0.14 opam install core jupyter opam install torch_ext.0.14 matplotlib.20221112 opam install owl The following command registers OCaml as a jupyter kernel (you might take a look at the installation log of the OCaml jupyter package to find out the exact command):\njupyter kernelspec install --name ocaml-jupyter /PATH/TO/YOUR/OCAML/SWITCH/share/jupyter For Anaconda-based Python distributions, or for Python distributions that are not linked to standard paths for looking for runtime libraries, you might need to update the kernels/ocaml-jupyter/kernel.json file located in your jupyter installation. For example, I need to add the following environment variable before invoking ocaml-jupyter-kernel:\nDYLD_LIBRARY_PATH=/opt/homebrew/anaconda3/lib:$DYLD_LIBRARY_PATH Finally, we need to add the following code to the .ocamlinit file (which should be located in your home folder):\n#use \u0026#34;topfind\u0026#34;;; Topfind.log := ignore;; Now you should be able to create and run an OCaml notebook in jupyter.\nOCaml Torch Basics Here is the link to the official introduction of the ocaml-torch package. Most APIs are directly generated from libtorch, and thus similar to the APIs of PyTorch, but in a more functional way. Tensors are of type Tensor.t and scalars are of type Scalar.t. Because OCaml is statically and strongly typed, we cannot directly multiply a tensor with a floating-point number; instead, we need to first embed a floating-point number as a scalar via Scalar.f : float -\u0026gt; Scalar.t and then perform the tensor-scalar multiplication via Tensor.mul_scalar : Tensor.t -\u0026gt; Scalar.t -\u0026gt; Tensor.t.\nOne benefit of this programming style is that it removes many runtime checks because we know the type information at compile time. However, this style is not very succinct compared to Python. Even worse, lack of ad-hoc polymorphism (e.g., operator overloading) makes programming in OCaml more inconvenient than Haskell in this setting. One workaround is that OCaml supports scoped function calls (operators are also functions). For example, if t1 : Tensor.t and t2 : Tensor.t are two tensors of the same shape, we can write Tensor.(t1 + t2) for pointwise addition of the two tensors.\nGaussian Process Regression Readers can refer to the textbook Gaussian Processes for Machine Learning for more details on Gaussian Processes. In this post, we focus on a Bayesian-style time-series analysis based on Gaussian Process Regression. Let $\\mathbb{T}$ be an index set and $X \\triangleq \\{ X(t) \\mid t \\in \\mathbb{T} \\}$ be a collection of real-valued random variables. We say $X$ is a Gaussian Process if for any $\\mathbf{t} = [t_1, t_2, \\cdots, t_n]$ of distinct indexes, the random vector $X(\\mathbf{t}) \\triangleq [X(t_1), X(t_2), \\cdots, X(t_n)]$ has a joint Gaussian distribution.\nWe can represent a Gaussian Process by its mean function $m : \\mathbb{T} \\to \\mathbb{R}$ and covariance function $k : \\mathbb{T} \\times \\mathbb{T} \\to \\mathbb{R}$ that satisfy for all $t,t’ \\in \\mathbb{T}$, it holds that $m(t) = \\mathbb{E}[X(t)]$ and $k(t,t’) = \\mathbb{E}[ (X(t) - m(t)) (X(t’) - m(t’))]$. Let $m(\\mathbf{t})$ denote the mean vector $[m(t_1), m(t_2), \\cdots, m(t_n)]$. Let $k(\\mathbf{t}, \\mathbf{t})$ denote the covariance matrix whose $i j$ entry is $k(t_i, t_j)$. We denote by $X \\sim \\mathrm{GP}(m,k)$ a Gaussian Process $X$ with mean $m$ and covariance $k$. For one-dimensional continuous time series (which we consider in this post), we can assume that $\\mathbb{T} = \\mathbb{R}$.\nThe joint probability density of $X(\\mathbf{t})$ at a real vector $x(\\mathbf{t}) \\triangleq [x(t_1), x(t_2), \\cdots, x(t_n)]$ is $$ \\begin{align} \\log p(x(\\mathbf{t})) \u0026amp; = …","date":1669772339,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1669772339,"objectID":"6ad96618d8ba20ff292d657f7dd25d6e","permalink":"https://stonebuddha.github.io/zh/post/bayesian-synthesis-in-ocaml/","publishdate":"2022-11-30T09:38:59+08:00","relpermalink":"/zh/post/bayesian-synthesis-in-ocaml/","section":"post","summary":"This post aims at reproducing some results from Saad et al.’s paper on Bayesian synthesis1 in OCaml, an industrial strength functional programming language. A complete notebook for the code in","tags":[],"title":"用 OCaml 实现贝叶斯程序合成（英文）","type":"post"},{"authors":["王迪"],"categories":[],"content":"人们近年来在人工智能领域取得的进展，除了层出不穷的新算法，也仰仗硬件算力的提升并得益于编程语言层面对自动微分和张量运算的支持。 基于神经网络的机器学习在很多应用中取得了成功，但在一些方面也尚存不足，例如对预测结果信度的评估1，纳入领域知识的方法2，以及在观测数据的分布发生改变时的鲁棒性3。 贝叶斯推断（Bayesian Inference）是一种历史悠久的、基于概率的贝叶斯解释（而非频率解释）的、在上述三个方面有一些优势的机器学习方法，其核心在于通过观测数据来估计模型假设空间的概率分布，而非选择出单个“最优”假设：设 $\\Theta$ 为假设空间、$x$ 为观测数据，每个假设 $\\theta \\in \\Theta$ 具有一个先验概率 $\\mathbb{P}(\\theta)$，而一个贝叶斯模型则描述了观测数据在给定假设下的条件概率 $\\mathbb{P}(x \\mid \\theta)$，那么由贝叶斯法则，我们可用观测数据更新模型假设的后验概率： $$ \\mathbb{P}(\\theta \\mid x) = \\frac{ \\mathbb{P}(x \\mid \\theta) \\mathbb{P}(\\theta) }{ \\sum_{\\theta’ \\in \\Theta} \\mathbb{P}(x \\mid \\theta’) \\mathbb{P}(\\theta’) } \\qquad (\\theta \\in \\Theta). $$ 基于贝叶斯推断的机器学习也被称为贝叶斯机器学习4 5。 然而，相比基于梯度下降等算法的机器学习方法，贝叶斯推断的计算复杂度更高，这阻挡了贝叶斯机器学习在更多领域、更大模型上的应用。\n为了更快更好地进行贝叶斯推断，概率编程6逐渐成为一个活跃的研究领域。 概率编程旨在分离描述概率模型和进行贝叶斯推断这两个步骤，通过良好的编程语言设计来支持丰富的模型种类，通过编程语言的各类技术（如编译优化、动态分析、元编程等）来自动、高效地进行贝叶斯推断。 人们已经设计、开发了多个概率编程语言（如 Stan、Pyro、Gen.jl 等），但如何平衡正确性和灵活性仍然是该领域的一个重要研究问题。 一方面，设计有语义限制的概率编程语言并提供特化的推断算法，可以保证正确性和高效性，但是语言可表达的模型种类受限，也难以重用已有的非概率的计算模块；另一方面，使用通用编程语言来描述概率模型，并允许用户对通用推断算法进行定制，可以满足灵活性和一定程度上的高效性7 8，但是用户定制会使得正确性的保证变得困难。 正如自动微分框架驱动了基于神经网络的机器学习的发展，我们期待一个正确而灵活的概率编程框架能驱动贝叶斯机器学习的进一步发展和流行。\n在这里，我们看一个使用概率编程来进行时间序列的在线学习的例子9。 该例子希望学习并预测美国的月度民航总里程数的走势（数据来源）。下图为 2009 年 1 月至 2020 年 2 月的数据： 在贝叶斯机器学习中，高斯过程回归（Gaussian Process Regression）是一种灵活的算法，该方法允许我们使用核函数（Kernel Function）来定制多元高斯分布的的协方差矩阵。 通过概率编程，我们可以不用预先指定使用什么形式的核函数，而是写一段程序来声明核函数形式的先验概率分布（换句话说，我们可以把结构的选择也纳入模型假设 $\\theta$ 中）。 下面的代码通过概率上下文无关文法（Probabilistic Context-Free Grammar）的方式实现了这样的一个先验概率分布：\ntype kernel = | Constant of float | Linear of float | ... | Plus of kernel * kernel | ... let rec kernel_prior () = let kernel_type = categorical [0.2; 0.2; 0.2; 0.2; 0.1; 0.1] in match kernel_type with | 0 -\u0026gt; Constant (rand ()) (* Constant (C): k(x, x\u0026#39;) = C *) | 1 -\u0026gt; Linear (rand ()) (* Linear (C): k(x, x\u0026#39;) = (x - C) * (x\u0026#39; - C) *) ... | 4 -\u0026gt; Plus (kernel_prior (), kernel_prior ()) (* Plus (k1, k2): k(x, x\u0026#39;) = k1(x, x\u0026#39;) + k2(x, x\u0026#39;) *) ... 结合序列蒙特卡洛（Sequential Monte Carlo）方法，我们可以实现一个基于高斯过程的时间序列的在线学习算法，该算法可以估计预测的不确定性，并在数据分布发生改变时即时响应。 下面这个动画展示了在线学习的效果，其中灰色的区域为使用 100 个对后验概率分布的采样做出的 95% 置信度预测区间的叠加： 可以看出，在数据比较多的时候，算法已经对整个趋势的掌握已经非常不错了。而下面的动画则展示在 2020 年 2 月之后的数据上的效果： 很明显，新冠疫情导致了民航数据的突变，而基于贝叶斯推断的在线学习可以及时对这种变化进行响应并调整之后的预测。\nChuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q. Weinberger. 2017. On Calibration of Modern Neural Networks. ICML\u0026#39;17. ↩︎\nNikhil Muralidhar, Mohammad Raihanul Islam, Manish Marwah, Anuj Karpatne, and Naren Ramakrishnan. 2018. Incorporating Prior Domain Knowledge into Deep Neural Networks. ICBD\u0026#39;18. ↩︎\nDario Amodei, Chris Olah, Jacob Steinhardt, Paul Christiano, John Schulman,and Dan Mané. 2016. Concrete Problems in AI Safety. https://arxiv.org/abs/1606.06565 ↩︎\nZoubin Ghahramani. 2015. Probabilistic machine learning and artiicial intelligence. Nature, 521. ↩︎\nJoshua B. Tenenbaum, Charles Kemp, Thomas L. Grifiths, and Noah D. Goodman. 2011. How to Grow a Mind: Statistics, Structure, and Abstraction. Science, 331, 6022. ↩︎\nJan Willem van de Meent, Brooks Paige, Hongseok Yang, and Frank Wood. 2018. An Introduction to Probabilistic Programming. https://arxiv.org/abs/1809.10756 ↩︎\nVikash K. Mansinghka, Ulrich Schaechtle, Shivam Handa, Alexey Radul, Yutian Chen, and Martin C. Rinard. 2018. Probabilistic Programming with Programmable Inference. PLDI\u0026#39;18. ↩︎\nEli Bingham, Jonathan P. Chen, Martin Jankowiak, Fritz Obermeyer, Neeraj Pradhan, Theofanis Karaletsos, Rishabh Singh, Paul Szerlip, Paul Horsfall, and Noah D. Goodman. 2018. Pyro: Deep Universal Probabilistic Programming. J. Machine Learning Research, 20, 1. ↩︎\nFeras A. Saad, Marco F. Cusumano-Towner, Ulrich Schaechtle, Martin C. Rinard, and Vikash K. Mansinghka. 2019. Bayesian Synthesis of Probabilistic Programs for Automatic Data. POPL\u0026#39;19. ↩︎\n","date":1667123397,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1667123397,"objectID":"7d130f80fb0a0c4948b3e6fb635e0362","permalink":"https://stonebuddha.github.io/zh/post/introduction-to-probabilistic-programming/","publishdate":"2022-10-30T17:49:57+08:00","relpermalink":"/zh/post/introduction-to-probabilistic-programming/","section":"post","summary":"人们近年来在人工智能领域取得的进展，除了层出不穷的新算法，也","tags":[],"title":"随便聊聊：贝叶斯概率编程","type":"post"},{"authors":["王迪"],"categories":[],"content":"本文参考了 Zachary Kincaid 和 Thomas Reps 在 CAV 2021 上的关于代数程序分析（Algebraic Program Analysis）的教程1 2。\n代数程序分析简单来说就是一种基于代数结构来设计程序分析的方法论：某种代数结构中的元素代表了程序的含义，而其上的运算则代表组合程序含义的方式。 这其实跟我们在程序语法树上用结构递归定义指称语义（Denotational Semantics）的方式类似： $$ \\begin{align} \\mathcal{A}[{-}] \u0026amp; : \\mathit{Program} \\to \\mathit{Meaning} \\\\ \\mathcal{A}[S_1;S_2] \u0026amp; = \\mathcal{A}[S_1] \\cdot \\mathcal{A}[S_2] \\\\ \\mathcal{A}[\\mathbf{if}(*)\\{S_1\\}\\mathbf{else}\\{S_2\\}] \u0026amp; = \\mathcal{A}[S_1] + \\mathcal{A}[S_2] \\\\ \\mathcal{A}[\\mathbf{while}(*)\\{S_0\\}] \u0026amp; = (\\mathcal{A}[S_0])^* \\end{align} $$ 而上面式子中的 $\\cdot$、$+$ 和 $^*$ 就可以视作某种代数结构所支持的运算。 这种方式具有良好的 Compositionality：一个程序的含义总是由该程序的组成部分的含义结合而来。 例如，如果上面的 $\\mathcal{A}$ 代表了一个程序分析，那么我们需要指定如何实现连接（$\\cdot$）、分支（$+$）和循环（$^*$）这三种运算。 注意，这里出现了一个与传统基于迭代的程序分析的重要不同：一个循环语句的含义并不是由反复迭代循环体直到不动点来获得，而是通过一个显式的 $^*$ 运算来获得。 换句话说，代数程序分析允许我们使用别的（非迭代的）方式来分析循环，这就为我们设计新的程序分析技术提供了可能性。\n在本文中，我们考虑通过状态转移公式代数（Transition Formula Alegebras）来分析程序变量间的数值关系。 一个状态转移公式$F(X,X’)$是一个逻辑公式，它描述了程序状态上的转移关系：$X$ 集合表示前状态（pre-state）的变量，$X’$ 集合表示后状态（post-state）的变量。 比如我们考虑变量有 $x,y$，那么程序语句 x = x + 1; 的状态转移公式就是 $x’ = x + 1 \\wedge y’ = y$。 对于一个固定的变量集合 $X$，我们考虑在所有可能的状态转移公式 $F(X,X’)$ 上建立一个适用于程序分析的代数结构。 在传统程序分析中，我们往往需要预先对可能的公式进行限制来使得迭代算法可以收敛：例如，只考虑变量间的线性不等式。 在代数程序分析中，我们不需要这种预先的限制，而是可以在实现循环运算（$^*$）时以即插即用的方式使用不同的近似方法。 在状态转移公式代数中，我们定义常数 $0$ 为 $\\mathit{false}$，常数 $1$ 为 $\\bigwedge_{x \\in X} (x’ = x)$，分支运算为 $F + G = F \\vee G$，连接运算为 $F \\cdot G = \\exists X’’. F(X,X’’) \\wedge G(X’’,X’)$（即用 $X’’$ 来表示中间状态）。 而对于循环运算 $({-})^* : \\mathit{TransitionFormula} \\to \\mathit{TransitionFormula}$，我们只需考虑在转移公式这一层面进行计算，并不用考虑循环语句本身可能有的嵌套循环结构！ 换句话说，我们可以借鉴已有的各种 Loop Summarization / Acceleration 技术。\n在这里，我们只讨论一种基于区间分析的循环运算实现方法（本文开头提到的参考材料中有更多的例子）。 在区间分析中，我们一般考虑形如 $\\bigwedge_{x \\in X} (a_x \\le x \\le b_x)$ 的状态公式，其中 $a_x,b_x$ 为常数。 例如，对于下面这个程序中的循环而言，$0 \\le i \\le 10 \\wedge 0 \\le j \\le 20$ 是一个区间不变量，但是 $0 \\le i \\le 10 \\wedge 0 \\le j \\le 10$ 并不是：\ni = 0; j = 0; while (i \u0026lt; 10 \u0026amp;\u0026amp; j != 20 \u0026amp;\u0026amp; j \u0026lt; 100) { i = i + 1; j = j + 1; } 传统的基于区间的程序分析会使用 widening / narrowing 等技术来确保迭代分析可以收敛，但这会影响分析的精度。 在代数程序分析的框架中，我们则拥有更好的自由度来设计对于循环的分析：考虑循环体的转移公式为 $F(X,X’)$，那么断言“$A = \\{ a_x \\mid x \\in X \\}$ 和 $B = \\{ b_x \\mid x \\in X \\}$构成一个区间不变量”可以表述为下面的公式： $$ \\forall X, X’. \\left(\\left(\\bigwedge_{x \\in X}(a_x \\le x \\le b_x)\\right) \\wedge F(X,X’)\\right) \\implies \\bigwedge_{x \\in X} (a_x \\le x’ \\le b_x) $$ 令 $Inv(A,B)$ 为上面这个式子。那么循环运算 $F^{*}$ 可以定义为： $$ \\forall A, B. \\left( Inv(A,B) \\wedge \\bigwedge_{x \\in X} (a_x \\le x \\le b_x) \\right) \\implies \\bigwedge_{x \\in X} (a_x \\le x’ \\le b_x) $$ 这种循环运算的实现蕴含了所有可以由循环体转移公式 $F$ 得出的区间不变量！\n前面我们提到，代数程序分析要求在程序语法树上进行结构递归，那么在非结构的程序上（例如有 break 和 continue），我们是否还能进行代数程序分析呢？ 答案再次由 Robert Tarjan 给出：Yes！（至于为什么用“再”可以看我上次的分享。) Tarjan 的两篇文章 Fast Algorithms for Solving Path Problems 和 A Unified Approach to Path Problems 中提出了一种高效的基于代数的在图上解决路径问题的算法：这里的路径问题指的是图中的边上有权值，一条路径的权值为其中边权相乘，然后我们想要计算符合某种条件的所有路径的权值和（这里的乘和和都是抽象的，例如如果权值为非负数，乘为加，和为取最小值，那么路径问题描述的则是最短路问题）。 Tarjan 提出了一种可以计算图上两点间所有路径的集合的高效算法，其关键点在于这个（可能无穷的）路径集合可以表述为一个有限的正则表达式，其后解路径问题就可以转化为在一个描述问题的代数结构中解释正则表达式：这与我们上文描述的三种运算（连接 $\\cdot$，分支 $+$，循环 $^*$）正好是符合的！ 所以，对于非结构的程序，我们可以把它表示成一个控制流图，然后通过 Tarjan 的算法计算出描述所有可能的程序执行路径的正则表达式，最后在描述程序分析的代数结构中解释该正则表达式。 例如，以下程序\nwhile (true) { m = 0; while (m \u0026lt; 8) { if (n \u0026lt; 0) { return; } else { m = m + 1; n = n - 1; } } } 中的所有可能路径的集合可以表述为下面的正则表达式： $$\\small \\left(\\fbox{m=0} \\cdot \\left(\\fbox{m\u0026lt;8} \\cdot \\fbox{n\u0026gt;=0} \\cdot \\fbox{m=m+1} \\cdot \\fbox{n=n-1}\\right)^* \\cdot \\fbox{m\u0026gt;=8}\\right)^* \\cdot \\fbox{m=0} \\cdot \\fbox{m\u0026lt;8} \\cdot \\fbox{n\u0026lt;0} $$\n在文章的最后，我们聊一聊代数程序分析的不足。 最明显的不足在于，尽管 Compositionality 是个好性质，它也意味着我们在程序分析中丢失了上下文信息。 一方面，由于在分析某个程序组成部分时不能依赖其上下文，我们在分析时需要追踪更多的信息（例如上文的状态转移公式代数需要同时记录 $X$ 和 $X’$）；另一方面，我们可能会由于缺乏上下文信息而对某个程序组成部分进行过于保守的分析（这取决于程序分析状态空间设计得好不好）。\nZachary Kincaid, Thomas Reps, and John Cyphert. Algebraic Program Analysis. https://doi.org/10.1007/978-3-030-81685-8_3 ↩︎\nZachary Kincaid and Thomas Reps. Introduction to Algebraic Program Analysis. Part 1, Part 2, Part 3, Part 4 ↩︎\n","date":1664722271,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1664722271,"objectID":"77b7cdc4ebaeb305431f0d0b85ae5883","permalink":"https://stonebuddha.github.io/zh/post/introduction-to-algebraic-program-analysis/","publishdate":"2022-10-02T22:51:11+08:00","relpermalink":"/zh/post/introduction-to-algebraic-program-analysis/","section":"post","summary":"本文参考了 Zachary Kincaid 和 Thomas Reps 在 CAV 2021 上的关于代数程序分析（Algebr","tags":[],"title":"随便聊聊：代数程序分析","type":"post"},{"authors":["王迪"],"categories":[],"content":"简单地说，程序的资源分析（Resource Analysis）指的是把该程序的资源消耗表示成一个关于程序输入的函数。 这里的资源可以是运行时间、内存使用、能源消耗，或别的什么数值指标。 高德纳（Donald Knuth）在《计算机程序设计的艺术》（The Art of Computer Programming）中就基于 MIX 汇编语言的语义讨论了一些资源分析的问题。 在计算机科学的课程中，资源分析通常以分析算法、数据结构的时间、空间复杂度的形式出现，而这里面最常见的又通常是渐近分析，即忽略常数、假定输入规模充分大时的复杂度，例如对长度为 $n$ 的数组进行归并排序时间复杂度为 $O(n \\log n)$。 在这篇文章中，我们考虑一个稍微困难点的情况，即我们希望得到的分析结果是带有常数信息的非渐近复杂度：从非渐近分析可以容易得出渐近分析的结果，而且前者还可以用来精细地比较渐近复杂度相同的算法、数据结构。\n静态资源分析即在不实际运行程序的情况下对其进行资源分析。 Facebook 出品的 Infer 工具提供了函数级的静态运行时间分析，其宗旨是在软件开发的过程中更早地指出性能问题（比方说，在 Code Review 阶段由工具自动反馈，而不是等到后面的性能回归测试）。 下面这个例子来源于 Infer 的官方文档1：\nvoid loop(ArrayList\u0026lt;Integer\u0026gt; list){ for (int i = 0; i \u0026lt;= list.size(); i++){ } } Infer 通过静态分析对上面这个函数得出一个描述其运行时间的多项式（比如 $8|list|+16$），从而知道这个函数的时间复杂度和其输入列表的长度呈线性关系。 如果某一次代码修改把这个函数更新为：\nvoid loop(ArrayList\u0026lt;Integer\u0026gt; list){ for (int i = 0; i \u0026lt;= list.size(); i++){ foo(i); // newly added function call } } 而此处的 foo 函数的时间复杂度也是与输入呈线性关系，那么 Infer 可以检测到 loop 函数的复杂度从 $O(|list|)$ 增长到了 $O(|list|^2)$，并向开发者发出警报。 （如果想要更深入了解 Infer 中的资源分析，可以参考这个视频。）\n笼统地说，Infer 中的资源分析可以大致理解为对循环次数进行计数，从而将资源分析问题转化为程序变量数值关系的分析；这也是很多静态资源分析（比如 SPEED2）背后的原理。 在这篇文章中，我们来聊另一种颇为有趣的静态资源分析：自动均摊资源分析（Automatic Amortized Resource Analysis，AARA）。 这种方法衍生自 Robert Tarjan 在 1985 年的一篇论文3，文中给出了一种推导序列操作的最坏情况资源消耗的方法。 该方法的思路可以概括为：对于很多数据结构来说，一个操作消耗的资源很大程度上是由数据结构的状态决定的，而且有可能会根据状态有很大的不同；但是比较高的资源消耗（例如重新组织整个数据结构）往往会以一种可以预测的频率出现，也就是说，这些消耗在时间轴上均摊了。 均摊资源分析即利用了这种思想：我们可以把程序的执行看做是一个操作序列 $s_1,s_2,s_3,\\cdots$，这里的每个 $s_i \\in \\mathrm{State}$ 都表示一个程序状态，而我们用一个函数 $cost(s_i,s_{i+1})$ 来描述资源的消耗；然后我们设计一个势能函数 $\\Phi : \\mathrm{State} \\to \\mathbb{Q}^+$ 把程序状态映射为非负数，使得对任意的 $i$，我们有 $$ \\Phi(s_{i}) \\ge cost(s_{i}, s_{i+1}) + \\Phi(s_{i+1}), $$ 即一个状态的势能要足以支付当前程序操作的资源消耗以及下一个程序状态的势能（思考题：$cost$ 为负时意味着什么？）。 如此以来，$\\Phi(s_0)$ 给出了程序的总资源消耗的一个上界，而我们需要做的是定义一个势能函数，并证明在每个程序执行的局部，上述表达式成立。 这意味着均摊资源分析的 Compositionality 是很好的！\n我们知道，类型系统的一大特点也是 Compositionality；所以，设计一个用于均摊资源分析的类型系统是非常自然的想法。 考虑下面这段 OCaml 代码，它是连接两个列表的简单实现，而我们想要分析它递归调用的次数（这也是一种资源消耗）：\nlet rec append (l1, l2) = match l1 with | [] -\u0026gt; l2 | x :: xs -\u0026gt; let rest = append (xs, l2) in x :: rest 我们能够很容易地看出 append 函数递归调用的次数是 $|l_1|$。 假定这个 append 函数的类型为 $L(\\alpha) \\times L(\\alpha) \\to L(\\alpha)$，这里的 $L$ 即表示列表类型。 均摊分析要求我们给程序状态赋予势能，在这个例子中，我们则需要把我们的势能放在 append 的参数 $l_1$ 和 $l_2$ 里。 让我们给列表类型增加一个数值标注：用 $L^q(\\alpha)$ 表示一个列表类型，其中的每个元素都携带了 $q$ 单位的势能，并假定所有程序操作的资源消耗都是 $0$，除了递归调用的消耗为 $1$ 单位。 所以，append 的带资源标注的类型可以写为 $L^1(\\alpha) \\times L^0(\\alpha) \\to L^0(\\alpha)$：如果我们计算参数和结果之间的势能差，我们就能发现那恰好是 $|l_1|$。 但是，我们如何通过类型系统来检查这个类型是不是正确的呢？ 还记得 Compositionality 吗——我们只需要对局部操作验证一下势能不等式：比如，在模式匹配时，如果 $l_1$ 非空，那么我们把它解构为 $x$ 和 $xs$，其中 $xs$ 的类型与 $l_1$ 相同，为 $L^1(\\alpha)$，但是 $xs$ 的长度比 $l_1$ 少 $1$，所以这一步解构给了我们 $1$ 单位的自由势能，我们可以用它来支付紧接着的这个递归调用。 接着我们检查 $xs$ 和 $l_2$ 的类型是否符合 append 的类型签名（当然！）。 最后，类型签名告诉我们 $rest$ 的类型为 $L^0(\\alpha)$，所以构建最终返回结果 $x :: rest$ 也不需要往这个数据结构里面存势能了。\n我在这份胶片里更详细地展示了这个带资源标注的类型系统。 需要特别提出的是，自动推导这些数值标注并不困难：我们用变量来表示这些类型标注，那么类型检查就成为了生成关于这些变量的约束（通常是线性的）的过程，最后再解这些约束就好了。 在这个页面上你可以和一个实现了自动均摊资源分析的工具（Resource-aware ML，RaML）玩耍，其主要贡献者也在今年发表了一篇还不错的综述4。 祝大家玩得愉快！\nhttps://fbinfer.com/docs/checker-cost#examples ↩︎\nhttps://www.microsoft.com/en-us/research/publication/speed-precise-and-efficient-static-estimation-of-program-computational-complexity-2/ ↩︎\nRobert Tarjan. Amortized Computational Complexity. https://doi.org/10.1137/0606031 ↩︎\nJan Hoffmann and Steffen Jost. Two decades of automatic amortized resource analysis. https://doi.org/10.1017/S0960129521000487 ↩︎\n","date":1662795139,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1662795139,"objectID":"ecc5d483fca4ca39896af5aa4d67d9db","permalink":"https://stonebuddha.github.io/zh/post/introduction-to-static-resource-analysis/","publishdate":"2022-09-10T15:32:19+08:00","relpermalink":"/zh/post/introduction-to-static-resource-analysis/","section":"post","summary":"简单地说，程序的资源分析（Resource Analysis）","tags":[],"title":"随便聊聊：静态资源分析","type":"post"},{"authors":["王迪"],"categories":[],"content":"Tool link: Emacs Syntax Highlighting for LaTeX (ESH).\nThe tool does not really require understanding Emacs: one just needs a working installation! The tool seems well tested on GNU/Linux; however, I am mainly using macOS, so I find out an easy workflow that works for me. First, we need to install Cask, a project management tool for Emacs; such process should be easy and straightforward. Then we clone the esh repo and run cask build at the root of the repo. If nothing goes wrong, we are now able to use ESH!\nLet us go to a LaTeX project where we want to highlight OCaml code. First, we create a file Cask with the following content:\n(source gnu) (source melpa) (depends-on \u0026#34;tuareg\u0026#34;) ;; for OCaml mode Then we run cask install to install the required packages. Now we start to configure how we would like our code to be highlighted. We achieve this by creating a file esh-init.el, and below gives an example:\n(load-theme \u0026#39;tango t) ;; a color theme (add-to-list \u0026#39;auto-mode-alist \u0026#39;(\u0026#34;\\\\.ml\\\\\u0026#39;\u0026#34; . tuareg-mode)) ;; .ml file extension ;; some custom prettification (when (require \u0026#39;tuareg nil t) (defun my-tuareg-setup () (setq-local prettify-symbols-alist \u0026#39;((\u0026#34;fun\u0026#34; . ?λ) (\u0026#34;-\u0026gt;\u0026#34; . ?→))) (prettify-symbols-mode)) (add-hook \u0026#39;tuareg-mode-hook #\u0026#39;my-tuareg-setup)) Next, we run ./path/to/esh/bin/esh2tex --write-preamble to create a file esh-preamble.tex. The generated TeX file implements functions to highlight code in TeX. Below presents an example LaTeX file:\n\\documentclass{article} \\usepackage[varqu]{zi4} % for inconsolata font \\input{esh-preamble} \\begin{document} \\ESHInputBlock{test.ml} \\end{document} And an example OCaml code file test.ml:\nlet rec append l1 l2 = match l1 with | [] -\u0026gt; l2 | x :: xs -\u0026gt; x :: (append xs l2) let rec partition f l = match l with | [] -\u0026gt; ([], []) | x :: xs -\u0026gt; let (cs, bs) = partition f xs in if f x then (cs, x :: bs) else (x :: cs, bs) let rec quicksort le = function | [] -\u0026gt; [] | x :: xs -\u0026gt; let (ys, zs) = partition (le x) xs in append (quicksort le ys) (x :: (quicksort le zs)) ESH needs to invoke Emacs to highlight the code and we have to perform this external operation manually. Fortunately, we just need to run ./path/to/esh/bin/esh2tex --standalone test.ml, which should generate a file test.ml.esh.tex. Finally, we can typeset our LaTeX project (e.g, pdflatex main) and should get something similar to the following screenshot: Amazing!\n","date":1657572982,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1657572982,"objectID":"40ea8ecde10ba59218355af403984ad6","permalink":"https://stonebuddha.github.io/zh/post/easy-syntax-highlighting-for-latex/","publishdate":"2022-07-12T04:56:22+08:00","relpermalink":"/zh/post/easy-syntax-highlighting-for-latex/","section":"post","summary":"Tool link: Emacs Syntax Highlighting for LaTeX (ESH). The tool does not really require understanding Emacs: one just needs a working installation! The tool seems well tested on GNU/Linux; however,","tags":[],"title":"LaTeX 中的代码高亮（英文）","type":"post"},{"authors":[],"categories":null,"content":"","date":1647064800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1647064800,"objectID":"2af9841c3ef5ceaafcebaa29860a2289","permalink":"https://stonebuddha.github.io/zh/talk/%E6%A6%82%E7%8E%87%E7%A8%8B%E5%BA%8F%E8%AF%AD%E4%B9%89/","publishdate":"2021-09-15T13:03:52+08:00","relpermalink":"/zh/talk/%E6%A6%82%E7%8E%87%E7%A8%8B%E5%BA%8F%E8%AF%AD%E4%B9%89/","section":"event","summary":"","tags":[],"title":"概率程序语义","type":"event"},{"authors":["王迪","Jan Hoffmann","Thomas Reps"],"categories":[],"content":"","date":1624147200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1624147200,"objectID":"45117ebf3164126815c2285cafe7bc4a","permalink":"https://stonebuddha.github.io/zh/publication/wanghr21a/","publishdate":"2021-09-15T11:30:37+08:00","relpermalink":"/zh/publication/wanghr21a/","section":"publication","summary":"For probabilistic programs, it is usually not possible to automatically derive exact information about their properties, such as the distribution of states at a given program point. Instead, one can attempt to derive approximations, such as upper bounds on *tail probabilities*. Such bounds can be obtained via concentration inequalities, which rely on the *moments* of a distribution, such as the expectation (the first *raw* moment) or the variance (the second *central* moment). Tail bounds obtained using central moments are often tighter than the ones obtained using raw moments, but automatically analyzing central moments is more challenging.\n\nThis paper presents an analysis for probabilistic programs that automatically derives symbolic upper and lower bounds on variances, as well as higher central moments, of *cost accumulators*. To overcome the challenges of higher-moment analysis, it generalizes analyses for expectations with an algebraic abstraction that simultaneously analyzes different moments, utilizing relations between them. A key innovation is the notion of *moment-polymorphic recursion*, and a practical derivation system that handles recursive functions.\n\nThe analysis has been implemented using a template-based technique that reduces the inference of polynomial bounds to linear programming. Experiments with our prototype central-moment analyzer show that, despite the analyzer's upper/lower bounds on various quantities, it obtains tighter tail bounds than an existing system that uses only raw moments, such as expectations.","tags":[],"title":"Central Moment Analysis for Cost Accumulators in Probabilistic Programs","type":"publication"},{"authors":["王迪","Jan Hoffmann","Thomas Reps"],"categories":[],"content":"","date":1624147200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1624147200,"objectID":"1c9c209b3c8ad03bd0f0d48a6fa71e7c","permalink":"https://stonebuddha.github.io/zh/publication/wanghr21b/","publishdate":"2021-09-15T11:52:24+08:00","relpermalink":"/zh/publication/wanghr21b/","section":"publication","summary":"Probabilistic programming languages aim to describe and automate Bayesian modeling and inference. Modern languages support programmable inference, which allows users to customize inference algorithms by incorporating guide programs to improve inference performance. For Bayesian inference to be sound, guide programs must be compatible with model programs. One pervasive but challenging condition for model-guide compatibility is absolute continuity, which requires that the model and guide programs define probability distributions with the same support.\n\nThis paper presents a new probabilistic programming language that guarantees absolute continuity, and features general programming constructs, such as branching and recursion. Model and guide programs are implemented as coroutines that communicate with each other to synchronize the set of random variables they sample during their execution. Novel guide types describe and enforce communication protocols between coroutines. If the model and guide are well-typed using the same protocol, then they are guaranteed to enjoy absolute continuity. An efficient algorithm infers guide types from code so that users do not have to specify the types. The new programming language is evaluated with an implementation that includes the type-inference algorithm and a prototype compiler that targets Pyro. Experiments show that our language is capable of expressing a variety of probabilistic models with nontrivial control flow and recursion, and that the coroutine-based computation does not introduce significant overhead in actual Bayesian inference.","tags":[],"title":"Sound Probabilistic Inference via Guide Types","type":"publication"},{"authors":[],"categories":null,"content":"","date":1622728800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1622728800,"objectID":"489a1a204bcc141119494b1b9fb94799","permalink":"https://stonebuddha.github.io/zh/talk/type-guided-worst-case-input-generation/","publishdate":"2021-09-15T13:03:52+08:00","relpermalink":"/zh/talk/type-guided-worst-case-input-generation/","section":"event","summary":"","tags":[],"title":"Type-Guided Worst-Case Input Generation","type":"event"},{"authors":["王迪","Jan Hoffmann","Thomas Reps"],"categories":[],"content":"","date":1617062400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1617062400,"objectID":"d76ecb80d763b2564b46315aae241e97","permalink":"https://stonebuddha.github.io/zh/publication/wanghr21c/","publishdate":"2021-09-15T11:57:39+08:00","relpermalink":"/zh/publication/wanghr21c/","section":"publication","summary":"In this article, we present a semantics-level adaption of the Optional Stopping Theorem, sketch an expected-cost analysis as its application, and survey different variants of the Optional Stopping Theorem that have been used in static analysis of probabilistic programs.","tags":[],"title":"Expected-Cost Analysis for Probabilistic Programs and Semantics-Level Adaption of Optional Stopping Theorems","type":"publication"},{"authors":["王迪"],"categories":[],"content":"In this post, we consider one-dimensional random walks: assume that $S_n = \\sum_{i=1}^n X_i$ is a random walk on the integers with initial value $S_0 = 0$, where $X_i, i \\in \\mathbb{N}$ are independent and identically distributed random variables. For termination analysis, we introduce a stopping time: a nonnegative integer-valued random variable $T$ such that for every integer $n \\ge 0$, the indicator function of the event $\\lbrace T = n \\rbrace$ is a function of $S_1,S_2,\\cdots,S_n$.\nSymmetric Random Walk For each $i \\in \\mathbb{N}$, we consider $X_i = \\left\\lbrace \\begin{array}{ll} 1 \u0026amp; \\text{with prob.}~0.5 \\\\ -1 \u0026amp; \\text{with prob.}~0.5 \\end{array} \\right.$. Symmetric random walks are known to be recurrent, i.e., with probability one, any state is visited infinitely often. Let us consider the case where the random walk terminates when it reaches the level $1$, i.e., $T := \\min\\lbrace n \\ge 0 : S_n = 1 \\rbrace$, and $T$ is clearly a stopping time. How do we establish the recurrence property for $T$, i.e., $\\mathbb{P}[T \u0026lt; \\infty] = 1$? Moreover, what can we say about $\\mathbb{E}[T]$?\nOne method is to derive $T$’s probability generating function $G(z) := \\mathbb{E}[z^T] = \\sum_{n=0}^{\\infty} z^n \\mathbb{P}[T=n]$, which is defined for all real values of $z$ less than $1$ in absolute value. The strategy for the derivation is to condition on the first step of the random walk to obtain a functional equation for $G$; there are two possibilities:\nif $X_1 = 1$, then $S_1 = 1$ and $T = 1$; or if $X_1 = -1$, then $S_1 = -1$, and the random walk must first return to the origin, and the amount of time it takes to reach $0$ starting from $-1$ has the same distribution as—and is conditionally independent of—$T$ itself (i.e., the amount of time to reach $1$ from $0$). Thus, $G(z) = 0.5z + 0.5z \\cdot G(z) \\cdot G(z) = (z + zG(z)^2) / 2$. This is a functional equation, whose solution is $G(z) = (1 \\pm \\sqrt{1 - z^2})/z$. Moreover, observing that $G(z)$ takes values between 0 and 1 when $z \\in (0,1)$, we obtain the unique solution $G(z) = (1 - \\sqrt{1- z ^2})/z$.\nThen, by the monotone convergence theorem, we have $$ \\mathbb{P}[T \u0026lt; \\infty] = \\sum_{n=0}^\\infty \\mathbb{P}[T = n] = \\lim_{z \\to 1^-} G(z) = 1. $$ Similarly, noting that $G’(z) = \\sum_{n=1}^{\\infty} n z^{n-1} \\mathbb{P}[T=n]$, we can express $\\mathbb{E}[T]$ as $G’(1^-)$. Because $G’(z) = (-1 + 1/\\sqrt{1 - z^2})/z^2$, we have $\\mathbb{E}[T] = G’(1^-) = \\infty$, i.e., the expected termination time is infinity.\nGambler’s Ruin Let us consider another termination criterion for symmetric random walks: it is set up so that Alice and Bob bet one dollar against each other on the results of a fair coin flip until one play runs out of money. Suppose that Alice starts with $A$ dollars and Bob starts with $B$ dollars. We define a termination time to model the gamble: $T := \\min\\lbrace n \\ge 0: S_n = -A \\vee S_n = B\\rbrace$, which is clearly a stopping time. By a similar argument, we can show both $\\mathbb{P}[T_A \u0026lt; \\infty] = 1$ where $T_A := \\min\\lbrace n \\ge 0: S_n = -A \\rbrace$, and $\\mathbb{P}[T_B \u0026lt; \\infty] = 1$ where $T_B := \\min\\lbrace n \\ge 0: S_n = B\\rbrace$. Thus, we know that $\\mathbb{P}[T \u0026lt; \\infty] = 1$ as $T = \\min(T_A,T_B)$. But what about $\\mathbb{E}[T]$ in this case?\nWe use another technique called Wald identities, two of which have the form below in a random-walk setting:\nIf the step distribution has a finite first moment and the stopping time has a finite expectation, then $\\mathbb{E}[S_T] = \\mathbb{E}[X_1]\\mathbb{E}[T]$. If the step distribution has a finite second moment and the stopping time has a finite expectation, then $\\mathbb{E}[(S_T-\\mathbb{E}[X_1]T)^2]=\\mathbb{E}[(X_1-\\mathbb{E}[X_1])^2]\\mathbb{E}[T]$. Let us assume $\\mathbb{E}[T] \u0026lt; \\infty$ first. By the definition of $X_1$, we know that $\\mathbb{E}[X_1] = 0$ and $\\mathbb{E}[X_1^2]=1$. By the first Wald identity, we have $\\mathbb{E}[S_T]=0$. The random variable $S_T$ takes only two values, $-A$ and $B$, with probabilities $u$ and $1-u$ such that $u \\cdot (-A) + (1-u) \\cdot B = 0 \\implies u = B/(A+B)$. By the second Wald identity, we know that $\\mathbb{E}[S_T^2]=\\mathbb{E}[T]$. Thus, we can compute $\\mathbb{E}[T]$ from $S_T$’s distribution: $ \\frac{B}{A+B} \\cdot (-A)^2 + \\frac{A}{A+B} \\cdot B^2 = A \\cdot B$.\nTo show $\\mathbb{E}[T] \u0026lt; \\infty$ at the first place, we observe that if at any time during the gamble Alice wins consecutive $A+B$ rounds, then Bob must run out of money and the gamble must terminate. Thus, $$ \\mathbb{P}[T \u0026gt; k(A+B)] \\le (1 - \\frac{1}{2^{A+B}})^k, $$ and $\\mathbb{E}[T] \\le \\sum_{k=0}^\\infty (A+B)(1-\\frac{1}{2^{A+B}})^k \u0026lt; \\infty$.\nAsymmetric Random Walk (Uneven Steps) For each $i \\in \\mathbb{N}$, we consider $X_i = \\left\\lbrace \\begin{array}{ll} 2 \u0026amp; \\text{with prob.}~0.5 \\\\ -1 \u0026amp; \\text{with prob.}~0.5 \\end{array} \\right.$. For the termination criterion, we define $T(m) := \\min\\lbrace n \\ge 0 : S_n \\ge m\\rbrace$ for any positive integer $m$. Let us fixed an $m$ and write $T = T(m)$. This …","date":1613347200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1631577600,"objectID":"56ec80e9a94396e230a2275c9f568763","permalink":"https://stonebuddha.github.io/zh/post/termination-analysis-of-random-walks/","publishdate":"2021-02-15T00:00:00Z","relpermalink":"/zh/post/termination-analysis-of-random-walks/","section":"post","summary":"In this post, we consider one-dimensional random walks: assume that $S_n = \\sum_{i=1}^n X_i$ is a random walk on the integers with initial value $S_0 = 0$, where $X_i, i","tags":[],"title":"随机游走的停时分析（英文）","type":"post"},{"authors":[],"categories":null,"content":"","date":1602864000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1602864000,"objectID":"f2f943e9b90569b648b57b0e28659d20","permalink":"https://stonebuddha.github.io/zh/talk/type-based-resource-guided-search/","publishdate":"2021-09-15T13:03:49+08:00","relpermalink":"/zh/talk/type-based-resource-guided-search/","section":"event","summary":"","tags":[],"title":"Type-Based Resource-Guided Search","type":"event"},{"authors":["Tristan Knoth","王迪","Adam Reynolds","Jan Hoffmann","Nadia Polikarpova"],"categories":[],"content":"","date":1598140800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1598140800,"objectID":"891908906372a09b354db8d1cdbd4ad8","permalink":"https://stonebuddha.github.io/zh/publication/knothwr20/","publishdate":"2021-09-15T12:13:40+08:00","relpermalink":"/zh/publication/knothwr20/","section":"publication","summary":"This article presents *liquid resource types*, a technique for automatically verifying the resource consumption of functional programs. Existing resource analysis techniques trade automation for flexibility -- automated techniques are restricted to relatively constrained families of resource bounds, while more expressive proof techniques admitting value-dependent bounds rely on handwritten proofs. Liquid resource types combine the best of these approaches, using logical refinements to automatically prove precise bounds on a program's resource consumption. The type system augments refinement types with potential annotations to conduct an amortized resource analysis. Importantly, users can annotate data structure declarations to indicate how potential is allocated within the type, allowing the system to express bounds with polynomials and exponentials, as well as more precise expressions depending on program values. We prove the soundness of the type system, provide a library of flexible and reusable data structures for conducting resource analysis, and use our prototype implementation to automatically verify resource bounds that previously required a manual proof.","tags":[],"title":"Liquid Resource Types","type":"publication"},{"authors":["王迪","David M. Kahn","Jan Hoffmann"],"categories":[],"content":"","date":1598140800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1598140800,"objectID":"e9891938a37fd75956d111600c8d43d4","permalink":"https://stonebuddha.github.io/zh/publication/wangkh20/","publishdate":"2021-09-15T12:17:33+08:00","relpermalink":"/zh/publication/wangkh20/","section":"publication","summary":"This article presents a type-based analysis for deriving upper bounds on the expected execution cost of probabilistic programs. The analysis is naturally compositional, parametric in the cost model, and supports higher-order functions and inductive data types. The derived bounds are multivariate polynomials that are functions of data structures. Bound inference is enabled by local type rules that reduce type inference to linear constraint solving. The type system is based on the potential method of amortized analysis and extends automatic amortized resource analysis (AARA) for deterministic programs. A main innovation is that bounds can contain symbolic probabilities, which may appear in data structures and function arguments. Another contribution is a novel soundness proof that establishes the correctness of the derived bounds with respect to a distribution-based operational cost semantics that also includes nontrivial diverging behavior. For cost models like time, derived bounds imply termination with probability one. To highlight the novel ideas, the presentation focuses on linear potential and a core language. However, the analysis is implemented as an extension of Resource Aware ML and supports polynomial bounds and user defined data structures. The effectiveness of the technique is evaluated by analyzing the sample complexity of discrete distributions and with a novel average-case estimation for deterministic programs that combines expected cost analysis with statistical methods.","tags":[],"title":"Raising Expectations: Automating Expected Cost Analysis with Types","type":"publication"},{"authors":[],"categories":null,"content":"","date":1574442000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1574442000,"objectID":"1f9966125b237ccbe96f2d654aaff7d6","permalink":"https://stonebuddha.github.io/zh/talk/resource-guided-program-synthesis/","publishdate":"2021-09-15T13:03:42+08:00","relpermalink":"/zh/talk/resource-guided-program-synthesis/","section":"event","summary":"","tags":[],"title":"Resource-Guided Program Synthesis","type":"event"},{"authors":["Tristan Knoth","王迪","Nadia Polikarpova","Jan Hoffmann"],"categories":[],"content":"","date":1561161600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1561161600,"objectID":"8c9817600be722a6272fb40bfcf9933c","permalink":"https://stonebuddha.github.io/zh/publication/knothwp19/","publishdate":"2021-09-15T12:22:06+08:00","relpermalink":"/zh/publication/knothwp19/","section":"publication","summary":"This article presents resource-guided synthesis, a technique for synthesizing recursive programs that satisfy both a functional specification and a symbolic resource bound. The technique is type-directed and rests upon a novel type system that combines polymorphic refinement types with potential annotations of automatic amortized resource analysis. The type system enables efficient constraint-based type checking and can express precise refinement-based resource bounds. The proof of type soundness shows that synthesized programs are correct by construction. By tightly integrating program exploration and type checking, the synthesizer can leverage the user-provided resource bound to guide the search, eagerly rejecting incomplete programs that consume too many resources. An implementation in the resource-guided synthesizer ReSyn is used to evaluate the technique on a range of recursive data structure manipulations. The experiments show that ReSyn synthesizes programs that are asymptotically more efficient than those generated by a resource-agnostic synthesizer. Moreover, synthesis with ReSyn is faster than a naive combination of synthesis and resource analysis. ReSyn is also able to generate implementations that have a constant resource consumption for fixed input sizes, which can be used to mitigate side-channel attacks.","tags":[],"title":"Resource-Guided Program Synthesis","type":"publication"},{"authors":["王迪","Jan Hoffmann","Thomas Reps"],"categories":[],"content":"","date":1559520000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1559520000,"objectID":"8c71245de524557a2fffb8e48e7fe3ca","permalink":"https://stonebuddha.github.io/zh/publication/wanghr19/","publishdate":"2021-09-15T12:25:42+08:00","relpermalink":"/zh/publication/wanghr19/","section":"publication","summary":"Probabilistic programming is an increasingly popular formalism for modeling randomness and uncertainty. Designing semantic models for probabilistic programs has been extensively studied, but is technically challenging. Particular complications arise when trying to account for (i) unstructured control-flow, a natural feature in low-level imperative programs; (ii) general recursion, an extensively used programming paradigm; and (iii) nondeterminism, which is often used to represent adversarial actions in probabilistic models, and to support refinement-based development. This paper presents a denotational-semantics framework that supports the three features mentioned above, while allowing nondeterminism to be handled in different ways. To support both probabilistic choice and nondeterministic choice, the semantics is given over control-flow *hyper*-graphs. The semantics follows an *algebraic* approach: it can be instantiated in different ways as long as certain algebraic properties hold. In particular, the semantics can be instantiated to support nondeterminism among either *program states* or *state transformers*. We develop a new formalization of nondeterminism based on *powerdomains* over *sub-probability kernels*. Semantic objects in the powerdomain enjoy a notion we call *generalized convexity*, which is a generalization of convexity. As an application, the paper studies the semantic foundations of an algebraic framework for static analysis of probabilistic programs.","tags":[],"title":"A Denotational Semantics for Low-Level Probabilistic Programs with Nondeterminism","type":"publication"},{"authors":["王迪","Jan Hoffmann"],"categories":[],"content":"","date":1547337600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1547337600,"objectID":"696798cbada90d27d9db5c1f6b017964","permalink":"https://stonebuddha.github.io/zh/publication/wangh19/","publishdate":"2021-09-15T12:28:43+08:00","relpermalink":"/zh/publication/wangh19/","section":"publication","summary":"This paper presents a novel technique for type-guided worst-case input generation for functional programs. The technique builds on automatic amortized resource analysis (AARA), a type-based technique for deriving symbolic bounds on the resource usage of functions. Worst-case input generation is performed by an algorithm that takes as input a function, its resource-annotated type derivation in AARA, and a skeleton that describes the shape and size of the input that is to be generated. If successful, the algorithm fills in integers, booleans, and data structures to produce a value of the shape given by the skeleton. The soundness theorem states that the generated value exhibits the highest cost among all arguments of the functions that have the shape of the skeleton. This cost corresponds exactly to the worst-case bound that is established by the type derivation. In this way, a successful completion of the algorithm proves that the bound is tight for inputs of the given shape. Correspondingly, a relative completeness theorem is proved to show that the algorithm succeeds if and only if the derived worst-case bound is tight. The theorem is relative because it depends on a decision procedure for constraint solving. The technical development is presented for a simple first-order language with linear resource bounds. However, the technique scales to and has been implemented for Resource Aware ML, an implementation of AARA for a fragment of OCaml with higher-order functions, user-defined data types, and types for polynomial bounds. Experiments demonstrate that the technique works effectively and can derive worst-case inputs with hundreds of integers for sorting algorithms, operations on search trees, and insertions into hash tables.","tags":[],"title":"Type-Guided Worst-Case Input Generation","type":"publication"},{"authors":["王迪"],"categories":[],"content":"Problem link: Counting Road Networks | HackerRank.\nYou are supposed to count the number of connected undirected labeled graphs with $n$ vertices. Algorithms with $O(n \\log^2 n)$ time complexity are preferable.\nA Dynamic-Programming Algorithm Let $f(n)$ be the answer for $n$. The first idea to compute $f(n)$ is subtracting the number of disconnected graphs from the total number. The total number of size-$n$ graphs is $g(n) := 2^{\\binom{n}{2}}$. How to count the disconnected graphs? Let’s consider the size $m$ of the connected component containing the vertex labeled with 1. Since the graph is disconnected, $m$ cannot be $n$. Then the number of disconnected graphs where the connected component containing vertex 1 is a certain one with size $m$ is exactly $f(m) \\cdot g(n-m)$. Now we have an $O(n^2)$-time dynamic-programming algorithm as follows. $$ f(n) = g(n) - \\sum_{m=1}^{n-1} \\binom{n-1}{m-1} \\cdot f(m) \\cdot g(n - m) $$\nExpression Rearrangement If we unfold the binomial coefficients, we will have $$ \\frac{f(n)}{(n-1)!} = n \\cdot \\frac{g(n)}{n!} - \\sum_{m=1}^{n-1} \\frac{f(m)}{(m-1)!} \\cdot \\frac{g(n-m)}{(n-m)!} $$ Let $F(n) := \\frac{f(n)}{(n-1)!}$ and $G(n) := \\frac{g(n)}{n!}$. Moreover, let’s set $F(0)$ to $0$ and then we have $$ F(n) = n \\cdot G(n) - \\sum_{m=0}^{n-1} F(m) \\cdot G(n-m) $$ Note that we already have a convolution-like term in the formula.\nAn Optimization Based on FFT We will use Fast Fourier transform (FFT) as an $O(n \\log n)$-time algorithm to compute convolution of length $n$.\nFirst of all, $G(n)$ are easy to compute so we can pre-process them. Now we are going to use a divide-and-conquer scheme. Let $solve(l,r)$ be a procedure that computes $F(n)$ for all $n \\in [l,r)$. In addition, we add the following invariant to this procedure:\nWhen invoking $solve(l,r)$, we already compute for each $n \\in [l,r)$, the partial convolution $\\sum_{m=0}^{l-1} F(m) \\cdot G(n-m)$, and store them in $H(n)$.\nThen our algorithm proceeds as follows.\nIf $l+1=r$, we set $F(l)$ to $l \\cdot G(l) - H(l)$. Otherwise, let’s invoke $solve(l,k)$ first where $k = \\frac{l+r}{2}$, i.e., the middle point. Now we already solve the first half of the problem. To become able to invoke $solve(k,r)$ to complete the second half, we need to do something to maintain the invariant above. In essence, we need to update $$ H(n) \\gets H(n) + \\sum_{m=l}^{k-1} F(m) \\cdot G(n-m) $$ for each $n \\in [k,r)$. Here comes the chance for optimization. What we really want to compute is the convolution of $F[l,k)$ and $G[0,r-l)$! Let the convolution result be $C$ and indeed we have $$ C(n) = \\sum_{m=l}^{k-1} F(m) \\cdot G(n-m) $$ for each $n \\in [k,r)$. After performing $H(n) \\gets H(n) + C(n)$ for each $n \\in [k,r)$, we reestablish the invariant and we can recurse to $solve(k,r)$. Finally, let’s estimate the time complexity of the algorithm above. Let $T(n)$ be the running time of $solve(l,r)$ with $n=r-l$. By using FFT to compute the convolution, we can establish the following $$ T(n) = 2T(\\frac{n}{2}) + O(n \\log n) $$ Then by the Master Theorem we derive that $T(n) = O(n \\log^2 n)$.\nWhat’s More For those who could read Chinese, CDQ’s divide-and-conquer is a good reference about applications of the divide-and-conquer scheme in this post.\n","date":1541203200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1541203200,"objectID":"29ccbfdaca3dda2d3b131cf43406a657","permalink":"https://stonebuddha.github.io/zh/post/using-fft-to-speed-up-dp/","publishdate":"2018-11-03T00:00:00Z","relpermalink":"/zh/post/using-fft-to-speed-up-dp/","section":"post","summary":"Problem link: Counting Road Networks | HackerRank. You are supposed to count the number of connected undirected labeled graphs with $n$ vertices. Algorithms with $O(n \\log^2 n)$ time complexity are","tags":[],"title":"使用 FFT 加速动态规划（英文）","type":"post"},{"authors":["王迪","Jan Hoffmann","Thomas Reps"],"categories":[],"content":"","date":1529452800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1529452800,"objectID":"101d9e3872d9bfa30a1da294e9e55e81","permalink":"https://stonebuddha.github.io/zh/publication/wanghr18/","publishdate":"2021-09-15T12:31:55+08:00","relpermalink":"/zh/publication/wanghr18/","section":"publication","summary":"Automatically establishing that a probabilistic program satisfies some property $\\varphi$ is a challenging problem. While a sampling-based approach---which involves running the program repeatedly---can *suggest* that $\\varphi$ holds, to establish that the program *satisfies* $\\varphi$, analysis techniques must be used. Despite recent successes, probabilistic static analyses are still more difficult to design and implement than their deterministic counterparts. This paper presents a framework, called *PMAF*, for designing, implementing, and proving the correctness of static analyses of probabilistic programs with challenging features such as recursion, unstructured control-flow, divergence, nondeterminism, and continuous distributions. PMAF introduces *pre-Markov algebras* to factor out common parts of different analyses. To perform *interprocedural analysis* and to create *procedure summaries*, PMAF extends ideas from non-probabilistic interprocedural dataflow analysis to the probabilistic setting. One novelty is that PMAF is based on a semantics formulated in terms of a control-flow *hyper-graph* for each procedure, rather than a standard control-flow graph. To evaluate its effectiveness, PMAF has been used to reformulate and implement existing *intraprocedural* analyses for Bayesian-inference and the Markov decision problem, by creating corresponding *interprocedural* analyses. Additionally, PMAF has been used to implement a new interprocedural *linear expectation-invariant analysis*. Experiments with benchmark programs for the three analyses demonstrate that the approach is practical.","tags":[],"title":"PMAF: An Algebraic Framework for Static Analysis of Probabilistic Programs","type":"publication"},{"authors":[],"categories":null,"content":"","date":1524240000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1524240000,"objectID":"daa36599b1552c0645901e5c699b9fd9","permalink":"https://stonebuddha.github.io/zh/talk/pmaf-an-algebraic-framework-for-static-analysis-of-probabilistic-programs/","publishdate":"2021-09-15T12:58:44+08:00","relpermalink":"/zh/talk/pmaf-an-algebraic-framework-for-static-analysis-of-probabilistic-programs/","section":"event","summary":"","tags":[],"title":"PMAF: An Algebraic Framework for Static Analysis of Probabilistic Programs","type":"event"},{"authors":[],"categories":null,"content":"","date":1518195600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1518195600,"objectID":"310a157f4f49e4d30f2538b522d5e363","permalink":"https://stonebuddha.github.io/zh/talk/timl-a-functional-language-for-practical-complexity-analysis-with-invariants/","publishdate":"2021-09-15T13:03:56+08:00","relpermalink":"/zh/talk/timl-a-functional-language-for-practical-complexity-analysis-with-invariants/","section":"event","summary":"","tags":[],"title":"TiML: A Functional Language for Practical Complexity Analysis with Invariants","type":"event"},{"authors":["王迪"],"categories":[],"content":"Suppose you have a toy specification with built-in nondeterminism, and you want to generate answers with respect to the specification:\ntype exp = EInt of int | EPair of exp * exp | ENdet of exp * exp type ans = VInt of int | VPair of ans * ans For example, from the following specification\nEPair (ENdet (EInt 5) (EInt 6)) (ENdet (EInt 7) (EInt 8)) you might want to generate a bunch of possible answers:\nVPair (VInt 5) (VInt 7) VPair (VInt 5) (VInt 8) VPair (VInt 6) (VInt 7) VPair (VInt 6) (VInt 8) The scene might be where you want to specify something with multiple sites of nondeterminism, ask the generator to come up with an answer, and successively give you other answers until you are satisfied.\nThe basic methodology is search. We want to construct a recursive procedure on the structure of a specification. For a sub-specification, it should know two sorts of computation:\nthe computation that completes a whole answer and constructs a procedure for next whole answers, given the current sub-answer for the sub-specification and a procedure for next whole answers if the current sub-answer would leads to a subsequent unsatisfactoriness; and the computation to find next whole answers. In this sense, the first computation has type $\\mathsf{ans} \\to \\mathsf{next} \\to \\mathsf{ans} \\times \\mathsf{next}$, and the second one should be typed $\\mathsf{next}$. A computation of type $\\mathsf{next}$ is supposed to (i) either fail, or (ii) take no arguments, and when invoked it should return the next whole answer as well as a new $\\mathsf{next}$ computation. Thus we have $\\mathsf{next} \\equiv \\mathbf{1} + \\mathbf{1} \\to (\\mathsf{ans} \\times \\mathsf{next})$. Therefore we use recursive types to model this mechanism.\ntype next = NFail | NCont of (unit -\u0026gt; ans * next) Then it is straightforward to implement an interpreter:\nlet rec interp exp cont fail = match exp with | EInt n -\u0026gt; cont (VInt n) fail | EPair (e, e\u0026#39;) -\u0026gt; interp e (fun v fail\u0026#39; -\u0026gt; interp e\u0026#39; (fun v\u0026#39; fail\u0026#39;\u0026#39; -\u0026gt; cont (VPair (v, v\u0026#39;)) fail\u0026#39;\u0026#39;) fail\u0026#39;) fail | ENdet (e1, e2) -\u0026gt; interp e1 cont (NCont (fun () -\u0026gt; interp e2 cont fail)) The execution should be the following:\nlet (ans1, next1) = interp (EPair (ENdet (EInt 5) (EInt 6)) (ENdet (EInt 7) (EInt 8))) (fun v fail -\u0026gt; (v, fail)) NFail;; (* val ans1 : ans = VPair (VInt 5, VInt 7) *) (* val next1 : next = NCont \u0026lt;fun\u0026gt; *) let (ans2, next2) = match next1 with NCont f -\u0026gt; f ();; (* val ans2 : ans = VPair (VInt 5, VInt 8) *) (* val next2 : next = NCont \u0026lt;fun\u0026gt; *) let (ans3, next3) = match next2 with NCont f -\u0026gt; f ();; (* val ans3 : ans = VPair (VInt 6, VInt 7) *) (* val next3 : next = NCont \u0026lt;fun\u0026gt; *) let (ans4, next4) = match next3 with NCont f -\u0026gt; f ();; (* val ans4 : ans = VPair (VInt 6, VInt 8) *) (* val next4 : next = NFail *) ","date":1518048000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1518048000,"objectID":"bdf032f7d4b3913f7157dc7ec6f50582","permalink":"https://stonebuddha.github.io/zh/post/nondeterministic-interpretation/","publishdate":"2018-02-08T00:00:00Z","relpermalink":"/zh/post/nondeterministic-interpretation/","section":"post","summary":"Suppose you have a toy specification with built-in nondeterminism, and you want to generate answers with respect to the specification: type exp = EInt of int | EPair of exp","tags":[],"title":"非确定性的解释器（英文）","type":"post"},{"authors":["Peng Wang","王迪","Adam Chlipala"],"categories":[],"content":"","date":1508889600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1508889600,"objectID":"c6416621277713f368cece0c36217422","permalink":"https://stonebuddha.github.io/zh/publication/wangwc17/","publishdate":"2021-09-15T12:35:14+08:00","relpermalink":"/zh/publication/wangwc17/","section":"publication","summary":"We present TiML (Timed ML), an ML-like functional language with time-complexity annotations in types. It uses indexed types to express sizes of data structures and upper bounds on running time of functions; and refinement kinds to constrain these indices, expressing data-structure invariants and pre/post-conditions. Indexed types are flexible enough that TiML avoids a built-in notion of \"size,\" and the programmer can choose to index user-defined datatypes in any way that helps her analysis. TiML's distinguishing characteristic is supporting highly automated time-bound verification applicable to data structures with nontrivial invariants. The programmer provides type annotations, and the typechecker generates verification conditions that are discharged by an SMT solver. Type and index inference are supported to lower annotation burden, and, furthermore, big-O complexity can be inferred from recurrences generated during typechecking by a recurrence solver based on heuristic pattern matching (e.g. using the Master Theorem to handle divide-and-conquerlike recurrences). We have evaluated TiML's usability by implementing a broad suite of case-study modules, demonstrating that TiML, though lacking full automation and theoretical completeness, is versatile enough to verify worst-case and/or amortized complexities for algorithms and data structures like classic list operations, merge sort, Dijkstra's shortest-path algorithm, red-black trees, Braun trees, functional queues, and dynamic tables with bounds like $mn \\log n$. The learning curve and annotation burden are reasonable, as we argue with empirical results on our case studies. We formalized TiML's type-soundness proof in Coq.","tags":[],"title":"TiML: A Functional Language for Practical Complexity Analysis with Invariants","type":"publication"},{"authors":["Hao Tang","王迪","Yingfei Xiong","Lingming Zhang","Xiaoyin Wang","Lu Zhang"],"categories":[],"content":"","date":1492819200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1492819200,"objectID":"f10bc7fc2a07bb729f6242653bbc6924","permalink":"https://stonebuddha.github.io/zh/publication/tangwx17/","publishdate":"2021-09-15T12:35:20+08:00","relpermalink":"/zh/publication/tangwx17/","section":"publication","summary":"Library summarization is an effective way to accelerate the analysis of client code. However, information about the client is unknown at the library summarization, preventing complete summarization of the library. An existing approach utilizes tree-adjoining languages (TALs) to provide conditional summaries, enabling the summarization of a library under certain premises. However, the use of TAL imposes several problems, preventing a complete summarization of a library and reducing the efficiency of the analysis. In this paper we propose a new conditional summarization technique based on the context-free language (CFL) reachability analysis. Our technique overcomes the above two limitations of TAL, and is more accessible since CFL reachability is much more efficient and widely-used than TAL reachability. Furthermore, to overcome the high cost from premise combination, we also provide a technique to confine the number of premises while maintaining full summarization of the library. We empirically compared our approach with the state-of-art TAL conditional summarization technique on 12 Java benchmark subjects from the SPECjvm2008 benchmark suite. The results demonstrate that our approach is able to significantly outperform TAL on both efficiency and precision.","tags":[],"title":"Conditional Dyck-CFL Reachability Analysis for Complete and Efficient Library Summarization","type":"publication"},{"authors":["王迪"],"categories":null,"content":"（最后更新：2024 年 4 月 8 日）\n我对编程语言的多个研究话题都很有兴趣，尤其是形式化验证、程序分析以及概率编程。 我目前的研究项目主要涉及资源安全的系统编程、可编程贝叶斯推断、量化程序分析以及面向证明的编程语言。\n如果你想了解我目前的研究项目和方向，可以参考下方的列表。 如果你想看一下我申请教职时关于软件中的随机性的构想，可以参考我的研究陈述（英文）。 如果你比较关心我在教学和指导学生上的经验和方法，可以参考我的教学陈述（英文）。 如果你有关于我、北京大学或者程序设计语言研究室的具体问题，可以参考下面的 Q\u0026amp;A 或者发邮件给我。 Q\u0026amp;A “你招收学生吗？” 是的！ 我计划每年招一到两个博士生，也欢迎感兴趣的硕士和本科生。 “我需要有特定的研究履历吗？我需要清楚自己要做什么特定的项目吗？” 简单的回答是“不用”。 有编程语言或软件工程相关的研究经验当然很好，但不是必需的。 相比于过往的经验，更重要的是你知道自己对什么感兴趣，并且有动力用四到五年的时间去探索一个领域内的各种问题。 “我可以做机器学习、操作系统、数据库等等相关的项目吗？” 没问题，这些领域与编程语言都有相关的交叉领域。 以下是一些跨领域的研讨会，仅作参考： Symposium on Machine Programming， Workshop on Languages for Inference， Workshop on Programming Languages and Operating Systems， Symposium on Database Programming Languages。 “北京大学有什么优势？在那儿可以跟哪些老师合作？” 北京大学拥有世界一流的计算机学院（CSRankings (2013-2023) 排名 14，QS Rankings (2023) 排名 19）。 计算机学院拥有很多很厉害的老师和学生，他们的研究包括软件工程、编程语言、操作系统等诸多领域。 以下是软件工程、编程语言领域的一些老师，按照姓氏字典序排列，仅供参考： 郝丹， 胡振江， 谢涛， 熊英飞， 张路， 张昕。 “你为什么还没有回我邮件！” 不好意思，如果一个星期了我都还没回，麻烦再发送一次。 目前的研究项目和方向 以下是我目前主要的研究项目（并不是一个完整的列表）。如果你有兴趣在这些项目上与我进行合作，请联系我！\n资源安全的系统编程 程序的资源消耗（比如时间、内存、能源）是计算机科学中的一个重要研究对象，但是它在程序语言理论（比如形式化语义、静态分析、类型系统、程序逻辑）里往往不太受重视。 我对与资源消耗分析相关的项目都很有兴趣，包括程序验证（比如验证现有语言上的现有代码的时间复杂度符合规约）和语言设计（比如使得资源分析更容易、更精确的语言特性）。\n在系统编程中，资源消耗分析正变得越来越重要。 编程语言 Rust 的成功说明了现代系统编程需要编程语言提供更强的静态安全保障，比如内存安全和线程安全。 当然，很多现有语言是能够提供多种安全保障的，但往往是通过一些运行时机制（比如垃圾回收），而这些机制会有一定的运行时开销，影响程序性能，这在系统软件中常常不够令人满意。 Rust 语言设计了一个保障内存安全的类型系统，降低了运行时的内存管理开销，从而提高了软件性能。 不过，系统软件的性能并不仅仅与内存管理有关。 我想要提出一个资源安全编程的范式，该范式不但能在静态检查中验证程序的资源消耗符合开发者的预期，而且能够保障程序中没有与资源消耗相关的安全缺陷，比如算法复杂度攻击漏洞和侧信道攻击漏洞。 以下为一些关于资源安全系统编程的中到长期项目：\nRust 语言上的资源分析：Rust 中的精确内存模型是否可以帮助提高资源分析的精度和效率？ 并发程序的资源分析：Rust 已经可以静态检查一些线程安全问题（如数据竞争），但还存在很多局限，比如不能静态检查是否存在死锁。 我们是否可以在系统编程的类型系统中融入精确的并发模型，并为之设计资源分析的方法？ 目标代码资源分析：如何保证编译后的目标代码仍然符合在源代码上分析出的资源消耗情况？更进一步地，如何分析目标代码的细粒度资源消耗，比如时钟周期数？ 在这个粒度上，我们需要考虑硬件特性，比如缓存、流水线、分支预测等。 挖掘资源消耗相关安全问题：我们是否可以利用资源消耗分析来挖掘算法复杂度攻击和/或侧信道攻击安全漏洞？ 更进一步地，如果发现了潜在漏洞，我们是否可以自动合成一个攻击方案来实际触发该漏洞，以证明漏洞确实存在？ 目前我比较倾向尝试的技术路线是自动均摊资源分析（Automatic Amortized Resource Analysis，AARA1）。 当然，我也愿意尝试其它方法，比如递推关系求解（Recurrence Solving）、带大小类型（Sized Types）、阶函数（Ranking Functions）、符号资源分析（Symbolic Resource Analysis）等，毕竟实践是检验真理的唯一标准。\n可编程贝叶斯推断 与频率学派的方法（如一般意义上的深度学习）认为模型是一个未知的假设，贝叶斯学习侧重分析能生成观测到的数据的假设的概率分布，从而自然地能对学习到的模型的不确定性进行分析。 贝叶斯学习也有容易融入领域知识、在未知数据上有较好的泛化能力等优点。 概率编程语言（Probabilistic Programming Language，PPL）如 Stan 和 Pyro 等通过自动化贝叶斯推断使得应用贝叶斯学习更加容易。 这些语言往往通过语言设计来隔离概率模型迭代和贝叶斯推断，并在推断引擎中提供若干种不同的推断算法。\n贝叶斯学习的一个主要不足是贝叶斯推断的计算复杂性很高，而且最先进的推断算法也不能在所有概率模型上都有令人满意的效果。 为了使贝叶斯推断在更多的概率模型和更大的数据规模上能够起作用，一些 PPL 减弱了建模和推断之间的隔离，允许用户对一些特性的贝叶斯推断算法进行定制，这种模式被称为可编程推断2。 然而，用户定制推断算法时是比较容易出错的，这些错误会影响贝叶斯推断的收敛性和正确性，甚至很多时候这些错误在开发和模型迭代的过程中难以被察觉。\n为了平衡可编程贝叶斯推断的可靠性和灵活性，我希望在概率编程中应用编程语言技术，比如类型系统、静态分析、程序合成等。 通过新的编程抽象和类型系统，我们可以保证推断的可靠性（包括收敛性和正确性），而通过静态分析和程序合成，我们可以为用户提供辅助来自动化推断自定义的过程，从而提高开发效率。 我们的 PLDI 论文可以看作这个研究项目的第一步。\n量化程序分析 程序中的随机性可以表现为两方面：外部随机性（比如运行环境中的不确定性）和内部随机性（比如随机化算法）。 正如 Kleene 代数可作为非概率程序的代数程序分析的理论基础3，我希望建立一个适用于概率程序的代数程序分析的理论框架。 为此，我们需要构建一个概率程序的代数语义框架，并以此为基础设计一个通用的概率程序的程序分析求解算法。\n非概率程序和概率程序间的一个本质不同是非概率程序的一个运行可以看作一条链，但是概率程序的一个运行需要看作一棵树。 为了说明这一点，我们考虑一个同时支持概率和非确定性的程序模型。 在该模型下，一个非概率程序对应一个可能的运行链的集合，但是一个概率程序需要对应一个概率分布的集合，其中的每个概率分布对应一个运行树，树上的每条从根出发的路径则对应程序中的一条具体的运行链。 我们在 MFPS 论文中基于超图（Hyper-Graphs）给出了上述想法的形式化表示。\n抽象解释是一个表达和求解程序分析的强大通用框架。在这个框架中，人们已经设计了多种通用求解策略和收敛技术，比如 Chaotic Iteration、Widening、Narrowing 等。 但是，这些基于迭代的求解算法与概率程序本身的量化特质不太匹配。 假设我们想分析概率循环“$\\mathbf{while}~(\\mathbf{prob}(3/4))~\\{ x = x + 1; \\}$”。 变量 $x$ 的期望变化量可以看作是方程 $r = f(r) \\equiv (1/4) \\cdot 0+(3/4) \\cdot (r+1)$ 的最小的解，很容易看出这个解是 $r=3$。 但是，一个基于迭代的求解策略大概会通过一系列近似来逼近 $r$：$\\{ f^i(0) \\}_{i \\in \\mathbb{N}}$，该序列并不能在任何有限的迭代次数内收敛。 在数值分析领域中，牛顿法往往是更适用于这种量化特性的方法，所以我希望能够将牛顿程序分析4技术迁移到概率程序的程序分析上。\n更进一步地，这个概率程序的代数分析框架从原则上也应该适用于其它的量化性质，比如资源消耗。 我很好奇这一观察是否可以导出一个更通用的量化程序分析框架。 最近的一篇论文5还提出了 Weighted Programming 的概念，进一步从量化数值性质推广到符合某些代数结构的性质。 作为这个通用量化程序分析框架的应用，我们可以在概率分析和资源分析两个社区间进行技术迁移，比如最大后验估计（MAP）跟最坏情况分析（WCA）的数学形式很相近，我希望研究是否可以基于此关系设计新的统计资源分析方法。\n其它项目 我对新的方向永远持欢迎的态度，包括跨领域的方向。 以下是一些我有兴趣探索的研究想法，它们通常是短到中期的研究项目。 注意，这个列表并不完整，而且很多想法并不成熟（我甚至预期其中的相当一部分不太能做得出来）。\n（以下内容为英文）\n静态分析 Library Summarization via Tensor Products Problem: Library summarization is an effective way to accelerate the analysis of client code. However, information about the client is unknown at the library summarization, preventing complete summarization of the library. A state-of-the-art approach is Conditional Dyck-CFL Reachability Analysis (ConCRA), which targets graph-reachability-like static analyses and uses hypothetical summaries.\nProposal: Lal et al.6 proposed a tensor-product principle: Tensor products with an appropriate detensor operation allow computations to be rearranged in certain ways; for example, they can be used to delay a multiplication in a chain of multiplications. This principle may allow us to generalize, in the summarization framework, Dyck-CFL-reachability-based analyses to algebraic semiring-based analysis.\nFollow-up: The library summarization problem can be generalized to partially solving an equation system for a static analysis. Any thoughts on partial evaluation?\nNPA-TP for Non-idempotent Semirings …","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":-62135596800,"objectID":"38459eac7fde56de6ea768a018e5a32d","permalink":"https://stonebuddha.github.io/zh/prospective-students/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/prospective-students/","section":"","summary":"（最后更新：2024 年 4 月 8 日） 我对编程语言的多个研究话题都","tags":null,"title":"Resources for Prospective Students","type":"page"},{"authors":["王迪"],"categories":null,"content":" [Sep 2021] 我开始找 2022 年入职的学术界工作！ [Feb 2021] 两篇论文 Sound Probabilistic Inference via Guide Types 和 Central Moment Analysis for Cost Accumulators in Probabilistic Programs 被 PLDI 2021 接收。 [Nov 2020] 预印本 Probabilistic Resource-Aware Session Types 已上传至 arXiv。 [Jun 2020] 两篇论文 Liquid Resource Types 和 Raising Expectations: Automating Expected Cost Analysis with Types 被 ICFP 2020 接收。 [May 2019] 论文 A Denotational Semantics for Low-Level Probabilistic Programs with Nondeterminism 被 MFPS 接收。 [Feb 2019] Resource-Guided Program Synthesis 被 PLDI 2019 接收。 [Nov 2018] Type-Guided Worst-Case Input Generation 被 POPL 2019 接收。 [Mar 2018] 这是我在 SCS Day 2018 上的表演：Chengdu。 [Feb 2018] PMAF: An Algebraic Framework for Static Analysis of Probabilistic Programs 被 PLDI 2018 接收。 [Jun 2017] 我从北京大学毕业了。我的学位论文为基于 Datalog 条件摘要的程序分析加速技术。 ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":-62135596800,"objectID":"52d880278beeb7d6fedf412fe0ffeb77","permalink":"https://stonebuddha.github.io/zh/news_archive/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/zh/news_archive/","section":"","summary":"[Sep 2021] 我开始找 2022 年入职的学术界工作！ [Feb 2021] 两篇论文 Sound Probabilistic Inference via Guide Types 和","tags":null,"title":"新闻归档","type":"page"}]